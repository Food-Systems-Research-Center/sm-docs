---
title: "Validation"
format:
  html:
    fig-dpi: 200
editor_options: 
  chunk_output_type: console
warnings: false
---

```{r}
#| label: prep
#| include: false
pacman::p_load(
  dplyr,
  purrr,
  stringr,
  tidyr,
  performance,
  AER,
  sandwich,
  sjPlot,
  htmltools,
  caret,
  ranger,
  glmnet,
  psych,
  tibble,
  reactable
)
source('dev/data_pipeline_functions.R')
source('dev/get_res_plots.R')
source('dev/get_setup.R')
source('dev/get_stargazer.R')
source('dev/get_reactable.R')

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter(),
  dplyr::select(),
  caret::cluster(),
  .quiet = TRUE
)
```

# Introduction

Here we will use the raw + min max + geometric aggregation scores and see how they hold up to validation by external variables and by PCA.

External variables:

- Food Security Index (Feeding America, Map the Meal Gap)
- Life expectancy, or premature age-adjusted mortality (UW County Health Rankings)
- Food Environment Index (UW County Health Rankings)
- Happiness Score (WalletHub - if anyone knows of a better metric for this, I'm all ears)

```{r}
#| label: wrangle
#| output: false
# Load sm_data
sm_data <- readRDS('data/sm_data.rds')

# Load state fips key to join other datasets
state_key <- sm_data[['state_key']] %>% 
  select(state, state_code)

# Load cleaned aggregated data for all levels of regresion
raw_minmax_geo <- readRDS('data/raw_minmax_geo.rds')
get_str(raw_minmax_geo)

# Reduce to just dimension scores, and remove prefix
dimension_scores <- raw_minmax_geo %>% 
  select(state, starts_with('dimen')) %>% 
  setNames(c(str_remove(names(.), 'dimen_')))
get_str(dimension_scores)

# Pull validation variables out of sm_data, wrangle them to match metrics_df
# Also including covariates, gdp and population
validation_vars <- sm_data$metadata %>% 
  select(variable_name, metric, definition, source) %>% 
  filter(variable_name %in% c(
    'foodInsecurity',
    'communityEnvRank',
    'happinessScore',
    'wellbeingRank',
    'workEnvRank',
    'foodEnvironmentIndex',
    'lifeExpectancy',
    'population',
    'gdpCurrent'
  )) %>% 
  pull(variable_name)
validation_vars  
 
# Get subset of metrics for our validation variables, get latest year only
validation_metrics <- sm_data$metrics %>% 
  filter(
    variable_name %in% validation_vars, 
    !is.na(value), 
    str_length(fips) == 2
  ) %>% 
  get_latest_year()
get_str(validation_metrics)
# All are available in 2024

# Pivot wider, also get rid of trailing year
validation_metrics <- validation_metrics %>% 
  pivot_wider(
    id_cols = fips,
    names_from = variable_name,
    values_from = value
  ) %>% 
  setNames(c(str_remove(names(.), '_[0-9]{4}'))) %>% 
  mutate(across(!fips, as.numeric))
get_str(validation_metrics)
# 00 US is missing a lot obviously
# 11 DC is the other one with missing data
# We will just filter down to 50 states to match metrics_df

# Combine validation variables with our dimension scores using state key as the 
# bridge. Also remove DC (don't have validation metrics there)
key <- sm_data$state_key %>% 
  select(state, fips = state_code)
dat <- dimension_scores %>% 
  left_join(key) %>% 
  left_join(validation_metrics) %>% 
  as.data.frame() %>% 
  filter(state != 'DC') %>% 
  select(-fips)

# Make a GDP per capita variable from GDP real and population
# It was already in millions to begin with
dat <- dat %>% 
  mutate(gdp_per_cap = ((gdpCurrent / population) * 1e6) / 1000)
get_str(dat)

# Check it out
get_str(dat)
skimr::skim(dat)
# Looks good

# Save this for other pages
saveRDS(dat, 'data/metrics_df_with_vals_and_covars.rds')
```

# Regression

## Food Insecurity

```{r}
#| label: food_insecurity_reg
lm1 <- lm(
  foodInsecurity ~ economics + environment + health + production + social,
  data = dat
)
```

```{r}
#| label: food_insecurity_table
#| results: asis
#| echo: false
#| class: stargazer-table
get_stargazer(lm1, type = 'html', dep_var = 'Food Insecurity Index')
```

```{r}
#| label: food_insecurity_check
#| fig-width: 8
#| fig-height: 8
#| fig-align: center
#| out-width: 75%
check_model(lm1)
```

```{r}
#| label: food_insecurity_bptest
lmtest::bptest(lm1)
```

## Life Expectancy

```{r}
#| label: life_exp
lm2 <- lm(
  lifeExpectancy ~ economics + environment + health + production + social,
  data = dat
)
```

```{r}
#| label: life_exp_table
#| class: stargazer-table
#| echo: FALSE
#| results: asis
get_stargazer(lm2, type = 'html', dep_var = 'Life Expectancy')
```

```{r}
#| label: life_exp_check
#| fig-width: 8
#| fig-height: 8
#| fig-align: center
#| out-width: 75%
check_model(lm2)
```

```{r}
#| label: life_exp_bptest
lmtest::bptest(lm2)
life_exp_vcov <- vcovHC(lm2, type = 'HC3')
```


```{r}
#| label: life_exp_robust
#| class: stargazer-table
#| echo: FALSE
#| results: asis
get_stargazer(lm2, dep_var = 'Life Expectancy', robust = TRUE)
```

## Food Environment Index

```{r}
#| label: food_env
lm3 <- lm(
  foodEnvironmentIndex ~ economics + environment + health + production + social,
  data = dat
)
```

```{r}
#| label: food_env_table
#| class: stargazer-table
#| echo: FALSE
#| results: asis
get_stargazer(lm3, type = 'html', dep_var = 'Food Environment Index')
```


```{r}
#| label: food_env_check
#| fig-width: 8
#| fig-height: 8
#| fig-align: center
#| out-width: 75%
bptest(lm3)
check_model(lm3)
```

The Food Environment Index Regression does not show heteroskedasticity, but may well have some non-linear relationships given the residual plots. Health and economics are significant predictors, with a pretty healthy $R^2$.

Let's try this one again with a random forest instead of linear model:

```{r}
#| label: food_env_split
#| output: false
# Get a version of dat without irrelevant variables
dat_ml <- dat %>% 
  select(
    economics, 
    environment, 
    health, 
    production, 
    social, 
    foodEnvironmentIndex,
    gdp_per_cap
  )

# Split data 60/40
set.seed(42)
indices <- createDataPartition(dat_ml$foodEnvironmentIndex, p = 0.60, list = FALSE)
training_data <- dat_ml[indices, ]
testing_data <- dat_ml[-indices,]

my_folds <- createFolds(training_data$foodEnvironmentIndex, k = 5, list = TRUE)

# Control
my_control <- trainControl(
  method = 'cv',
  number = 5,
  verboseIter = TRUE,
  index = my_folds
)

# Check for zero variance or near zero variance indicators
nearZeroVar(dat, names = TRUE, saveMetrics = TRUE)
# All clear

# Also let's start a list with other results for preso
# hyperparameters, etc
ml_out <- list()
```

### GLMnet

```{r}
#| label: food_env_glmnet
#| output: false
set.seed(42)
food_env_glmnet <- train(
  foodEnvironmentIndex ~ economics + environment + health + production + social + gdp_per_cap,
  data = training_data, 
  tuneGrid = expand.grid(
    alpha = seq(0.1, 1, length = 5),
    lambda = seq(0.0001, 0.1, length = 100)
  ),
  method = "glmnet",
  trControl = my_control,
  preProcess = c('zv', 'center', 'scale')
)
get_str(food_env_glmnet)

# Pull out best tune
ml_out$glmnet_best_tune <- food_env_glmnet$bestTune
```


```{r}
#| label: food_env_glmnet_importance
#| fig-align: center
#| out-width: 75%
#| fig-height: 3
importance <- varImp(food_env_glmnet, scale = TRUE)

# Save for preso 
saveRDS(importance, 'preso/plots/val3_food_env_glmnet_importance.rds')

#
pred <- predict(food_env_glmnet, testing_data)
ml_out$glmnet_performance <- postResample(
  pred = pred, 
  obs = testing_data$foodEnvironmentIndex
) %>% 
  round(3)
# ml_out$glmnet_performance

ml_out$glmnet_imp_plot <- importance %>% 
  ggplot(aes(x = Overall, y = rownames(.))) +
  geom_col(
    color = 'royalblue',
    fill = 'lightblue'
  ) +
  theme_classic() 

plot(importance)
```

### Random Forest

```{r}
#| label: food_env_rf
#| output: false
set.seed(42)
food_env_rf <- train(
  foodEnvironmentIndex ~ production + social + health + economics + environment + gdp_per_cap,
  data = training_data, 
  tuneLength = 7,
  method = "ranger",
  trControl = my_control,
  importance = 'impurity'
)

get_str(food_env_rf)

# Pull out best tune
ml_out$rf_best_tune <- food_env_rf$bestTune
```

OOB prediction error (MSE): `r food_env_rf$finalModel$prediction.error`

```{r}
#| label: food_env_rf_importance
#| out-width: 75%
#| fig-height: 3
#| fig-align: center
importance <- varImp(food_env_rf, scale = TRUE)

# Save for preso
saveRDS(importance, 'preso/plots/val3_rf_importance.rds')

# Get RMSEA and stuff
pred <- predict(food_env_rf, testing_data)
ml_out$rf_performance <- postResample(
  pred = pred, 
  obs = testing_data$foodEnvironmentIndex
) %>% 
  round(3)
# ml_out$rf_performance

imp <- importance$importance %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column() %>% 
  setNames(c('Feature', 'Importance')) %>% 
  mutate(Importance = round(Importance, 2)) %>% 
  arrange(desc(Importance)) %>% 
  mutate(
    Feature = Feature %>% 
      str_to_title() %>% 
      str_replace('Gdp_per_cap', 'GDP per capita')
  )
  

ml_out$rf_imp_plot <- imp %>% 
  ggplot(aes(
    x = Importance, 
    y = reorder(Feature, Importance),
    text = paste0(
      '<b>Variable:</b> ', Feature, '\n',
      '<b>Importance:</b> ', Importance
    )
  )) +
  geom_col(
    color = 'royalblue',
    fill = 'lightblue',
  ) +
  theme_classic() +
  labs(
    x = 'Importance',
    y = 'Feature'
  )

# Save all results for preso
saveRDS(ml_out, 'preso/data/ml_out.rds')

# Show plot
ml_out$rf_imp_plot
```

## Happiness Score

```{r}
#| label: happiness
lm4 <- lm(
  happinessScore ~ economics + environment + health + production + social,
  data = dat
)
```

```{r}
#| label: happiness_table
#| class: stargazer-table
#| echo: FALSE
#| results: asis
get_stargazer(lm4, type = 'html', dep_var = 'Happiness Index')
```

```{r}
#| label: happiness_check
#| fig-width: 8
#| fig-height: 8
#| fig-align: center
#| out-width: 75%
check_model(lm4)
```

# PCA

Let's use PCA to see how our indicators are associated with a set of orthogonal components. Ideally, we might like to see that each indicator is associated strongly with a single component (simple structure) that corresponds to the dimension.

## Component Extraction

First we determine how many components to extract. This is a bit subjective, so we will use a few methods.

```{r}
#| label: extraction
#| warning: false
raw_minmax_geo <- readRDS('data/raw_minmax_geo.rds')
framework <- readRDS('data/filtered_frame.rds')

# Filter down to just indicators for PCA
pca_dat <- raw_minmax_geo %>% 
  select(starts_with('indic')) %>% 
  setNames(c(str_remove(names(.), 'indic_'))) %>% 
  as.data.frame()
# get_str(pca_dat)

# Explore how many factors to extract
VSS(pca_dat, n = 8, fm = 'pc', rotate = 'Promax')
set.seed(42)
fa.parallel(pca_dat, fm = 'ml')
```

MAP suggests 6, VSS 2 or 3, PA suggests 5. Not half bad. I think we are justified to go with 5.

```{r}
#| label: scree
# Oblique rotations: promax, oblimin, simplimax, cluster
rotations <- c(
  'Promax',
  'oblimin',
  'simplimax',
  'cluster'
)
pca_outs <- map(rotations, ~ {
  pca_dat %>% 
    # scale() %>% 
    pca(nfactors = 5, rotate = .x)
}) %>% 
  setNames(c(rotations))

# Save a version of promax for preso?
png(
  filename = 'preso/plots/scree.png',
  width = 800,
  height = 600,
  units = 'px',
  res = 150
)
plot(
  pca_outs$simplimax$values,
  xlab = 'Number of Components',
  ylab = 'Eigen Values'
)
abline(h = 1)
dev.off()

# Now actually show it 
plot(
  pca_outs$simplimax$values,
  xlab = 'Number of Components',
  ylab = 'Eigen Values'
)
abline(h = 1)
```

The scree plot makes a reasonably convincing case for 6 components, as the slope falls off substantially after the fifth.

## Run PCA

```{r}
#| label: pca_table_wrangle
#| output: false
pca_tables <- map(pca_outs, ~ {
  .x$loadings %>% 
    unclass() %>% 
    as.data.frame() %>% 
    select(order(colnames(.))) %>%
    mutate(
      across(everything(), ~ round(.x, 3)),
      across(everything(), ~ case_when(
        .x < 0.20 ~ '',
        .x >= 0.20 & .x < 0.32 ~ '.',
        .x >= 0.32 ~ as.character(.x),
        .default = NA
      ))
    ) %>% 
    rownames_to_column() %>% 
    rename(indicator = 1) %>% 
    mutate(
      dimension = framework$dimension[match(indicator, framework$indicator)]
    ) %>% 
    select(indicator, dimension, everything())
})
get_str(pca_tables)

# Save it for preso
saveRDS(pca_tables, 'preso/data/pca_tables.rds')
```

```{r}
#| label: pca_reactable
#| class: centered
get_reactable(
  pca_tables$Promax
)
```

Note that we are using the promax rotation here as it seemed most interpretable, but we have created and saved all the other available oblique rotations as well. 

It looks like our economics indicators are quite scattered, but the environment indicators mostly stick to components 3 and 4. Health is quite well centered on component 3, although the "physical health tbd" indicator has meaningful loadings on three components. Production and social are rather scattered, and it is also noteworthy that participatory governance is associated with three components as well.
