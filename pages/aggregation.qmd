---
title: "Metric Aggregation"
format:
  html:
    fig-dpi: 200
warnings: false
---

# Introduction

Exploring methods of aggregating data into index and dimension scores. To Add:

- Primer on methods, cite [@oecdHandbookConstructingComposite2008]
- Examples
  - cite Schneider [@schneider2023StateFoodSystems]
    - rank order comparisons only
    - compare to global weighted means by groups based on GDP
    - min max scaling to show distance from global groups
  - cite Bene et al 2019 [@bene2019GlobalMapIndicators]
    - Box cox for most skewed indicators (skew > 2)
    - then min max 
    - geometric means for enviro and economic dimensions
    - arithmetic means for social and food dimensions
    - geometric mean for combining all four dimensions into one
  - cite Nicoletti [@nicolettiSummaryIndicatorsProduct2000]
    - Use normaliaed square loadings (indicator weights) to weight each indicator
  - cite Gomez Limon and Sanchez [@gomez-limon2010EmpiricalEvaluationAgricultural]
    - min max normalization
    - Aggregation - compared several different methods - mostly correlate, no big differences
      - weighted sum of indicators
      - product of weighted indicators
      - muilticriteria function based on distance to ideal point
    - Weighting - did both PCA and analytic hierarchy process
    - Validation (identifying important factors) - double censored tobit - index as dependent, indicators as independent
  - cite demelash and aremu [@adamudemelash2024MeasuringFoodSystem]
    - Normalization - distance to reference
      - refernce determined by quartile analysis
      - not affected by outliers, extreme values
    - Weighting - equal
    - Aggregation - linear
    - Additive method for indicators within dimensions
    - Geometric means for aggregate scores across four dimensions


```{r}
#| label: prep
#| echo: false
source('dev/get_setup.R')
source('dev/get_aggregations.R')
get_setup()
```

# Imputation

First, check how much missing data there are. If it is within reason, use missForest algorithm to impute missing data [@stekhovenMissForestNonparametricMissing2012a]. This is particularly good at handling MAR data, and does a decent job at handling MNAR data and non-linear relationships as well. If less than 5% of data are missing, just about any method for handling it is reasonable, even listwise deletion [@beaujean2013].

```{r}
#| label: imputation
#| output: false
pacman::p_load(
  missForest,
  tibble,
  dplyr
)

metrics_df <- readRDS('data/metrics_df.rds')
get_str(metrics_df)

# Check for missing data
skimr::skim(metrics_df)
mis_dat <- sum(is.na(metrics_df))/(nrow(metrics_df)*(ncol(metrics_df) - 1)) * 100 
mis_dat <- round(mis_dat, 3)

# Change fips from column to rowname so we can impute without losing it
metrics_df <- metrics_df %>% 
  column_to_rownames('fips')
get_str(metrics_df)

# Impute missing variables
set.seed(42)
mf_out <- metrics_df %>%
  missForest(
    ntree = 200,
    mtry = 10,
    verbose = FALSE,
    variablewise = FALSE
  )
# get_str(mf_out)

# Extract OOB error
(oob <- mf_out$OOBerror)

# Check missing again
skimr::skim(mf_out$ximp)
# Looks good

# Save just imputed data
imp_dat <- mf_out$ximp
```

We had `{r} mis_dat`% missing data, which is rather little, and gives us flexibility in handling it. The Out-of-Bag (OOB) error, quantified by the normalized residual mean squared error (NRMSE) the missForest imputation algorithm was `r round(oob, 3)`.

# Normalization

We are normalizing our data using three methods: min-max, Box-Cox, and Z-scores. (We might also consider Winsorizing at some point.) Results will be saved to a list of three normalized datasets so we can compare outcomes of each one and see what the consequences are.

**Min Max** [@oecdHandbookConstructingComposite2008]

Min-maxing scales all the data from 0 to 1 by subtracting the minimum value of each variable from all cases and dividing by the range of all cases in the variable. It is rather intuitive, as 1 is the best score, and 0 is the worst. This is a linear transformation, so the relationships between the values should not change.

\begin{equation}
I^t_qc = \frac{x^t_qc - min_c(x^{t_0}_q)}{max_c(x^{t_0}_q)-min_c(x^{t_0}_q)}
\end{equation}

Where $x^t_qc$ is the metric $q$ for state $c$ at time $t$. 

**Z-Scores** [@oecdHandbookConstructingComposite2008]

Z-scores are stardized to have a mean of 0 and a standard deviation of 1. Larger numbers are better, but there are no caps on the highest or lowest values. A value of 2 would mean that it is 2 standard deviations greater than the mean. Again, this is a linear transformation, so relationships between variables should not change.  

\begin{equation}
I^t_{qc} = \frac{x^t_{qc}-x^t_{qc=\overline{c}}}{\sigma^t_{qc=\overline{c}}}
\end{equation}

Where $x^t_qc$ is the metric $q$ for state $c$ at time $t$.

**Box Cox** [@bickel1981]

Box-Cox transformations are non-linear transformations that use an optimal value of lambda to make the distribution as normal as possible. This has some strengths in that the data are easier to work with in further analyses. It also effectively pulls outliers inward toward the center of the distribution. However, it also changes relationships between the variables, so it will distort any bivariate correlations.

\begin{equation}
{\rm For}\ \lambda\neq0,\ f\lambda(x) = (sign(x)|x|^\lambda-1)/\lambda
\end{equation}

\begin{equation}
{\rm For}\ \lambda = 0,\ f_0(x) = log(x)
\end{equation}

**Rank Order** 

**Winsorization**


```{r}
#| label: normalization
#| output: false
pacman::p_load(
  forecast,
  DescTools,
  purrr
)

# List of results
normed <- list()
get_str(imp_dat)

# Z scores
normed$zscore <- imp_dat %>% 
  mutate(across(everything(), ~ as.numeric(scale(.x, scale = TRUE, center = TRUE))))

# Min Max
min_max <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}
normed$minmax <- imp_dat %>% 
  mutate(across(everything(), min_max))

# Box Cox. Adding 1 as constant to remove zeroes
normed$boxcox <- imp_dat %>% 
  mutate(across(everything(), ~ forecast::BoxCox(.x + 1, lambda = 'auto')))

# Rank order from lowest to highest value for each var. We are coding this such
# that higher ranks are better. So 51 should have the highest/best value and
# rank 1 should have the worst.
normed$rank <- map(names(imp_dat), \(col_name) {
  imp_dat %>% 
    rownames_to_column('fips') %>% 
    select(fips, col_name) %>% 
    mutate(!!sym(col_name) := dense_rank(.data[[col_name]]))
}) %>% 
  reduce(full_join) %>% 
  column_to_rownames('fips')
get_str(normed$rank)
# get_str(normed$rank[[1]])
# normed$rank[[1]] %>% arrange(unemploymentRate)

# Winsorization
normed$winsor <- imp_dat %>% 
  mutate(across(everything(), Winsorize))

# Check
map(normed, get_str)

# Save this for later
saveRDS(normed, 'data/normalized_metrics_df.rds')
```

# Directional Values

Here, we are assuming that each metric has a direction that is more sustainable than the opposite. Either more of it is better, or less of it is better. This is rather problematic in that just about any metric becomes negative with too much or too little of it. What might make more sense in the long run would be to consult the expertise of our teams and develop targets or acceptable ranges for some metrics once they are settled. Still, just about every sustainability indicator framework does some variation of this one-way value system [@schneider2023StateFoodSystems; @bene2019GlobalMapIndicators; @nicolettiSummaryIndicatorsProduct2000; @jacobi2020NewUnderstandingEvaluation; @gomez-limon2010EmpiricalEvaluationAgricultural].

Alas, for now we will invert variables in each of the transformed datasets as necessary so that larger numbers are more sustainable, and smaller numbers are less sustainable. The table below shows this assignment in the `desirable` column. For couple of variables (vacancy rate and animal sales as a percentage of all agricultural sales) I was not comfortable assigning one direction as better than the other, so I have removed them from the refined framework.

```{r}
#| label: directional_values
pacman::p_load(
  reactable,
  purrr
)
source('dev/get_reactable.R')

# map(normed, get_str)
# (names <- names(normed[[1]]))

# Higher numbers should be better. Reverse metrics that are the opposite, 
# where lower numbers are better. Only listing reverse here - metrics are 
# implicitly better with larger numbers otherwise.
reverse <- c(
  'unemploymentRate',
  'gini',
  'lowBirthweight',
  'teenBirths',
  'uninsured',
  'incomeInequality',
  'childrenInSingleParentHouseholds',
  'injuryDeaths',
  'airPollutionParticulateMatter',
  'drinkingWaterViolations',
  'severeHousingProblems',
  'prematureAgeAdjustedMortality',
  'infantMortality',
  'frequentPhysicalDistress',
  'frequentMentalDistress',
  'diabetesPrevalence',
  'hivPrevalence',
  'limitedAccessToHealthyFoods',
  'drugOverdoseDeaths',
  'disconnectedYouth',
  'residentialSegregationBlackWhite',
  'suicides',
  'motorVehicleCrashDeaths',
  'severeHousingCostBurden',
  'schoolSegregation',
  'childCareCostBurden',
  'wicPercEligible', # Iffy on this one
  'droughtMeanPercArea',
  'pctAtRiskAnimalSpp',
  'pctAtRiskPlantSpp',
  'pctAtRiskBeeSpp',
  'pctAtRiskOrchidSpp',
  'pctAtRiskEcosystems',
  'expChemicalPct',
  'ageProducers', # Could be better to use age diversity?
  'waterIrrSrcOffFarmExp',
  'waterIrrSrcOffFarmExpPerAcreFt',
  'CH4FromAg',
  'N2OFromAg',
  'CO2FromAg',
  'propAreaFsaSecDisasters',
  'totalCapConsNoDwellings',
  'totalIntExpRealEstateNoDwellings',
  'totalIncomeInsuranceIndemnities',
  'totalIncomeInsuranceIndemnitiesFederal',
  'totalValueEmergPayments',
  'totalValueOtherAdHocEmergPayments',
  'totalValueDairyMarginProtPayments',
  'totalValueAllLossCoveragePayments',
  'totalValueAgRiskCoveragePayments',
  'totalCapExpBldgsLandNoDwellings'
)

# Iffy: landValPF, landValPerAcre - in good column for now, but unclear
# indemnities and emergency payments - in bad column for now, but more access
# coud be good?

# Some are unclear - without clear direction, better to remove:
remove <- c(
  'vacancyRate',
  'salesAnimalPctSales',
  'expHiredLaborPercOpExp',
  'acresPF',
  'medianAcresPF',
  'importsTopFive'
)

## Remove the unclear ones from all three datasets
# Then for each transformation, flip values in a way that makes sense
# zscore: multiple by -1, easy
# minmax: 1 - x, easy
# rank: nrow - x, easy
# boxcox and winsor: trickier. want to just reverse the distribution. 
#   max(x) - x + min(x)
# Could we have just done this in the beginning, before normalization? Maybe
out <- imap(normed, \(df, method) {
  df %>% 
    select(-matches(remove)) %>% 
    mutate(across(all_of(reverse), ~ case_when(
      method == 'zscore' ~ .x * -1,
      method == 'minmax' ~ 1 - .x,
      method %in% c('boxcox', 'winsor') ~ max(.x) - .x + min(.x),
      method == 'rank' ~ max(.x) - .x + 1
    )))
})
# map(out, get_str)
# map(normed, get_str)

# Compare
# checklist <- list(normed, out)
# map(checklist, ~ .x$rank[[2]])


# Use the table from refined metrics here instead of making it again



## Show table of which metrics were set in which direction
sm_data <- readRDS('data/sm_data.rds')
meta <- sm_data$metadata

# Reactable table showing var, metric, source, and direction
table <- meta %>% 
  dplyr::filter(variable_name %in% names(imp_dat)) %>% 
  mutate(desirable = case_when(
    variable_name %in% reverse ~ 'Lower',
    variable_name %in% remove ~ 'Removed',
    .default = 'Higher'
  )) %>% 
  select(
    metric, 
    variable_name, 
    dimension,
    index,
    indicator,
    desirable, 
    definition, 
    source
  )

# Save this desirable direction table for preso
saveRDS(table, 'preso/data/desirable_directions_table.rds')
  
# Make reactable table
table %>% 
  get_reactable(
    defaultPageSize = 5,
    columns = list(
      'definition' = colDef(
        minWidth = 150
      ),
      'source' = colDef(
        minWidth = 150
      )
    )
  )

```

# Aggregation

Here we are combining values in each indicator, index, and dimension using both arithmetic and geometric means [@oecdHandbookConstructingComposite2008]. Arithmetic means are fully compensable, in that a strong score in one area can make up for a weak score in another. Geometric means are only somewhat compensable - it effectively applies a penalty for unbalanced scores.

We might also consider PCA here, as we have done with the preliminary dimension metrics previously. But the n:p ratio is not in our favor for PCA as we have more metrics than states. Will revisit this, perhaps by splitting it up into dimensions again rather than trying the whole framework at once, or possible using a sparse PCA procedure that incorporates variable selection.

We will end up with 10 iterations of our data (5 normalization methods \* 2 aggregation methods).

Indicator aggregation:

```{r}
#| label: indicator_aggregation
#| output: false
# We need to attach these back to framework from metadata
# Filter frame from earlier down to our current metrics
frame <- readRDS('data/frame.rds')
filtered_frame <- frame %>% 
  dplyr::filter(variable_name %in% names(normed[[1]])) %>% 
  dplyr::select(variable_name, indicator, index, dimension)
get_str(filtered_frame)

# Save this for later - use in regression and variable selection 
saveRDS(filtered_frame, 'data/filtered_frame.rds')

# Make a list where we hold scores for indicators, indices, and dimensions
scores <- list()

# Function for geometric mean
geometric_mean <- function(x, na.rm = TRUE){
  exp(sum(log(x[x > 0]), na.rm = na.rm) / length(x))
}

# Get indicator scores across all three normalization methods
indicator_scores <- map(normed, \(df) {
  
  # For each df, calculate indicator means
  indicators_out <- map(unique(filtered_frame$indicator), \(ind) {
  
    # Column name based on indicator
    ind_snake <- ind
    
    # Split into groups by indicator, with one or more metrics each
    variables <- filtered_frame %>% 
      dplyr::filter(indicator == ind) %>% 
      pull(variable_name) %>% 
      unique()
    indicator_metrics <- df %>% 
      select(all_of(variables))
    
    # Get arithmetic and geo means for each indicator
    dfs <- list()
    dfs$arithmetic <- indicator_metrics %>%
      rowwise() %>%
      mutate(
        !!sym(ind_snake) := mean(c_across(everything())),
      ) %>%
      select(!!sym(ind_snake))
    dfs$geometric <- indicator_metrics %>% 
      rowwise() %>% 
      mutate(
        !!sym(ind_snake) := geometric_mean(c_across(everything())),
      ) %>%
      select(!!sym(ind_snake))
    return(dfs) 
  })
  
  # Rearrange so we put each aggregation method (arith, geo) together
  norm_out <- list()
  norm_out$arithmetic <- map(indicators_out, ~ {
    .x[grep("arithmetic", names(.x))]
  }) %>% 
    bind_cols()
  norm_out$geometric <- map(indicators_out, ~ {
    .x[grep("geometric", names(.x))]
  }) %>% 
    bind_cols()
  return(norm_out) 
})
  
get_str(indicator_scores, 3)
get_str(indicator_scores, 4)

# Test function
# test <- get_agg_indicators(normed, filtered_frame)
# identical(indicator_scores, test)
```

Index aggregation:

```{r}
#| label: test_pca_aggregation
get_str(indicator_scores)

```

```{r}
#| label: index_aggregation
#| output: false
# For each set of indicator scores, calculate index scores
# get_str(indicator_scores, 4)
indices <- unique(filtered_frame$index)

# Choose aggregation function based on agg_type
agg_function <- function(x, agg_type) {
   if (agg_type == 'geometric') {
    geometric_mean(x)
  } else if (agg_type == 'arithmetic') {
    mean(x)
  }
}

index_scores <- map(indicator_scores, \(norm_type) {
  imap(norm_type, \(agg_df, agg_type) {
    map(indices, \(index_) {
      # Get names of indicators for this index
      index_indicators <- filtered_frame %>% 
        filter(index == index_) %>% 
        pull(indicator) %>% 
        unique()
      # Get DF of indicators for this index
      index_indicator_df <- agg_df %>% 
        select(all_of(index_indicators))
      # Get arithmetic or geometric mean, based on agg_type
      index_indicator_df %>% 
        rowwise() %>% 
        # mutate(mean = across(everything(), agg_function(agg_type)))
        mutate(!!sym(index_) := agg_function(c_across(everything()), agg_type)) %>% 
        select(!!sym(index_))
    }) %>% 
      bind_cols()
  })
})
get_str(index_scores, 4)

# Test function
# test_indices <- get_agg_indices(indicator_scores, frame)
# identical(index_scores, test_indices)
```

Dimension aggregation:

```{r}
#| label: dimension_aggregation
#| output: false
get_str(index_scores, 4)

# Same process for dimensions
dimensions <- unique(filtered_frame$dimension)

dimension_scores <- map(index_scores, \(norm_type) {
  imap(norm_type, \(agg_df, agg_type) {
    map(dimensions, \(dimension_) {
      # Get names of indices for this dimension
      dimension_indices <- filtered_frame %>% 
        filter(dimension == dimension_) %>% 
        pull(index) %>% 
        unique()
      # Get DF of indice for this dimension
      dimension_index_df <- agg_df %>% 
        select(all_of(dimension_indices))
      # Get arithmetic or geometric mean, based on agg_type
      dimension_index_df %>% 
        rowwise() %>% 
        mutate(!!sym(dimension_) := agg_function(
          c_across(everything()), 
          agg_type
        )) %>% 
        select(!!sym(dimension_))
    }) %>% 
      bind_cols()
  })
})
get_str(dimension_scores, 4)

# Test function
# test_dimensions <- get_agg_dimensions(index_scores, filtered_frame)
# identical(dimension_scores, test_dimensions)
```

# Wrangle

Here, we organize arithmetic and geometric means for each level of the framework (indicator, index, dimension) in a way that is easier to work with. We also add means and medians for all US states as well as New England states that we can use as points of comparison.

```{r}
#| label: wrangle
#| output: false
pacman::p_load(
  purrr
)

get_str(indicator_scores, 4)
get_str(index_scores, 4)
get_str(dimension_scores, 4)

# Want to end up with 6 lists: 3 norm types * 2 mean types
# Put them all together in one list to work with
all_scores <- mget(c(
  'indicator_scores',
  'index_scores',
  'dimension_scores'
))
get_str(all_scores, 3)

# Function to pull out the pieces we want
# Also put state names back in as a column and with real names, not codes
get_output <- function(norm_type, agg_type) {
  # Get list of each df (dimension, index, indicator) for combo
  dfs <- all_scores %>% 
    map(\(level) level[[norm_type]]) %>% 
    map(\(norm) norm[[agg_type]])
  # Get state back into a proper column for each df
  out <- map(dfs, ~ {
    .x %>% 
      # Note that we are binding fips back in - this is hinky, note to fix
      bind_cols(
        metrics_df %>% 
          rownames_to_column('fips') %>% 
          dplyr::select(fips)
      ) %>% 
      left_join(
        dplyr::select(sm_data$state_key, state, state_code),
        by = join_by(fips == state_code) 
      ) %>% 
      dplyr::select(-fips)
  })
  return(out)
}

# All combinations, also a name
combos <- expand.grid(
  names(all_scores[[1]]),
  c('arithmetic', 'geometric')
) %>% 
  mutate(name = paste0(Var1, '_', Var2))

# Map to pull them all out
scores <- map2(combos[[1]], combos[[2]], ~ {
  get_output(.x, .y)
}) %>% 
  setNames(c(combos$name))
get_str(scores, 4)
get_str(scores, 3)

# Test function
# test_organized <- get_organized_scores(all_scores, sm_data$state_key, metrics_df)
# identical(scores, test_organized)


## Add medians for New England states and US
final_scores <- map(scores, \(method) {
  map(method, \(level) {
    
    # Mean of every US state and DC
    us_means <- level %>%
      dplyr::select(-state) %>% 
      colMeans() %>% 
      as.list()
    us_means$state <- 'US_mean'
    
    # Median of every US state and DC
    us_medians <- level %>% 
      dplyr::select(-state) %>% 
      map_dbl(median) %>% 
      as.list()
    us_medians$state <- 'US_median'
    
    # Mean of just New England states
    ne_means <- level %>% 
      dplyr::filter(state %in% c('VT', 'NH', 'ME', 'MA', 'CT', 'RI')) %>% 
      dplyr::select(-state) %>% 
      colMeans() %>% 
      as.list()
    ne_means$state <- 'NE_mean'
     
    # Median of just New England states
    ne_medians <- level %>% 
      dplyr::filter(state %in% c('VT', 'NH', 'ME', 'MA', 'CT', 'RI')) %>% 
      dplyr::select(-state) %>% 
      map_dbl(median) %>% 
      as.list()
    ne_medians$state <- 'NE_median'
    
    # Return the level + US + NewEng means
    level %>% 
      bind_rows(us_means) %>% 
      bind_rows(us_medians) %>% 
      bind_rows(ne_means) %>% 
      bind_rows(ne_medians)
  })
})
get_str(final_scores, 3)
get_str(final_scores, 4)

# Test function
# test_final_scores <- get_groupings(scores)
# get_str(test_final_scores)
# get_str(test_final_scores, 4)
# identical(final_scores, test_final_scores)
# Not same because we added NE medians. That's okay.

# Save this for use elsewhere
saveRDS(final_scores, 'data/state_score_iterations.rds')
```

This gives us a list of 10 elements, one for each combination of normalization method and aggregation method. Each element has three data frames, one for indicator, index, and dimension. Now we can compare these 6 outputs to see how the methodological differences affect scores and ranks.

# References
