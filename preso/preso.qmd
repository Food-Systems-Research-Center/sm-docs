---
title: "Sustainability Metrics Secondary Data"
author: "Chris Donovan"
institute: "Food Systems Research Center"
date: '2025-03-19'
format:
  revealjs:
    embed-resources: true
    incremental: false
    theme: [serif, preso.scss]
    transition: fade
    scrollable: true
    revealjs-plugins:
      - revealjs-text-resizer
editor: 
  markdown: 
    wrap: 72
bibliography: ../fsrc.bib
citations-hover: true
citeproc: true
---

```{r}
#| label: prep
#| include: false
pacman::p_load(
  ggplot2,
  ggpubr,
  plotly,
  forcats,
  reactable,
  htmltools,
  stringr,
  Hmisc,
  reshape,
  performance,
  AER,
  sandwich,
  sjPlot,
  caret,
  ranger,
  glmnet,
  conflicted,
  knitr,
  kableExtra,
  sf,
  leaflet,
  ggraph,
  igraph,
  readr,
  RColorBrewer,
  paletteer,
  fmsb,
  purrr
)

source('dev/get_reactable.R')
source('dev/get_vt_spiders.R')

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter(),
  tidyr::expand(),
  .quiet = TRUE
)
```

## Introduction {.smaller}

:::: {.columns}

::: {.column width = '40%'}

-   Secondary data goals:
    -   Identify existing data and gaps
    -   Explore methods of aggregating data
-   Goals for today:
    -   Share methods
    -   Share preliminary findings
    -   Feedback and discussion
-   Guiding topics:
    -   How well do the data represesent the system?
    -   Normalization, aggregation, and values
    -   Where and how do we incorporate qualitative data?
    -   Informing the next RFP
    
:::

::: {.column width = '60%'}

![Intervale Farm, Sally McCay, UVM Photo](../images/intervale_small.png){fig-align="center" width=90% fig-alt="A picture of a field at Intervale Farm."}

:::

::::

::: notes
The point is to take stock of existing data, use primary research 
:::

## Framework {.smaller}

::: {.panel-tabset}

### Economics

```{r}
#| fig-height: 8
#| fig-width: 10
#| fig-align: center
#| out-width: 75%
plots <- readRDS('preso/plots/frameworks.rds')
plots$economics
```

### Environment

```{r}
#| fig-height: 8
#| fig-width: 10
#| fig-align: center
#| out-width: 75%
plots$environment
```

### Health

```{r}
#| fig-height: 11
#| fig-width: 10
#| fig-align: center
#| out-width: 75%
plots$health
```

### Production

```{r}
#| fig-height: 7
#| fig-width: 10
#| fig-align: center
#| out-width: 75%
plots$production
```

### Social

```{r}
#| fig-height: 8
#| fig-width: 10
#| fig-align: center
#| out-width: 75%
plots$social
```
:::

::: notes
-   NONE is a placeholder for when I don't have a metric there
-   All ears for more datasets if you can fill in some NONEs
:::

## Secondary Data - Refined {.smaller}

A set of 130 metrics to match the refined framework

```{r}
#| label: metadata_table_refined
metadata <- readRDS('preso/data/meta_for_table.rds')

htmltools::browsable(
  tagList(
    
    tags$div(
      style = "display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;",
      
      tags$button(
        class = "btn btn-primary",
        style = "display: flex; align-items: center; gap: 8px; padding: 8px 12px;",
        tagList(fontawesome::fa("download"), "Show/hide more columns"),
        onclick = "Reactable.setHiddenColumns('metadata_table_refined', prevColumns => {
          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []
        })"
      ),
      
      tags$button(
        class = "btn btn-primary",
        style = "display: flex; align-items: center; gap: 8px; padding: 8px 12px;",
        tagList(fontawesome::fa("download"), "Download as CSV"),
        onclick = "Reactable.downloadDataCSV('metadata_table_refined', 'sustainability_metadata.csv')"
      )
    ),
    
    reactable(
      metadata[, which(names(metadata) != 'Years')],
      sortable = TRUE,
      resizable = TRUE,
      filterable = TRUE,
      searchable = TRUE,
      pagination = TRUE,
      bordered = TRUE,
      wrap = TRUE,
      rownames = FALSE,
      onClick = 'select',
      striped = TRUE,
      pageSizeOptions = c(5, 10, 25, 50, 100),
      defaultPageSize = 5,
      showPageSizeOptions = TRUE,
      highlight = TRUE,
      style = list(fontSize = "14px"),
      compact = TRUE,
      fullWidth = TRUE,
      columns = list(
        Metric = colDef(
          minWidth = 200,
          sticky = 'left'
        ),
        'Variable Name' = colDef(
          minWidth = 150
        ),
        Definition = colDef(
          minWidth = 250
        ),
        'Latest Year' = colDef(minWidth = 75),
        Source = colDef(minWidth = 250),
        Scope = colDef(show = FALSE),
        Resolution = colDef(show = FALSE),
        Url = colDef(
          minWidth = 300,
          show = FALSE
        )
      ),
      defaultColDef = colDef(minWidth = 100),
      elementId = "metadata_table_refined",
      details = function(index) {
        div(
          style = "padding: 15px; border: 1px solid #ddd; margin: 10px 0;
             background-color: #ecf4ed; border-radius: 10px; border-color: black;
             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);",
          
          tags$h4(
            strong("Details"), 
          ),
          tags$p(
            strong('Metric Name: '), 
            as.character(metadata[index, 'Metric']),
          ),
          tags$p(
            strong('Variable Name: '), 
            as.character(metadata[index, 'Variable Name']),
          ),
          tags$p(
            strong('Definition: '), 
            as.character(metadata[index, 'Definition']),
          ),
          tags$p(
            strong('Source: '), 
            as.character(metadata[index, 'Source'])
          ),
          tags$p(
            strong('Latest Year: '), 
            as.character(metadata[index, 'Year'])
          ),
          tags$p(
            strong('All Years (cleaned, wrangled, and included): '), 
            as.character(metadata[index, 'Years'])
          ),
          tags$p(
            strong('Updates: '), 
            str_to_title(as.character(metadata[index, 'Updates']))
          ),
          tags$p(
            strong('URL: '), 
            tags$a(
              href = as.character(metadata[index, 'Url']),
              target = '_blank',
              as.character(metadata[index, 'Url'])
            )
          )
        )
      }
    )
  )
)
```

::: {.notes}

-   \~650 metrics, plus another thousand NAICS variables

Sources

-   USDA NASS
-   USDA ERS Farm Income and Wealth Statistics
-   USDA ERS Food Environment Atlas
-   USDA Farm Service Agency Distaster Assistance
-   USDA Food and Nutrition Service
-   USDA Food Safety and Inspection Service
-   University of Wisconsin
-   US Census
-   EPA State GHG Data
-   TreeMap 2016
-   NatureServe - biodiversity data

:::

## Desirable Directions {.smaller}

:::: {.columns}
::: {.column width = '30%'}

-   Official benchmarks where possible, otherwise largest value is 100%
    [@jacobi2020NewUnderstandingEvaluation]
-   Every indicator gets a good direction and bad direction
    [@schneider2023StateFoodSystems]
:::

::: {.column width = '70%'}

```{r}
desirable_table <- readRDS('preso/data/desirable_directions_table.rds')
desirable_table %>% 
  dplyr::select(
    metric,
    desirable,
    definition,
    source
  ) %>% 
  setNames(c(names(.) %>% stringr::str_to_title())) %>% 
  get_reactable(
    defaultPageSize = 5,
    columns = list(
      Metric = colDef(minWidth = 150),
      Desirable = colDef(minWidth = 100)
    )
  )
```

:::

::::

## Rescaling

::: panel-tabset
### Rank Order

**Rank Order**

-   Makes no distributional assumptions [@schneider2025]
-   Useful for comparing other transformation methods
-   Loss of information

### Winsor

**Winsorization**

-   Reduce all outliers to a percentile (95th and 5th)
-   Doesn't reward overperformance in one area
-   Used in the Environmental Performance Indicator (EPI) before scaling
    from 0 to 100 [@esty2008Pilot2006Environmental]
-   More robust than leaving keeping outliers
    [@mayerStrengthsWeaknessesCommon2008]

### Min Max

**Min Max** [@oecdHandbookConstructingComposite2008]

\begin{equation}
I^t_qc = \frac{x^t_qc - min_c(x^{t_0}_q)}{max_c(x^{t_0}_q)-min_c(x^{t_0}_q)}
\end{equation}

::: {.center}
Where $x^t_qc$ is the metric $q$ for state $c$ at time $t$.
:::

-   Scales all data from 0 to 1
-   Intuitive (0 is worst, 1 is best)
-   Linear transformation
-   [@schneider2025, @schneider2023StateFoodSystems]

### Z-Scores

**Z-Scores** [@oecdHandbookConstructingComposite2008]

\begin{equation}
I^t_{qc} = \frac{x^t_{qc}-x^t_{qc=\overline{c}}}{\sigma^t_{qc=\overline{c}}}
\end{equation}

-   Scales data to mean of 0 and standard deviation of 1
-   Larger numbers are better, but no limits
-   Linear transformation

### Box Cox

**Box Cox** [@bickel1981]

\begin{equation}
{\rm For}\ \lambda\neq0,\ f\lambda(x) = (sign(x)|x|^\lambda-1)/\lambda
\end{equation} \begin{equation}
{\rm For}\ \lambda = 0,\ f_0(x) = log(x)
\end{equation}

-   Finds an optimal value of $\lambda$ to make distribution normal
-   More tractable distribution for analysis
-   Harder to interpret
-   Non-linear transformation

### Distance*

**Distance to Target** [@oecdHandbookConstructingComposite2008]

-   Ratio of the indicator to a reference system or reference value
-   Used with official benchmarks like minimum wage [@jacobi2020NewUnderstandingEvaluation]
-   Difficult to set targets in many applications

\begin{equation}
I^t_qc = \frac{x^t_qc}{x^t_{qc=\overline{c}}}
\end{equation}

:::

## Aggregation

:::: {.columns}

::: {.column width = '40%'}

-   Arithmetic [@jacobi2020NewUnderstandingEvaluation]
-   Geometric:

\begin{equation}
\sqrt[n]{x_1 * x_2 * ... * x_n}
\end{equation}

-   Compensatory and non compensatory
-   Some did both and compared, came out similar
    [@gomez-limon2010EmpiricalEvaluationAgricultural]
    
:::

::: {.column width = '60%'}

-   images here?
  
:::

::::

## Indicator Distributions

An example of indicator distributions with the Min Max + geometric means
methods

![](plots/indic_dists.png){height="1500"}

## Comparisons {.smaller}

::: panel-tabset
### Rank Order

```{r}
#| fig-width: 10
#| fig-height: 5
# source('dev/get_vt_spiders.R')
dat <- readRDS('data/state_score_iterations.rds')
get_vt_spiders(dat, 'rank')
```

### Winsorization

```{r}
#| fig-width: 10
#| fig-height: 5
get_vt_spiders(dat, 'winsor')
```

### Min Max

```{r}
#| fig-width: 10
#| fig-height: 5
get_vt_spiders(dat, 'minmax')
```

### Z-Score

```{r}
#| fig-width: 10
#| fig-height: 5
get_vt_spiders(dat, 'zscore')
```

### Box Cox

```{r}
#| fig-width: 10
#| fig-height: 5
get_vt_spiders(dat, 'boxcox')
```
:::

## Dimension Score Maps {.smaller}

Using Min Max normalization and geometric aggregation

::: panel-tabset
```{r}
#| label: map
dim_scores <- readRDS('data/minmax_geo_all_levels.rds')
state_key <- readRDS('data/state_key.rds')
dim_scores <- dim_scores %>% 
  as.data.frame() %>% 
  dplyr::select(state, starts_with('dimen')) %>% 
  setNames(c(names(.) %>% str_remove('dimen_')))
# get_str(dim_scores)

# Polygons for states
states <- readRDS('preso/data/state_polygons.rds')

# Combine dim scores with state key to get fips
map_dat <- left_join(
  dim_scores, 
  select(state_key, state, fips = state_code)
) %>%
  left_join(states) %>% 
  select(state:name, geometry) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>% 
  st_as_sf()

get_leaflet <- function(map_dat, dimension) {
  
  # Two palettes, one reversed, so we can swap legend order
  pal1 <- colorNumeric(
    palette = rev(brewer.pal(n = 11, name = 'YlGn')),
    domain = map_dat[[dimension]],
    reverse = TRUE
  )
  pal2 <- colorNumeric(
    palette = rev(brewer.pal(n = 11, name = 'YlGn')),
    domain = map_dat[[dimension]]
  )

  # Create leaflet map
  leaflet(map_dat) %>%
    # addProviderTiles(providers$Stadia.AlidadeSmooth) %>% 
    addTiles() %>% 
    addPolygons(
      fillColor = ~pal1(map_dat[[dimension]]),
      color = 'black',
      weight = 1.5,
      fillOpacity = 0.8,
      popup = ~paste0(
        "<strong>State:</strong> ", map_dat$name, "<br>",
        "<strong>Economics:</strong> ", map_dat$economics, "<br>",
        "<strong>Environment:</strong> ", map_dat$environment, "<br>",
        "<strong>Health:</strong> ", map_dat$health, "<br>",
        "<strong>Production:</strong> ", map_dat$production, "<br>",
        "<strong>Social:</strong> ", map_dat$social
      )
    ) %>%
    addLegend(
      pal = pal2,
      values = map_dat[[dimension]],
      title = str_to_title(dimension),
      position = "bottomright",
      labFormat = labelFormat(transform = \(x) sort(x, decreasing = TRUE)),
      opacity = 0.8
    ) %>%
    setView(lng = -98.583333, lat = 39.833333, zoom = 4)
}
```

### Economics

```{r}
get_leaflet(map_dat, 'economics')
```

### Environment

```{r}
get_leaflet(map_dat, 'environment')
```

### Health

```{r}
get_leaflet(map_dat, 'health')
```

### Production

```{r}
get_leaflet(map_dat, 'production')
```

### Social

```{r}
get_leaflet(map_dat, 'social')
```
:::

::: {.notes}

* Note: cannot compare across dimensions
* Env:
  + Scaling, everything looks good compared to NV
  + Bias toward biodiverse areas with denser population?
* Prod: California skews everything
* Social: Arkansas skews everything

:::

## Indicator Correlations {.smaller}

::: panel-tabset
### Correlation Matrix

Min Max geometric aggregation

```{r}
# mat <- readRDS('preso/data/correlation_data.rds')
# cor <- rcorr(mat, type = 'pearson')
# cor_r <- melt(cor$r) %>% 
#   setNames(c('var_1', 'var_2', 'value'))
# cor_p <- melt(cor$P)
# p.value <- cor_p$value
# 
# plot <- cor_r %>% 
#   ggplot(aes(var_1, var_2, fill = value, text = paste0(
#     'Var 1: ', var_1, '\n',
#     'Var 2: ', var_2, '\n',
#     'Correlation: ', format(round(value, 3), nsmall = 3), '\n',
#     'P-Value: ', format(round(p.value, 3), nsmall = 3)
#   ))) + 
#   geom_tile() + 
#   scale_fill_gradient2(
#     low = "#762a83", 
#     mid = "white", 
#     high = "#1b7837", 
#     midpoint = 0
#   ) +
#   theme(axis.text.x = element_text(hjust = 1, angle = 45)) +
#   labs(
#     x = NULL,
#     y = NULL,
#     fill = 'Correlation'
#   )
#   
# ggplotly(
#   plot, 
#   tooltip = 'text',
#   width = 850,
#   height = 650
# )
```

<iframe src="plots/correlation_plotly.html" width="100%" height="650"></iframe>

### Influential Indicators

```{r}
#| class: centered
cor_table <- readRDS('preso/data/correlation_counts.rds')
cor_table %>% 
  get_reactable(
    fullWidth = FALSE,
    columns = list(
      Index = colDef(minWidth = 150),
      Indicator = colDef(minWidth = 150)
    )
  )
```
:::

::: notes
-   Highly correlating indicators from different dimensions are a
    problem (double counting)
:::

## Validation: Regression {.smaller}

:::::: panel-tabset
### Food Insecurity

Food Insecurity Index (UW Population Health Institute 2024)

```{r}
#| label: val1_food_insecurity
#| include: false
source('dev/get_stargazer.R')
dat <- readRDS('data/metrics_df_with_vals_and_covars.rds')
lm1 <- lm(
  foodInsecurity ~ economics + environment + health + production + social,
  data = dat
)
get_stargazer(
  lm1, 
  dep_var = 'Food Insecurity Index', 
  type = 'html', 
  out = 'preso/data/val1_food_insecurity.html',
  single_row = FALSE
)
```

::: flex-container
<iframe src="data/val1_food_insecurity.html" width="100%" height="600" style="border: none;">

</iframe>
:::

### Life Expectancy

Life Expectancy (UW Population Health Institute 2024)

```{r}
#| label: val2_life_exp
#| include: false
lm2 <- lm(
  lifeExpectancy ~ economics + environment + health + production + social,
  data = dat
)
life_exp_vcov <- vcovHC(lm2, type = 'HC3')
get_stargazer(
  lm2, 
  dep_var = 'Life Expectancy', 
  robust = TRUE,
  type = 'html',
  out = 'preso/data/val2.html',
  single_row = FALSE
)
```

::: flex-container
<iframe src="data/val2.html" width="100%" height="600" style="border: none;">

</iframe>
:::

### Food Environment Index

Food Environment Index (UW Population Health Institute 2024)

GLMnet variable importance:

```{r}
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
importance <- readRDS('preso/plots/val3_food_env_glmnet_importance.rds')
plot(importance)
```

Random forest variable importance:

```{r}
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
importance <- readRDS('preso/plots/val3_rf_importance.rds')
plot(importance)
```

::::::

::: notes
-   Food Environment Index: 0 (worst) 10 (best). Distance to grocery,
    cost of health diet.
-   Happiness (WalletHub):
    -   emotional and physical wellbeing (health index, depression,
        alcohol use disorder, adequate sleep rate...)
    -   Work environment (work hours, commute time, income,
        unemployment...)
    -   Community and environment (ideal weather, leisure time, safety,
        volunteer rate)
        
:::

## Validation: PCA {.smaller}

::: columns
::: {.column width = '30%'}

-   EXPLAIN WHAT IT IS
-   Factor extraction:
    -   Parallel Analysis (PA) suggests 5 components
    -   Velicer MAP suggests 6 
    -   VSS suggests 2 or 3
-   Key to loadings:
    -   x \< 0.2 \~ ''
    -   x \< 0.32 \~ '.'
    -   x \>= 0.32 \~ x
    
:::

::: {.column width = '70%'}

::: panel-tabset
### Scree Plot

![](plots/scree.png){fig-align="center" width="90%"}

### Promax

```{r}
pca_tables <- readRDS('preso/data/pca_tables.rds')

get_pca_table <- function(table) {
  get_reactable(
    table,
    pagination = FALSE,
    defaultPageSize = 50,
    showPageSizeOptions = FALSE,
    fullWidth = TRUE,
    defaultColDef = colDef(minWidth = 50),
    columns = list(
      indicator = colDef(minWidth = 200),
      dimension = colDef(minWidth = 100)
    )
  )  
}

get_pca_table(pca_tables$promax)
```

### Simplimax

```{r}
get_pca_table(pca_tables$simplimax)
```

### Oblimin

```{r}
get_pca_table(pca_tables$oblimin)
```

### Cluster

```{r}
get_pca_table(pca_tables$cluster)
```

:::

:::

::::

::: notes

* Might be better off with 6 components - sign indicators are not cohesive
* PA: randomize rows, do PCA. Keep PCs that explain significantly more variance than expected by chance
* MAP: get average squared partial correlations for each PC. Keep PCs that lead to lowest average squared partial correlation
* VSS: compare fit of simplified model to original correlations. VSS = 1-sumsquares(r*)/sumsquares(r)Peaks at optimal (most interpretable) number of factors.
* Promax is best interpretation, but not great

:::

## Metric Uncertainty {.smaller}

:::: {.columns}

::: {.column width = '30%'}

* notes here
* is this even interesting?

:::

::: {.column width = '70%'}

::: {.panel-tabset}

### Dimension Scores 

```{r}
#| fig-align: center
uncertainty_plots <- readRDS('preso/plots/uncertainty_plots.rds')
ggplotly(
  uncertainty_plots$sd,
  width = 700,
  height = 400,
  tooltip = 'text'
)
```

### Standard Deviations

```{r}
#| fig-align: center
ggplotly(
  uncertainty_plots$sd,
  width = 700,
  height = 400,
  tooltip = 'text'
)
```

:::

:::

::::

::: {.notes}

* Scores stay about stable 
* SD only goes down for health and economics - both have an indicator with many metrics
* Not sure this is anything

:::

## Sensitivity by Dimension {.smaller}

:::: {.columns}

::: {.column width = '40%'}

-   Sample from uncertain inputs
    [@oecdHandbookConstructingComposite2008]
    -   Rescaling methods (5)
    -   Aggregation methods (2)
    -   Leave out one indicator (39)
    -   = 390 iterations
-   Higher ranks are desirable
-   Some dimensions are quite unstable (Economics)
-   Some are quite stable (Health)

:::

::: {.column width = '60%'}

::: panel-tabset
### Economics

Distribution for Vermont

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
dim_sens_plots <- readRDS('preso/plots/dimension_sensitivity_plots.rds')
dim_sens_plots$economics
```

### Environment

Distribution for Vermont

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
dim_sens_plots$environment
```

### Health

Distribution for Vermont

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
dim_sens_plots$health
```

### Production

Distribution for Vermont

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
dim_sens_plots$production
```

### Social

Distribution for Vermont

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
dim_sens_plots$social
```
:::

:::

::::

## Indicator Influence {.smaller}

::: columns
::: {.column width = '30%'}

-   Some points before plot
-   another point before the plot
-   some other important point
:::

::: {.column width = '70%'}

::: panel-tabset
### Economics

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
get_plotly <- function(plot) {
  ggplotly(
    plot,
    width = 700,
    height = 500,
    tooltip = 'text'
  )
}
ind_inf_plots <- readRDS('preso/plots/ind_influence_plots.rds')
get_plotly(ind_inf_plots$economics)
```

### Environment

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
get_plotly(ind_inf_plots$environment)
```

### Health

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
get_plotly(ind_inf_plots$health)
```

### Production

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
get_plotly(ind_inf_plots$production)
```

### Social

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
get_plotly(ind_inf_plots$social)
```
:::

:::

::::

## Conclusions and Discussion

-   Conclusions
    -   Gaps
    -   Stability and Sensitivity
    -   Framework complexity
    -   Influential indicators
-   Discussion
    -   How well do these data represent the system?
    -   Can we reasonably assign desirable directions to metrics and
        indicators?
    -   What are fair and interpretable methods of transformations and
        aggregation?

::: notes

* Gaps:
  + NASS stats lean toward commodity crops
  + Soil health
  + Food distribution capacity (have some of this)
  + Food loss and waste
  + Embodied Carbon
  + Carbon stocks
  + forest complexity
  + water quality
  + Water quantity
  + precarity, market health indices
  + diversity of Farm Types (this one tricky for VT)
  + nutrition
  + all of social dimension
* Sensitivity:
  + Economics, environment need to be refined
  
:::

## To Add

-   Scenario Analysis with random forest for predictions?

## References
