@article{alexander2020QualitativeDataSharing,
  title = {Qualitative Data Sharing and Synthesis for Sustainability Science},
  author = {Alexander, Steven M. and Jones, Kristal and Bennett, Nathan J. and Budden, Amber and Cox, Michael and Crosas, Merc{\`e} and Game, Edward T. and Geary, Janis and Hardy, R. Dean and Johnson, Jay T. and Karcher, Sebastian and Motzer, Nicole and Pittman, Jeremy and Randell, Heather and Silva, Julie A. and {da Silva}, Patricia Pinto and Strasser, Carly and Strawhacker, Colleen and Stuhl, Andrew and Weber, Nic},
  year = {2020},
  month = feb,
  journal = {Nature Sustainability},
  volume = {3},
  number = {2},
  pages = {81--88},
  publisher = {Nature Publishing Group},
  issn = {2398-9629},
  doi = {10.1038/s41893-019-0434-8},
  urldate = {2024-09-03},
  abstract = {Socio--environmental synthesis as a research approach contributes to broader sustainability policy and practice by reusing data from disparate disciplines in innovative ways. Synthesizing diverse data sources and types of evidence can help to better conceptualize, investigate and address increasingly complex socio--environmental problems. However, sharing qualitative data for re-use remains uncommon when compared to sharing quantitative data. We argue that qualitative data present untapped opportunities for sustainability science, and discuss practical pathways to facilitate and realize the benefits from sharing and reusing qualitative data. However, these opportunities and benefits are also hindered by practical, ethical and epistemological challenges. To address these challenges and accelerate qualitative data sharing, we outline enabling conditions and suggest actions for researchers, institutions, funders, data repository managers and publishers.},
  copyright = {2019 Springer Nature Limited},
  langid = {english},
  keywords = {Interdisciplinary studies,Research data},
  file = {C:\Users\cdonov12\Zotero\storage\LS3RK2R8\Alexander et al. - 2020 - Qualitative data sharing and synthesis for sustain.pdf}
}

@article{boettiger2017IntroductionRockerDocker,
  title = {An {{Introduction}} to {{Rocker}}: {{Docker Containers}} for {{R}}},
  shorttitle = {An {{Introduction}} to {{Rocker}}},
  author = {Boettiger, Carl and Eddelbuettel, Dirk},
  year = {2017},
  journal = {The R Journal},
  volume = {9},
  number = {2},
  pages = {527},
  issn = {2073-4859},
  doi = {10.32614/RJ-2017-065},
  urldate = {2024-09-12},
  abstract = {We describe the Rocker project, which provides a widely-used suite of Docker images with customized R environments for particular tasks. We discuss how this suite is organized, and how these tools can increase portability, scaling, reproducibility, and convenience of R users and developers.},
  langid = {english},
  file = {C:\Users\cdonov12\Zotero\storage\8PSK8QCT\Boettiger and Eddelbuettel - 2017 - An Introduction to Rocker Docker Containers for R.pdf}
}

@article{conzett2022DataverseCommunitySurvey,
  title = {Dataverse {{Community Survey}} 2022 -- {{Report}}},
  author = {Conzett, Philipp},
  year = {2022},
  month = dec,
  journal = {Septentrio Reports},
  number = {1},
  issn = {2387-4597},
  doi = {10.7557/7.6872},
  urldate = {2024-09-03},
  abstract = {This report presents some of the results from the Dataverse Community Survey 2022. The main goal of the survey was to help the Global Dataverse Community Consortium (GDCC; https://dataversecommunity.global/) and the Dataverse Project (https://dataverse.org/) decide on what actions to take to improve the Dataverse software and the larger ecosystem of integrated tools and services as well as better support community members. The results from the survey may also be of interest to other communities working on software and services for managing research data. The survey was designed to map out the current status as well as the roadmaps and priorities of Dataverse installations around the world. The main target group for participating in the survey were the people/teams responsible for operating Dataverse installations around the world. A secondary target group were people/teams at organizations that are planning to deploy or considering deploying a Dataverse installation. There were 34 existing and planned Dataverse installations participating in the survey.},
  copyright = {Copyright (c) 2022 Philipp Conzett},
  langid = {english},
  keywords = {Open Science},
  file = {C:\Users\cdonov12\Zotero\storage\265I72NN\Conzett - 2022 - Dataverse Community Survey 2022 â€“ Report.pdf}
}

@article{fenner2019DataCitationRoadmap,
  title = {A Data Citation Roadmap for Scholarly Data Repositories},
  author = {Fenner, Martin and Crosas, Merc{\`e} and Grethe, Jeffrey S. and Kennedy, David and Hermjakob, Henning and {Rocca-Serra}, Phillippe and Durand, Gustavo and Berjon, Robin and Karcher, Sebastian and Martone, Maryann and Clark, Tim},
  year = {2019},
  month = apr,
  journal = {Scientific Data},
  volume = {6},
  number = {1},
  pages = {28},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-019-0031-8},
  urldate = {2024-09-03},
  abstract = {This article presents a practical roadmap for scholarly data repositories to implement data citation in accordance with the Joint Declaration of Data Citation Principles, a synopsis and harmonization of the recommendations of major science policy bodies. The roadmap was developed by the Repositories Expert Group, as part of the Data Citation Implementation Pilot (DCIP) project, an initiative of FORCE11.org and the NIH-funded BioCADDIE (https://biocaddie.org) project. The roadmap makes 11 specific recommendations, grouped into three phases of implementation: a) required steps needed to support the Joint Declaration of Data Citation Principles, b) recommended steps that facilitate article/data publication workflows, and c) optional steps that further improve data citation support provided by data repositories. We describe the early adoption of these recommendations 18 months after they have first been published, looking specifically at implementations of machine-readable metadata on dataset landing pages.},
  copyright = {2019 The Author(s)},
  langid = {english},
  keywords = {Computational platforms and environments,Data publication and archiving,Databases},
  file = {C:\Users\cdonov12\Zotero\storage\LXVIIEEW\Fenner et al. - 2019 - A data citation roadmap for scholarly data reposit.pdf}
}

@article{king2007IntroductionDataverseNetwork,
  title = {An {{Introduction}} to the {{Dataverse Network}} as an {{Infrastructure}} for {{Data Sharing}}},
  author = {King, Gary},
  year = {2007},
  month = nov,
  journal = {Sociological Methods \& Research},
  volume = {36},
  number = {2},
  pages = {173--199},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124107306660},
  urldate = {2024-09-04},
  abstract = {The author introduces a set of integrated developments in Web application software, networking, data citation standards, and statistical methods designed to increase scholarly recognition for data contributions; to put some of the universe of data and data-sharing practices on firmer ground; and to facilitate the public distribution of persistent, authorized, and verifiable data, with powerful and easy-to-use technology, even when the data are confidential or proprietary. The goal is to solve some of the political and sociological problems of data sharing via technological means, with the result intended to benefit both the scientific community and the sometimes apparently contradictory goals of individual researchers.},
  copyright = {http://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {C:\Users\cdonov12\Zotero\storage\BA9M64SS\King - 2007 - An Introduction to the Dataverse Network as an Inf.pdf}
}

@article{pasquier2017IfTheseData,
  title = {If These Data Could Talk},
  author = {Pasquier, Thomas and Lau, Matthew K. and Trisovic, Ana and Boose, Emery R. and Couturier, Ben and Crosas, Merc{\`e} and Ellison, Aaron M. and Gibson, Valerie and Jones, Chris R. and Seltzer, Margo},
  year = {2017},
  month = sep,
  journal = {Scientific Data},
  volume = {4},
  number = {1},
  pages = {170114},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/sdata.2017.114},
  urldate = {2024-09-03},
  abstract = {In the last few decades, data-driven methods have come to dominate many fields of scientific inquiry. Open data and open-source software have enabled the rapid implementation of novel methods to manage and analyze the growing flood of data. However, it has become apparent that many scientific fields exhibit distressingly low rates of reproducibility. Although there are many dimensions to this issue, we believe that there is a lack of formalism used when describing end-to-end published results, from the data source to the analysis to the final published results. Even when authors do their best to make their research and data accessible, this lack of formalism reduces the clarity and efficiency of reporting, which contributes to issues of reproducibility. Data provenance aids both reproducibility through systematic and formal records of the relationships among data sources, processes, datasets, publications and researchers.},
  copyright = {2017 The Author(s)},
  langid = {english},
  keywords = {Research data,Research management},
  file = {C:\Users\cdonov12\Zotero\storage\RE4KXYTL\Pasquier et al. - 2017 - If these data could talk.pdf}
}

@inproceedings{trisovic2020AdvancingComputationalReproducibility,
  title = {Advancing {{Computational Reproducibility}} in the {{Dataverse Data Repository Platform}}},
  booktitle = {Proceedings of the 3rd {{International Workshop}} on {{Practical Reproducible Evaluation}} of {{Computer Systems}}},
  author = {Trisovic, Ana and Durbin, Philip and Schlatter, Tania and Durand, Gustavo and Barbosa, Sonia and Brooke, Danny and Crosas, Merc{\`e}},
  year = {2020},
  month = jun,
  series = {P-{{RECS}} '20},
  pages = {15--20},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3391800.3398173},
  urldate = {2024-09-03},
  abstract = {Recent reproducibility case studies have raised concerns showing that much of the deposited research has not been reproducible. One of their conclusions was that the way data repositories store research data and code cannot fully facilitate reproducibility due to the absence of a runtime environment needed for the code execution. New specialized reproducibility tools provide cloud-based computational environments for code encapsulation, thus enabling research portability and reproducibility. However, they do not often enable research discoverability, standardized data citation, or long-term archival like data repositories do. This paper addresses the shortcomings of data repositories and reproducibility tools and how they could be overcome to improve the current lack of computational reproducibility in published and archived research outputs.},
  isbn = {978-1-4503-7977-9},
  file = {C:\Users\cdonov12\Zotero\storage\9YPBQ4KI\Trisovic et al. - 2020 - Advancing Computational Reproducibility in the Dat.pdf}
}

@article{trisovic2021RepositoryApproachesImproving,
  title = {Repository {{Approaches}} to {{Improving}} the {{Quality}} of {{Shared Data}} and {{Code}}},
  author = {Trisovic, Ana and Mika, Katherine and Boyd, Ceilyn and Feger, Sebastian and Crosas, Merc{\`e}},
  year = {2021},
  month = feb,
  journal = {Data},
  volume = {6},
  number = {2},
  pages = {15},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2306-5729},
  doi = {10.3390/data6020015},
  urldate = {2024-09-03},
  abstract = {Sharing data and code for reuse has become increasingly important in scientific work over the past decade. However, in practice, shared data and code may be unusable, or published results obtained from them may be irreproducible. Data repository features and services contribute significantly to the quality, longevity, and reusability of datasets. This paper presents a combination of original and secondary data analysis studies focusing on computational reproducibility, data curation, and gamified design elements that can be employed to indicate and improve the quality of shared data and code. The findings of these studies are sorted into three approaches that can be valuable to data repositories, archives, and other research dissemination platforms.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {data curation,data quality,data repository,digital libraries,fair principles,gamification,open code,open data},
  file = {C:\Users\cdonov12\Zotero\storage\8FV2EF6A\Trisovic et al. - 2021 - Repository Approaches to Improving the Quality of .pdf}
}

@article{trisovic2022LargescaleStudyResearch,
  title = {A Large-Scale Study on Research Code Quality and Execution},
  author = {Trisovic, Ana and Lau, Matthew K. and Pasquier, Thomas and Crosas, Merc{\`e}},
  year = {2022},
  month = feb,
  journal = {Scientific Data},
  volume = {9},
  number = {1},
  pages = {60},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01143-6},
  urldate = {2024-09-03},
  abstract = {This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74\% of R files failed to complete without error in the initial execution, while 56\% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals' collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Information technology,Research data,Software},
  file = {C:\Users\cdonov12\Zotero\storage\X4PZHKUC\Trisovic et al. - 2022 - A large-scale study on research code quality and e.pdf}
}
