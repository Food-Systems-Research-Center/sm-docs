[
  {
    "objectID": "pages/04.2_environment.html",
    "href": "pages/04.2_environment.html",
    "title": "Environment",
    "section": "",
    "text": "The first plot shows all the environment indicators from both the current studies and the original framework in the y-axis. Purple indicates that the indicator is only being used in the current studies, orange that it is only included in the Wiltshire framework, and green that the indicator is used in both the framework and current studies.\nThe x-axis shows the number of secondary data metrics that have been collected to represent those indicators. You can see that there are some indicators for which there exist many data, but many indicators for which I have found little to represent them.\nNASS figures are used to cover on-farm water use, energy efficiency, and acres in conservation practices. I used the National Aquatic Resource Surveys aggregated at the state level to measure water quality. Land use diversity is pretty well represented by Multi-Resolution Land Characteristics LULC layers, which I also aggregated at the county level. Greenhouse gas emissions come from EPA figures by state, broken down by economic sector. Finally, the USFS TreeMap dataset accounts for aboveground biomass and would do reasonably well in tree vigor. There is more to pull out here than I have so far.\nOtherwise, if anyone has ideas for secondary datasets to cover the rest of the indicators, please do let me know.\n\n\nCode\npacman::p_load(\n  dplyr,\n  ggplot2,\n  stringr,\n  plotly,\n  RColorBrewer\n)\n\n## Load data for tree and metrics\nenv_tree &lt;- readRDS('data/trees/env_tree.rds')\n\nmeta &lt;- readRDS('data/sm_data.rds')[['metadata']] %&gt;% \n  filter(dimension == 'environment')\n\n# Format to match Wiltshire framework\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Above') ~ 'Aboveground biomass',\n      str_detect(indicator, '^Water') ~ 'Water use / irrigation efficiency',\n      TRUE ~ indicator\n    )\n  ) \n\n# Counts of secondary data metrics\ncounts &lt;- meta %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n# Join to Wiltshire framework\ncolors &lt;- RColorBrewer::brewer.pal(n = 3, name = 'Dark2')\ndat &lt;- full_join(env_tree, counts, by = join_by(Indicator == indicator)) %&gt;% \n  mutate(\n    count = ifelse(is.na(count), 0, count),\n    label_color = case_when(\n      Use == 'both' ~ colors[1],\n      Use == 'wiltshire_only' ~ colors[2],\n      Use == 'current_only' ~ colors[3]\n    )\n  )\n\n# Plot\ndat %&gt;%\n  ggplot(aes(x = Indicator, y = count)) +\n  geom_col(\n    color = 'black',\n    fill = 'grey'\n  ) +\n  geom_point(\n    data = dat,\n    aes(x = 1, y = 1, color = Use),\n    inherit.aes = FALSE\n  ) +\n  scale_color_manual(\n    name = \"Indicator Use:\",\n    values = c(\n      \"both\" = colors[1],\n      \"current_only\" = colors[3],\n      \"wiltshire_only\" = colors[2]\n    ),\n    labels = c(\n      'Both',\n      'Current Only',\n      'Framework Only'\n    )\n  ) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_text(color = dat$label_color),\n    legend.position = \"bottom\",\n    plot.margin = margin(t = 10, r = 75, b = 10, l = 10)\n  ) +\n  guides(\n    color = guide_legend(override.aes = list(size = 3))\n  ) +\n  coord_flip() +\n  labs(y = 'Secondary Data Count')\n\n\n\n\n\nBar Plot of Indicators",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#dimension-overview",
    "href": "pages/04.2_environment.html#dimension-overview",
    "title": "Environment",
    "section": "",
    "text": "The first plot shows all the environment indicators from both the current studies and the original framework in the y-axis. Purple indicates that the indicator is only being used in the current studies, orange that it is only included in the Wiltshire framework, and green that the indicator is used in both the framework and current studies.\nThe x-axis shows the number of secondary data metrics that have been collected to represent those indicators. You can see that there are some indicators for which there exist many data, but many indicators for which I have found little to represent them.\nNASS figures are used to cover on-farm water use, energy efficiency, and acres in conservation practices. I used the National Aquatic Resource Surveys aggregated at the state level to measure water quality. Land use diversity is pretty well represented by Multi-Resolution Land Characteristics LULC layers, which I also aggregated at the county level. Greenhouse gas emissions come from EPA figures by state, broken down by economic sector. Finally, the USFS TreeMap dataset accounts for aboveground biomass and would do reasonably well in tree vigor. There is more to pull out here than I have so far.\nOtherwise, if anyone has ideas for secondary datasets to cover the rest of the indicators, please do let me know.\n\n\nCode\npacman::p_load(\n  dplyr,\n  ggplot2,\n  stringr,\n  plotly,\n  RColorBrewer\n)\n\n## Load data for tree and metrics\nenv_tree &lt;- readRDS('data/trees/env_tree.rds')\n\nmeta &lt;- readRDS('data/sm_data.rds')[['metadata']] %&gt;% \n  filter(dimension == 'environment')\n\n# Format to match Wiltshire framework\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Above') ~ 'Aboveground biomass',\n      str_detect(indicator, '^Water') ~ 'Water use / irrigation efficiency',\n      TRUE ~ indicator\n    )\n  ) \n\n# Counts of secondary data metrics\ncounts &lt;- meta %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n# Join to Wiltshire framework\ncolors &lt;- RColorBrewer::brewer.pal(n = 3, name = 'Dark2')\ndat &lt;- full_join(env_tree, counts, by = join_by(Indicator == indicator)) %&gt;% \n  mutate(\n    count = ifelse(is.na(count), 0, count),\n    label_color = case_when(\n      Use == 'both' ~ colors[1],\n      Use == 'wiltshire_only' ~ colors[2],\n      Use == 'current_only' ~ colors[3]\n    )\n  )\n\n# Plot\ndat %&gt;%\n  ggplot(aes(x = Indicator, y = count)) +\n  geom_col(\n    color = 'black',\n    fill = 'grey'\n  ) +\n  geom_point(\n    data = dat,\n    aes(x = 1, y = 1, color = Use),\n    inherit.aes = FALSE\n  ) +\n  scale_color_manual(\n    name = \"Indicator Use:\",\n    values = c(\n      \"both\" = colors[1],\n      \"current_only\" = colors[3],\n      \"wiltshire_only\" = colors[2]\n    ),\n    labels = c(\n      'Both',\n      'Current Only',\n      'Framework Only'\n    )\n  ) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_text(color = dat$label_color),\n    legend.position = \"bottom\",\n    plot.margin = margin(t = 10, r = 75, b = 10, l = 10)\n  ) +\n  guides(\n    color = guide_legend(override.aes = list(size = 3))\n  ) +\n  coord_flip() +\n  labs(y = 'Secondary Data Count')\n\n\n\n\n\nBar Plot of Indicators",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#maps",
    "href": "pages/04.2_environment.html#maps",
    "title": "Environment",
    "section": "2 Maps",
    "text": "2 Maps\nTaking a quick tour through some of the spatial data here. I’m not including full rasters of LULC or TreeMap layers to conserve space, but I have included some derived metrics by county. With the exception of hotspot and species atlas data, these will also be up on the Shiny app along with all the other metrics.\n\nLand Use Diversity\nThis is derived from the USGS MRLC 30m LULC layer for 2023. LULC types are aggregated by category (water, developed, barren, forest, shrubland, herbaceous, cultivated, wetlands) and Shannon diversity is calculated for each county.\n\n\nCode\npacman::p_load(\n  mapview,\n  dplyr,\n  sf,\n  leaflet,\n  leafpop,\n  viridisLite\n)\n\ndiv &lt;- readRDS('data/sm_data.rds')[['lulc_div']]\n\nmapview(\n  div,\n  zcol = 'lulc_div',\n  label = 'county_name',\n  layer.name = 'LULC Diversity',\n  popup = popupTable(\n    div,\n    zcol = c(\n      'county_name',\n      'lulc_div'\n    ),\n    row.numbers = FALSE,\n    feature.id = FALSE\n  )\n)\n\n\n\n\nLand Use Land Cover Diversity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiodiversity Hotspots\nAgain, this biodiversity hotspot map was being put together around the same time as the Y2k crisis. Even if this were more recent and throughout New England, incoporating this kind of data into the framework seems a bit fraught.\n\n\nCode\nhotspots &lt;- readRDS('data/sm_data.rds')[['hotspots']]\nmapview(hotspots, col.regions = '#154734')\n\n\n\n\nBiodiversity Hotspots Map\n\n\n\n\nForest Biomass\nThe TreeMap 2016 dataset is quite comprehensive national survey of forest health and diversity. Updates are infrequent, but this is the best layer I’ve found to address biomass. The raster is at 30m. Shown below is the mean live above-ground biomass aggregated by county so that it plays well with other metrics. Note that it is measured in tons per acre of forest, non-forest cells were removed from analysis. So, it is not showing density of forest, just biomass in existing forest. This is why the more urban counties still show a reasonable density of live biomass. There is lots more that can be pulled out of this dataset, like dead/down carbon, tree stocking, live canopy cover, height, volume, tree per acre, etc. More info can be found here.\n\n\nCode\npacman::p_load(\n  mapview,\n  dplyr,\n  sf,\n  viridisLite,\n  leaflet,\n  leafpop\n)\nbiomass &lt;- readRDS('data/sm_data.rds')[['mean_biomass']]\nmapview(\n  biomass,\n  zcol = 'mean_biomass',\n  layer.name = 'Mean Live Above&lt;br&gt;Ground Biomass&lt;br&gt;(tons per acre)',\n  label = 'county_name',\n  popup = popupTable(\n    biomass,\n    zcol = c(\n      'county_name',\n      'mean_biomass'\n    ),\n    feature.id = FALSE,\n    row.numbers = FALSE\n  )\n)\n\n\n\n\nMap of aboveground forest biomass by county",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#metadata-table",
    "href": "pages/04.2_environment.html#metadata-table",
    "title": "Environment",
    "section": "3 Metadata Table",
    "text": "3 Metadata Table\nThis table includes all secondary data metrics. Filter by dimension to get just environment metrics.\nUsing the table:\n\nClick column headers to sort\nGlobal search in the top right, or column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\nClick the arrow on the left of each row for details, including a URL to the data source.\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Renaming latest year as year, not including og year\n    source,\n    scope,\n    resolution,\n    url\n) %&gt;% \n  setNames(c(str_to_title(names(.))))\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metadata_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metadata_table', 'sustainability_metadata.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 150\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metadata_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Variable Name: '), \n            as.character(metadata_all[index, 'variable_name']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)\n\n\n\n\n\nShow/hide more columns\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#data-table",
    "href": "pages/04.2_environment.html#data-table",
    "title": "Environment",
    "section": "4 Data Table",
    "text": "4 Data Table\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load metrics and metadata\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nfips_key &lt;- readRDS('data/sm_data.rds')[['fips_key']]\n\n# Value formatting function based on units\nsource('dev/format_values.R')\n\n# Filter to economics metrics, join with metadata and county fips codes\nenv_metrics &lt;- metrics %&gt;% \n  left_join(metadata_all, by = join_by('variable_name')) %&gt;% \n  filter(dimension == 'environment') %&gt;% \n  left_join(fips_key, by = join_by('fips')) %&gt;% \n  mutate(county_name = ifelse(is.na(county_name), state_name, county_name)) %&gt;% \n  format_values() %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    year = year.x,\n    Area = county_name,\n    units,\n    value\n  ) %&gt;% \n  setNames(c(str_to_title(names(.)))) %&gt;% \n  filter(!is.na(Value))\n\n\n## Reactable table\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      env_metrics,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 125,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 125\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        Units = colDef(minWidth = 100),\n        'Year' = colDef(minWidth = 100)\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\"\n    )\n  )\n)\n\n\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#distribution-plots",
    "href": "pages/04.2_environment.html#distribution-plots",
    "title": "Environment",
    "section": "5 Distribution Plots",
    "text": "5 Distribution Plots\n\nBy County\nNote that while most of the available secondary data is at the county level, the environment dimension includes a fair amount at the state level as well. This includes greenhouse gas emissions and water quality surveys. For now, I’ll just show these separately, but some creative aggregation will have to happen eventually.\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nmetadata &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Use metadata to get help filter by dimension\nenv_meta &lt;- metadata %&gt;% \n  filter(dimension == 'environment')\n\n# Filter to economics dimension\nenv_metrics &lt;- metrics %&gt;% \n  filter(variable_name %in% env_meta$variable_name)\n\n# env_metrics$variable_name %&gt;% unique\n# get_str(env_metrics)\n\n# Filter to latest year and new (post-2024) counties\n# And pivot wider so it is easier to get correlations\nenv_county &lt;- env_metrics %&gt;%\n  filter_fips(scope = 'counties') %&gt;% \n  get_latest_year() %&gt;% \n  select(fips, variable_name, value) %&gt;% \n  mutate(variable_name = str_split_i(variable_name, '_', 1)) %&gt;% \n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;% \n  unnest(!fips) %&gt;% \n  mutate(across(c(2:last_col()), as.numeric))\n# get_str(env_county)\n\n## Plot\nplots &lt;- map(names(env_county)[-1], \\(var){\n  if (is.character(env_county[[var]])) {\n    env_county %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_bar(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else if (is.numeric(env_county[[var]])) {\n    env_county %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_density(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else {\n    return(NULL)\n  }\n}) \n\n\n# Arrange them in 4 columns\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 7\n)\n\n\n\n\n\nDistributions of economic metrics at the county level.\n\n\n\n\n\n\nBy State\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nstate_codes &lt;- readRDS('data/sm_data.rds')[['fips_key']] %&gt;% \n  select(fips, state_code)\n\nenv_state &lt;- env_metrics %&gt;%\n  filter_fips(scope = 'state') %&gt;% \n  get_latest_year() %&gt;% \n  select(fips, variable_name, value) %&gt;% \n  mutate(variable_name = str_split_i(variable_name, '_', 1)) %&gt;% \n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;% \n  unnest(!fips) %&gt;% \n  mutate(across(c(2:last_col()), as.numeric)) %&gt;% \n  left_join(state_codes, by = 'fips')\n# get_str(env_state)\n\n# Variables to map. Take out some that didn't come through well.\nvars &lt;- names(env_state)[-1] %&gt;% \n  str_subset(\n    'lakesAcidCond|lakesCylsperEpaCond|lakesMicxEpaCond|state_code|waterIrrSrcOffFarmExp|waterIrrReclaimedAcreFt|waterIrrReclaimedOpenAcres',\n    negate = TRUE\n  )\n\n## Plot\nplots &lt;- map(vars, \\(var){\n  env_state %&gt;% \n    ggplot(aes(y = !!sym(var), x = state_code, color = state_code)) + \n    geom_point(\n      alpha = 0.5,\n      size = 3\n    ) +\n    theme_classic() +\n    theme(\n      plot.margin = unit(c(rep(0.5, 4)), 'cm'),\n      legend.position = 'none'\n    ) +\n    labs(\n      x = 'State'\n    )\n}) \n\n# Arrange them in 4 columns\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 17\n)\n\n\n\n\n\nDistributions of environmental variables at state level",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#bivariate-plots",
    "href": "pages/04.2_environment.html#bivariate-plots",
    "title": "Environment",
    "section": "6 Bivariate Plots",
    "text": "6 Bivariate Plots\nUsing a selection of variables at the county level. The variable names are a bit hard to fit in here, but from left to right across the top they are LULC diversity, mean live above-ground forest biomass, conservation income per farm, conservatino easement acres per farm, conservation tillage: no-till acres per farm, conservation tillage: excluding no-till acres per farm, and cover cropping: excluding CRP acres per farm.\n\n\nCode\npacman::p_load(\n  GGally\n)\n\n# Neat function for mapping colors to ggpairs plots\n# https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values\nmap_colors &lt;- function(data,\n                       mapping,\n                       method = \"p\",\n                       use = \"pairwise\",\n                       ...) {\n  # grab data\n  x &lt;- eval_data_col(data, mapping$x)\n  y &lt;- eval_data_col(data, mapping$y)\n  \n  # calculate correlation\n  corr &lt;- cor(x, y, method = method, use = use)\n  colFn &lt;- colorRampPalette(c(\"blue\", \"white\", \"red\"), interpolate = 'spline')\n  fill &lt;- colFn(100)[findInterval(corr, seq(-1, 1, length = 100))]\n  \n  # correlation plot\n  ggally_cor(data = data, mapping = mapping, color = 'black', ...) +\n    theme_void() +\n    theme(panel.background = element_rect(fill = fill))\n}\n\nlower_function &lt;- function(data, mapping, ...) {\n  ggplot(data = data, mapping = mapping) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(color = \"blue\", fill = \"grey\", ...) +\n    theme_bw()\n}\n\n# Rename variables to be shorter\nenv_county %&gt;%\n  select(\n    LULC = lulcDiversity,\n    Biomass = meanAboveGrndForBiomass,\n    consIncomePF,\n    consEasementAcresPF,\n    consTillNoTillAcresPF,\n    consTillExclNoTillAcresPF,\n    coverCropExclCrpAcresPF\n  ) %&gt;%\n  ggpairs(\n    upper = list(continuous = map_colors),\n    lower = list(continuous = lower_function),\n    axisLabels = 'show'\n  ) + \n  theme(\n    strip.text = element_text(size =  5),\n    axis.text = element_text(size =   5),\n    legend.text = element_text(size = 5)\n  )",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#sec-correlations",
    "href": "pages/04.2_environment.html#sec-correlations",
    "title": "Environment",
    "section": "7 Correlations",
    "text": "7 Correlations\nOnly showing correlations by county because we don’t have enough observations to run it by state.\n\n\nCode\npacman::p_load(\n  dplyr,\n  tidyr,\n  tibble,\n  stringr,\n  purrr,\n  tidyr,\n  ggplot2,\n  plotly,\n  reshape,\n  Hmisc,\n  viridisLite\n)\n\n# get_str(env_county)\n\ncor &lt;- env_county %&gt;% \n  select(-fips) %&gt;% \n  as.matrix() %&gt;% \n  rcorr()\n\n# Melt correlation values and rename columns\ncor_r &lt;- melt(cor$r) %&gt;% \n  setNames(c('var_1', 'var_2', 'value'))\n\n# Save p values\ncor_p &lt;- melt(cor$P)\np.value &lt;- cor_p$value\n\n# Make heatmap with custom text aesthetic for tooltip\nplot &lt;- cor_r %&gt;% \n  ggplot(aes(var_1, var_2, fill = value, text = paste0(\n    'Var 1: ', var_1, '\\n',\n    'Var 2: ', var_2, '\\n',\n    'Correlation: ', format(round(value, 3), nsmall = 3), '\\n',\n    'P-Value: ', format(round(p.value, 3), nsmall = 3)\n  ))) + \n  geom_tile() + \n  scale_fill_viridis_c() + \n  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    fill = 'Correlation'\n  )\n\n# Convert to interactive plotly figure with text tooltip\nggplotly(\n  plot, \n  tooltip = 'text',\n  width = 1000,\n  height = 800\n)\n\n\n\n\nInteractive correlation plot of metrics by county",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#pca",
    "href": "pages/04.2_environment.html#pca",
    "title": "Environment",
    "section": "8 PCA",
    "text": "8 PCA\nAgain, this is only at the county level. First, imputing missing data.\n\n\nCode\npacman::p_load(\n  missForest\n)\n\n# Wrangle dataset. Need all numeric vars or factor vars. And can't be tibble\n# Also removing character vars - can't use these in PCA\ndat &lt;- env_county %&gt;%\n  select(where(is.numeric)) %&gt;%\n  as.data.frame()\n# get_str(dat)\n\n# Impute missing variables\nset.seed(42)\nmf_out &lt;- dat %&gt;%\n  missForest(\n    ntree = 200,\n    mtry = 10,\n    verbose = FALSE,\n    variablewise = FALSE\n  )\n\n# Save imputed dataset\nimp &lt;- mf_out$ximp\n\n# Print OOB\nmf_out$OOBerror\n\n\n   NRMSE \n0.697027 \n\n\n\n\nCode\npacman::p_load(\n  psych\n)\nVSS(imp)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.81  with  1  factors\nVSS complexity 2 achieves a maximimum of 0.94  with  2  factors\n\nThe Velicer MAP achieves a minimum of 0.06  with  8  factors \nBIC achieves a minimum of  -296  with  8  factors\nSample Size adjusted BIC achieves a minimum of  277.68  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq\n1 0.81 0.00 0.145 350  2179\n2 0.76 0.94 0.076 323  1504\n3 0.74 0.94 0.075 297  1299\n4 0.58 0.89 0.070 272  1106\n5 0.55 0.85 0.069 248   919\n6 0.52 0.82 0.072 225   704\n7 0.51 0.83 0.056 203   641\n8 0.50 0.80 0.056 182   492\n                                                                                                                                                                                                                                                                      prob\n1 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000039\n2 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002228854813387505566513180355059375870041549205780029296875000000000000000000000000000000000000000000000000000000\n3 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000408777760604219059237252054117561783641576766967773437500000000000000000000000000000000000000000000000000000000000000000000000000000000000\n4 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000602490680256329630285275222867369393497938290238380432128906250000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n5 0.0000000000000000000000000000000000000000000000000000000000000000000000000000091858681800976788285953422708018933917628601193428039550781250000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n6 0.0000000000000000000000000000000000000000000000000089846726271129007624846596335999038274167105555534362792968750000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n7 0.0000000000000000000000000000000000000000000000727638909934370133351586029668567334738327190279960632324218750000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n8 0.0000000000000000000000000000022116284781404799940351946219152523553930222988128662109375000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n  sqresid  fit RMSEA  BIC SABIC complex eChisq  SRMR eCRMS  eBIC\n1   39.37 0.81  0.26  663  1766     1.0   2206 0.196 0.204   690\n2   11.72 0.94  0.22  105  1123     1.2    481 0.091 0.099  -918\n3    7.36 0.96  0.21   13   949     1.4    273 0.069 0.078 -1013\n4    5.07 0.98  0.20  -72   785     1.8    170 0.054 0.064 -1008\n5    3.50 0.98  0.19 -155   627     1.9    100 0.042 0.051  -974\n6    2.51 0.99  0.17 -270   439     1.9     57 0.031 0.041  -918\n7    1.41 0.99  0.17 -238   402     2.0     26 0.021 0.029  -854\n8    0.84 1.00  0.15 -296   278     1.9     13 0.015 0.021  -776\n\n\nCode\nfa.parallel(imp)\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  4  and the number of components =  3 \n\n\nVSS suggests 1 or 2 components, MAP suggests 7, parallel analysis shows 2 or 3. Let’s go with 3 for now.\n\n\nCode\n(pca_out &lt;- pca(imp, nfactors = 3))\n\n\nPrincipal Components Analysis\nCall: principal(r = r, nfactors = nfactors, residuals = residuals, \n    rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, \n    missing = missing, impute = impute, oblique.scores = oblique.scores, \n    method = method, use = use, cor = cor, correct = 0.5, weight = NULL)\nStandardized loadings (pattern matrix) based upon correlation matrix\n                            RC1   RC2   RC3   h2    u2 com\nlulcDiversity              0.00  0.57 -0.08 0.33 0.672 1.0\nmeanAboveGrndForBiomass   -0.39  0.46  0.21 0.41 0.593 2.4\nconsIncomeNOps             0.93  0.09  0.04 0.88 0.123 1.0\nconsIncomeTotal            0.63  0.35  0.20 0.56 0.444 1.8\nconsIncomePF               0.24  0.53 -0.10 0.35 0.648 1.5\nalleyCropSilvapastureNOps  0.18  0.62  0.55 0.72 0.282 2.2\nconsEasementAcres          0.08  0.34  0.87 0.88 0.121 1.3\nconsEasementAcresPF        0.29 -0.11  0.80 0.73 0.271 1.3\nconsEasementNOps          -0.17  0.74  0.45 0.77 0.230 1.8\nconsTillExclNoTillAcres    0.94  0.15  0.07 0.92 0.080 1.1\nconsTillExclNoTillAcresPF  0.92 -0.03  0.09 0.85 0.152 1.0\nconsTillExclNoTillNOps     0.31  0.84  0.17 0.84 0.163 1.4\nconsTillNoTillAcres        0.73  0.33  0.25 0.70 0.300 1.7\nconsTillNoTillAcresPF      0.67 -0.01  0.20 0.48 0.517 1.2\nconsTillNoTillNOps         0.12  0.89  0.16 0.84 0.161 1.1\ncoverCropExclCrpAcres      0.89  0.21 -0.06 0.83 0.168 1.1\ncoverCropExclCrpAcresPF    0.89  0.02  0.07 0.80 0.204 1.0\ncoverCropExclCrpNOps       0.24  0.86  0.07 0.81 0.190 1.2\ndrainedDitchesAcres        0.93  0.21  0.00 0.91 0.088 1.1\ndrainedDitchesAcresPF      0.94  0.09  0.02 0.89 0.107 1.0\ndrainedDitchesNOps         0.47  0.53  0.11 0.52 0.482 2.1\ndrainedTileAcres           0.71  0.06  0.30 0.60 0.403 1.4\ndrainedTileAcresPF         0.71 -0.05  0.31 0.61 0.394 1.4\ndrainedTileNOps            0.70  0.40  0.28 0.74 0.265 1.9\nprecisionAgNOps            0.66  0.55 -0.18 0.78 0.222 2.1\nrotateIntenseGrazeNOps     0.21  0.71  0.47 0.76 0.241 1.9\nfertExpenseTotal           0.83  0.32 -0.19 0.82 0.176 1.4\nfertExpenseOpsWithExp      0.07  0.93 -0.04 0.86 0.136 1.0\n\n                        RC1  RC2  RC3\nSS loadings           10.72 6.70 2.74\nProportion Var         0.38 0.24 0.10\nCumulative Var         0.38 0.62 0.72\nProportion Explained   0.53 0.33 0.14\nCumulative Proportion  0.53 0.86 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n with the empirical chi square  301.08  with prob &lt;  0.42 \n\nFit based upon off diagonal values = 0.98\n\n\nCode\nplot(pca_out$values)\nabline(h = 1)\n\n\n\n\n\n\n\n\n\nThe scree plot makes a pretty good case for 3 components here as well, as it has a nice elbow after the third.\nIt looks like the first component is made up of most of the conservation agriculture practices from the NASS datasets, namely acres of conservation tillage, cover cropping, and draining. Fertilizer expenses loads surprisingly strongly here too. The second component seems to have the most to do with county size or population; anything measured by the number of operations does well here, as does mean above-ground forest biomass. The last component is a grab-bag - conservation easement acres load the strongest onto it, but I don’t see a coherent pattern among metrics here.",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  },
  {
    "objectID": "pages/03_sm-explorer.html",
    "href": "pages/03_sm-explorer.html",
    "title": "SM-Explorer",
    "section": "",
    "text": "Caution\n\n\n\n\n\nThe SM-Explorer is a work in progress. There are a small heap of bugs I’m already aware of, and about a hundred things I’d still like to add. If/when you find things that aren’t working properly, please feel free to let Chris know!\n\n\n\nThis is a Shiny app that allows for interactive exploration of metrics, mostly at the county level. It includes a map page, a bivariate plot explorer, and a metadata table much like what is included in this Quarto doc. It tends to work best if you open it in its own page using the button below:\n\n\n\n\nGo To SM-Explorer\n\n\n\n\nYou can also just use it here in the window. Note that some functions (like the full screen button) won’t work here.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "SM-Explorer"
    ]
  },
  {
    "objectID": "pages/01_home.html",
    "href": "pages/01_home.html",
    "title": "Sustainability Metrics",
    "section": "",
    "text": "Caution\n\n\n\n\n\nThe Sustainability Metrics project, as well as this site itself, are works in progress. All data and analyses shown here are preliminary. If you have any questions, comments, or suggestions about this site or the accompanying Shiny app, feel free to reach out to Chris at christopher.donovan@uvm.edu.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#sec-intro",
    "href": "pages/01_home.html#sec-intro",
    "title": "Sustainability Metrics",
    "section": "1 Introduction",
    "text": "1 Introduction\n\n\n\nIntervale Center, Burlington, Vermont. Copyright: Sally McCay, UVM Photo.\n\n\nResilient food systems are increasingly recognized as essential, not only in meeting human needs, but in doing so within planetary bounds (Conijn et al. 2018). Approximately 42% of world’s population depend on agriculture for employment, which is a challenging endeavor in the face of farm consolidation, changing consumption patterns, and climate change (Giller et al. 2021; Aznar-Sánchez et al. 2019). Food systems themselves are responsible for one-third of greenhouse gas emissions, while anthropogenic climate change has reduced agricultural output by 21% in the last 60 years (Crippa et al. 2021; Ortiz-Bobea et al. 2021).\nMonitoring and adaptively managing the sustainability of food systems is thus vital. However, there is little consensus on how to define, let alone measure food system sustainability (Allen and Prosperi 2016; Béné et al. 2019). And while there is an abundance of research at the global level (Bathaei and Štreimikienė 2023; Chaudhary, Gustafson, and Mathys 2018), there exist gaps in understanding at the local, regional, and landscape levels (Dale et al. 2012).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#sustainability-metrics",
    "href": "pages/01_home.html#sustainability-metrics",
    "title": "Sustainability Metrics",
    "section": "2 Sustainability Metrics",
    "text": "2 Sustainability Metrics\n\n\n\nSpread from the Climate Kitchen harvest dinner. Photo credit: Colleen Goodhue, FSRC.\n\n\nThe Sustainability Metrics project is an effort to develop both the conceptual and methodological frameworks to define and measure regional food system sustainability in New England. The framework could be used to monitor sustainability over time and inform interventions at the policy and farm levels, creating a healthier and more resilient food system for both social and ecological ends.\nThe project is led by the Food Systems Research Center at the University of Vermont in partnership with, and funded by, the USDA ARS Food Systems Research Unit in Burlington, Vermont. Five teams of researchers and numerous community partners are currently conducting primary research on the development and measurement of indicators for food system sustainability. You can find more information about this work at the UVM FSRC Sustainability Metrics website. For now, what you will find here is a growing collection of secondary data, visualizations, and exploratory analyses to help support the project.\nMetadata and citations will be provided throughout the document, but it is worth appreciating the work of the folks at USDA AMS Food and Agriculture Mapper and Explorer in particular, as many of the data shown here were cleaned and compiled in their data warehouse. Considerable inspiration was also taken from the Food Systems Dashboard, developed by the Global Alliance for Improved Nutrition.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#about-fsrc",
    "href": "pages/01_home.html#about-fsrc",
    "title": "Sustainability Metrics",
    "section": "3 About FSRC",
    "text": "3 About FSRC\nThe Food Systems Research Center at the University of Vermont is transforming the research landscape by funding collaborative projects that put people and the planet first, break down traditional academic silos and are integrated with and responsive to the needs of the communities we serve, including decision-makers, farmers, and food systems actors.\nRooted in the belief that no one group can find the answers alone, FSRC empowers researchers to work together across disciplines to address critical issues like soil health, food security, and climate resilience. Instead of funding research that leads to short-term fixes, our commitment is to give researchers the freedom, resources, and time they need to do relevant research that will inform policies, practices, and programs that will long outlast their work.\nFSRC considers the relationship of food systems across scales from local to global and is a partnership between UVM and the U.S. Department of Agriculture (USDA) Agricultural Research Service (ARS). FSRC’s transdisciplinary approach prioritizes research that studies food systems as a whole, including the networks of people, institutions, physical infrastructure, and natural resources through which food is grown, processed, distributed, sold, prepared, and eaten.\nLearn more about us at the Food Systems Research Center website.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#license",
    "href": "pages/01_home.html#license",
    "title": "Sustainability Metrics",
    "section": "4 License",
    "text": "4 License\n\n    This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. \n\n\n    The code is licensed under the GNU General Public License v3.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "dev/old/04.2_correlations.html",
    "href": "dev/old/04.2_correlations.html",
    "title": "Correlations",
    "section": "",
    "text": "Kate Schneider (Schneider et al. 2023)\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "dev/old/04.2_correlations.html#sec-intro",
    "href": "dev/old/04.2_correlations.html#sec-intro",
    "title": "Correlations",
    "section": "",
    "text": "Kate Schneider (Schneider et al. 2023)\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "dev/old/04.2_correlations.html#correlation-heatmap",
    "href": "dev/old/04.2_correlations.html#correlation-heatmap",
    "title": "Correlations",
    "section": "2 Correlation Heatmap",
    "text": "2 Correlation Heatmap\nFirst we have some data wrangle to do. Here, we choose a selection of 35 variables to work with. We also filter for the Connecticut governing regions rather than counties. Finally, we arrange the variables in sensible order so they appear in similar blocks on the correlation plot.\n\n\nCode\npacman::p_load(\n  dplyr,\n  tidyr,\n  tibble,\n  stringr,\n  purrr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n\n# What variables should we use?\n# First let's just take the last year of everything\ndat &lt;- dat %&gt;%\n  filter_fips(scope = 'new') %&gt;% \n  get_latest_year()\n\n# Put together a matching pattern for a selection of relevant variables\npattern &lt;- paste0(c(\n  '^agri', 'd2c', '^edu', '^groc', 'insecurity', 'median_rent$', '^female',\n  'median_rent_as_perc', '^n_house', '^number_', 'refrig', 'pth$', '_pct$',\n  '^wic', '^hired', '^total', '^womens_earnings_as_perc', 'vacancy'\n  ), collapse = '|')\n\n# Filter by variables, break out variables into separate columns, and make some variable names shorter so they fit in figures\ndat &lt;- dat %&gt;%\n  filter(str_detect(variable_name, pattern)) %&gt;%\n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;%\n  dplyr::rename(\n    womens_earnings_perc_men_fff_2023 = womens_earnings_as_perc_of_men_farming_fishing_forestry_2023,\n    womens_earnings_perc_men_service_2023 = \n    womens_earnings_as_perc_of_men_food_prep_and_serving_2023\n  )\n\n# Arrange variables in a sensible order by group\n# Housing, income, education, food security, infrastructure, localness, total sales, expenses\ndat &lt;- dat %&gt;% \n  select(\n    matches('_rent_|vacancy'),\n    matches('income|earnings'),\n    matches('education'),\n    matches('insecurity|^wic|^snap'),\n    matches('^number|^groc'),\n    matches('agritourism|market|_csa_|d2c|valueadded|local_sales'),\n    matches('total_|^hired|producer')\n  )\n\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  ggplot2,\n  plotly,\n  reshape,\n  Hmisc,\n  viridisLite\n)\n\n# Make a correlation matrix using all the selected variables\ncor &lt;- dat %&gt;% \n  as.matrix() %&gt;% \n  rcorr()\n\n# Melt correlation values and rename columns\ncor_r &lt;- melt(cor$r) %&gt;% \n  setNames(c('var_1', 'var_2', 'value'))\n\n# Save p values\ncor_p &lt;- melt(cor$P) \np.value &lt;- cor_p$value\n\n# Make heatmap with custom text aesthetic for tooltip\nplot &lt;- cor_r %&gt;% \n  ggplot(aes(var_1, var_2, fill = value, text = paste0(\n  'Var 1: ', var_1, '\\n',\n  'Var 2: ', var_2, '\\n',\n  'Correlation: ', format(round(value, 3), nsmall = 3), '\\n',\n  'P-Value: ', format(round(p.value, 3), nsmall = 3)\n))) + \n  geom_tile() + \n  scale_fill_viridis_c() + \n  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    fill = 'Correlation'\n  )\n\n# Convert to interactive plotly figure with text tooltip\nggplotly(\n  plot, \n  tooltip = 'text',\n  width = 1000,\n  height = 800\n)"
  },
  {
    "objectID": "dev/old/03_dimensions.html",
    "href": "dev/old/03_dimensions.html",
    "title": "Dimensions",
    "section": "",
    "text": "The plan here is to describe the dimensions, indices, and indicators in detail. Waiting on most of this until it is slightly more clear what we are working with."
  },
  {
    "objectID": "dev/old/03_dimensions.html#environment",
    "href": "dev/old/03_dimensions.html#environment",
    "title": "Dimensions",
    "section": "1 Environment",
    "text": "1 Environment"
  },
  {
    "objectID": "dev/old/03_dimensions.html#economics",
    "href": "dev/old/03_dimensions.html#economics",
    "title": "Dimensions",
    "section": "2 Economics",
    "text": "2 Economics"
  },
  {
    "objectID": "dev/old/03_dimensions.html#production",
    "href": "dev/old/03_dimensions.html#production",
    "title": "Dimensions",
    "section": "3 Production",
    "text": "3 Production"
  },
  {
    "objectID": "dev/old/03_dimensions.html#health",
    "href": "dev/old/03_dimensions.html#health",
    "title": "Dimensions",
    "section": "4 Health",
    "text": "4 Health"
  },
  {
    "objectID": "dev/old/03_dimensions.html#social",
    "href": "dev/old/03_dimensions.html#social",
    "title": "Dimensions",
    "section": "5 Social",
    "text": "5 Social"
  },
  {
    "objectID": "dev/old/03.1_metrics.html",
    "href": "dev/old/03.1_metrics.html",
    "title": "Metrics",
    "section": "",
    "text": "Using the table:\n\nClick column headers to sort\nGlobal search at top right, column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Note renaming latest year as year, not including year\n    source,\n    scope,\n    resolution,\n    url\n)\n\n# Fix capitalization of column names\nnames(metadata) &lt;- str_to_title(names(metadata))\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metrics_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        # Dimension = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Index = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Indicator = colDef(\n          # minWidth = 100,\n          # sticky = 'left'\n        # ),\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        Definition = colDef(\n          minWidth = 250,\n        ),\n        # Units = colDef(minWidth = 50),\n        # Year = colDef(minWidth = 75),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included here): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)"
  },
  {
    "objectID": "dev/old/03.1_metrics.html#metrics-explorer",
    "href": "dev/old/03.1_metrics.html#metrics-explorer",
    "title": "Metrics",
    "section": "",
    "text": "Using the table:\n\nClick column headers to sort\nGlobal search at top right, column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Note renaming latest year as year, not including year\n    source,\n    scope,\n    resolution,\n    url\n)\n\n# Fix capitalization of column names\nnames(metadata) &lt;- str_to_title(names(metadata))\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metrics_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        # Dimension = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Index = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Indicator = colDef(\n          # minWidth = 100,\n          # sticky = 'left'\n        # ),\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        Definition = colDef(\n          minWidth = 250,\n        ),\n        # Units = colDef(minWidth = 50),\n        # Year = colDef(minWidth = 75),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included here): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)"
  },
  {
    "objectID": "dev/old/04.1_graphs.html",
    "href": "dev/old/04.1_graphs.html",
    "title": "Exploratory Graphs",
    "section": "",
    "text": "Outdated\n\n\n\n\n\nThis section is outdated and uses an older, smaller dataset. To be reworked."
  },
  {
    "objectID": "dev/old/04.1_graphs.html#introduction",
    "href": "dev/old/04.1_graphs.html#introduction",
    "title": "Exploratory Graphs",
    "section": "\n1 Introduction",
    "text": "1 Introduction\n\n\n\n\n\n\nConnecticut Planning Regions\n\n\n\n\n\nThe state of Connecticut has operated under an alternative to the traditional county system known as the Councils of Governments since 1960. The U.S. Census Bureau has historically released figures on the county level. In 2022, the Census Bureau formally recognized the state’s nine governing regions. Unfortunately as it relates to data management, this means that data from before and after 2022 are challenging to compare at the county level. Some resources for understanding the shift can be found at the CT Data Collaborative.\n\n\n\nThis is a first pass at exploratory graphs with the metrics collected so far. We will explore time series trends, marginal distributions, and some bivariate plots and correlations.\n\nKate Schneider (Schneider et al. 2023)\n\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "dev/old/04.1_graphs.html#time-series",
    "href": "dev/old/04.1_graphs.html#time-series",
    "title": "Exploratory Graphs",
    "section": "\n2 Time Series",
    "text": "2 Time Series\nExplore a few metrics that have 5 or more time points at state level.\n\nCodepacman::p_load(\n  dplyr,\n  ggplot2,\n  plotly,\n  purrr,\n  RColorBrewer,\n  stringr\n)\n\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\nfips_key &lt;- readRDS('data/sm_data.rds')[['fips_key']]\n\n## Select metrics\n# Start with variables with &gt;= 5 time points\nts_vars &lt;- dat %&gt;% \n  group_by(variable_name) %&gt;% \n  summarize(n_years = length(unique(year))) %&gt;% \n  filter(n_years &gt;= 5) %&gt;% \n  pull(variable_name)\n\n# Select a subset of them\nts_vars &lt;- str_subset(ts_vars, 'child|overall|^wic|^women')\n\n# Add a clean name for graphs\nts_vars &lt;- data.frame(\n  variable = ts_vars,\n  yaxis = c(\n    'Insecurity Rate',\n    'Insecurity Rate',\n    'Coverage Rate',\n    'Eligibility Rate',\n    'Percent',\n    'Percent'\n  ),\n  title = c(\n    'Child Food Insecurity Rate',\n    'Overall Food Insecurity Rate',\n    'WIC Coverage Rate',\n    'WIC Eligibility Rate',\n    'Women\\'s Earnings as % of Men, Farming',\n    'Women\\'s Earnings as % of Men, Food Service'\n  )\n)\n\n## Keep only New England states, add state names from fips_key df\ndat &lt;- dat %&gt;% \n  filter_fips(scope = 'states') %&gt;% \n  left_join(fips_key, by = 'fips')\n\n\n\nCode# Mapping over our time series variables to make a list of plots\nplots &lt;- map(1:nrow(ts_vars), \\(row) {\n  sub_plot &lt;- dat %&gt;% \n    filter(variable_name == ts_vars$variable[row], str_length(fips) == 2) %&gt;% \n    ggplot(aes(\n      x = year, \n      y = value, \n      group = state_name, \n      color = state_name,\n      text = paste0(\n        'State: ', state_name, '\\n',\n        'Value: ', round(value, 3)\n      )\n    )) +\n    geom_line(\n      lwd = 1,\n      alpha = 0.6\n    ) +\n    theme_bw() +\n    scale_y_continuous(n.breaks = 10) +\n    labs(\n      x = 'Year',\n      y = ts_vars$yaxis[row],\n      color = 'State'\n    ) + \n    scale_color_manual(values = brewer.pal(6, 'Dark2'))\n  \n  ggplotly(\n    sub_plot, \n    tooltip = 'text',\n    width = 500,\n    height = 500\n  ) %&gt;% \n  add_annotations(\n    text = ~unique(ts_vars$title[row]),\n    x = -0.05,\n    y = 1.175,\n    yref = \"paper\",\n    xref = \"paper\",\n    xanchor = \"left\",\n    yanchor = \"top\",\n    showarrow = FALSE,\n    font = list(size = 15)\n  )\n})\n\n# Arrange the plots together in one frame\nsubplot(\n  plots[[1]],\n  style(plots[[2]], showlegend = FALSE),\n  style(plots[[3]], showlegend = FALSE),\n  style(plots[[4]], showlegend = FALSE),\n  style(plots[[5]], showlegend = FALSE),\n  style(plots[[6]], showlegend = FALSE),\n  nrows = 3,\n  heights = c(0.32, 0.36, 0.32),\n  margin = c(0.05, 0.06, 0.05, 0.06),\n  titleY = TRUE\n) %&gt;% \n  plotly::layout(\n    autosize = FALSE,\n    margin = list(l = 25, r = 10, t = 75, b = 75),\n    width = 800,\n    height= 600\n  )\n\n\nThere is certainly more to come in terms of time series data."
  },
  {
    "objectID": "dev/old/04.1_graphs.html#distributions",
    "href": "dev/old/04.1_graphs.html#distributions",
    "title": "Exploratory Graphs",
    "section": "\n3 Distributions",
    "text": "3 Distributions\nTaking an exploratory look at the distributions of our variables at the county level. We are only using the latest years available for each metric. Note that y-axes are indepednent\n\nCodepacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n\n# Get names of all vars\nvars &lt;- dat$variable_name %&gt;% unique\n\n# DF with only final years of all vars, states only, CT governing regions\ndat_latest &lt;- dat %&gt;% \n  filter_fips(scope = 'new') %&gt;% \n  mutate(\n    variable_name = str_sub(variable_name, end = 60),\n    value = as.numeric(value)\n  ) %&gt;%\n  get_latest_year() %&gt;%\n  unique() %&gt;% \n  pivot_wider(\n    id_cols = fips,\n    names_from = 'variable_name',\n    values_from = 'value'\n  )\n\nplots &lt;- map(names(dat_latest)[-1], \\(var){\n  dat_latest %&gt;% \n    ggplot(aes(x = !!sym(var))) + \n    geom_density(\n      fill = 'lightblue',\n      color = 'royalblue',\n      alpha = 0.5\n    ) +\n    theme_classic() +\n    theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n})\n\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 17\n)"
  },
  {
    "objectID": "dev/old/04.1_graphs.html#bivariate-plots",
    "href": "dev/old/04.1_graphs.html#bivariate-plots",
    "title": "Exploratory Graphs",
    "section": "\n4 Bivariate Plots",
    "text": "4 Bivariate Plots\n\n\nCodepacman::p_load(\n  GGally\n)\n\n# Neat function for mapping colors to ggpairs plots\n# https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values\nmap_colors &lt;- function(data,\n                       mapping,\n                       method = \"p\",\n                       use = \"pairwise\",\n                       ...) {\n  # grab data\n  x &lt;- eval_data_col(data, mapping$x)\n  y &lt;- eval_data_col(data, mapping$y)\n  \n  # calculate correlation\n  corr &lt;- cor(x, y, method = method, use = use)\n  colFn &lt;- colorRampPalette(c(\"blue\", \"white\", \"red\"), interpolate = 'spline')\n  fill &lt;- colFn(100)[findInterval(corr, seq(-1, 1, length = 100))]\n  \n  # correlation plot\n  ggally_cor(data = data, mapping = mapping, color = 'black', ...) +\n    theme_void() +\n    theme(panel.background = element_rect(fill = fill))\n}\n\nlower_function &lt;- function(data, mapping, ...) {\n  ggplot(data = data, mapping = mapping) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(color = \"blue\", fill = \"grey\", ...) +\n    theme_bw()\n}\n\ndat_latest %&gt;%\n  select(\n    rent = median_rent_2022,\n    rent_burden = median_rent_as_perc_of_household_income_2022,\n    vacancy = vacancy_rate_2022,\n    edu = education_prop_bs_2022,\n    pay_equity = womens_earnings_as_perc_of_men_farming_fishing_forestry_2023,\n    age = mean_producer_age_2022,\n    groc = grocpth_2016,\n    wic = wicspth_2016,\n    snap = snapspth_2017,\n    insecurity = overall_food_insecurity_rate_2021\n  ) %&gt;%\n  ggpairs(\n    upper = list(continuous = map_colors),\n    lower = list(continuous = lower_function),\n    axisLabels = 'show'\n  )"
  },
  {
    "objectID": "dev/old/04.3_pca.html",
    "href": "dev/old/04.3_pca.html",
    "title": "PCA",
    "section": "",
    "text": "Code\n# pacman::p_load(\n#   dplyr,\n#   tidyr,\n#   tibble,\n#   missForest\n# )\n# \n# source('dev/data_pipeline_functions.R')\n# source('dev/filter_fips.R')\n# dat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n# get_str(dat)\n# \n# # Wrangle dataset. Need all numeric vars, also have to remove CT because the \n# # county change creates lots of missing data.\n# dat &lt;- dat %&gt;% \n#   filter_fips(scope = 'new') %&gt;% \n#   get_latest_year() %&gt;% \n#   pivot_wider(\n#     names_from = 'variable_name',\n#     values_from = 'value'\n#   ) %&gt;% \n#   filter(str_detect(fips, '^09', negate = TRUE)) %&gt;% \n#   tibble::column_to_rownames('fips')\n# get_str(dat)\n# \n# # Impute missing variables for now (revisit this, too much missing to go well)\n# mf_out &lt;- dat %&gt;% \n#   missForest()\n# \n# # Check OOB\n# mf_out$OOBerror\n# \n# # Use imputed dataset\n# dat &lt;- mf_out$ximp\n\n\n\n\nCode\n# pacman::p_load(\n#   dplyr,\n#   psych\n# )\n# \n# VSS(dat) # 7 \n# fa.parallel(dat) # 5\n# (pca_out &lt;- pca(dat, nfactors = 5))\n# get_str(pca_out)\n# \n# \n# plot(pca_out$values)\n# abline(h = 1)"
  },
  {
    "objectID": "dev/old/04.3_pca.html#something",
    "href": "dev/old/04.3_pca.html#something",
    "title": "PCA",
    "section": "",
    "text": "Code\n# pacman::p_load(\n#   dplyr,\n#   tidyr,\n#   tibble,\n#   missForest\n# )\n# \n# source('dev/data_pipeline_functions.R')\n# source('dev/filter_fips.R')\n# dat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n# get_str(dat)\n# \n# # Wrangle dataset. Need all numeric vars, also have to remove CT because the \n# # county change creates lots of missing data.\n# dat &lt;- dat %&gt;% \n#   filter_fips(scope = 'new') %&gt;% \n#   get_latest_year() %&gt;% \n#   pivot_wider(\n#     names_from = 'variable_name',\n#     values_from = 'value'\n#   ) %&gt;% \n#   filter(str_detect(fips, '^09', negate = TRUE)) %&gt;% \n#   tibble::column_to_rownames('fips')\n# get_str(dat)\n# \n# # Impute missing variables for now (revisit this, too much missing to go well)\n# mf_out &lt;- dat %&gt;% \n#   missForest()\n# \n# # Check OOB\n# mf_out$OOBerror\n# \n# # Use imputed dataset\n# dat &lt;- mf_out$ximp\n\n\n\n\nCode\n# pacman::p_load(\n#   dplyr,\n#   psych\n# )\n# \n# VSS(dat) # 7 \n# fa.parallel(dat) # 5\n# (pca_out &lt;- pca(dat, nfactors = 5))\n# get_str(pca_out)\n# \n# \n# plot(pca_out$values)\n# abline(h = 1)"
  },
  {
    "objectID": "pages/02_framework.html",
    "href": "pages/02_framework.html",
    "title": "Framework",
    "section": "",
    "text": "Just including some visualizations of the framework here for now. These include all the indicators currently in the matrix.",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/02_framework.html#radial-plot",
    "href": "pages/02_framework.html#radial-plot",
    "title": "Framework",
    "section": "1 Radial Plot",
    "text": "1 Radial Plot\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite\n)\n\n\n## Load data and add an origin level\ndat &lt;- readRDS('data/trees/tree_dat.rds') %&gt;% \n  mutate(Framework = 'Sustainability') %&gt;% \n  select(Framework, Dimension:Indicator)\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$sm_dim &lt;- dat %&gt;% \n  select(Framework, Dimension) %&gt;% \n  unique() %&gt;% \n  rename(from = Framework, to = Dimension) %&gt;% \n  mutate(group = to)\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = from)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = edges$dim_ind$from[match(.$from, edges$dim_ind$to)])\nedges &lt;- bind_rows(edges)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to))) , \n  value = runif(nrow(edges) + 1)\n) \n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(aes(color = group), width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.04,\n      y = y * 1.04,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 2.7,\n    alpha = 1\n  ) +\n  \n  # Make the points for indicators based on dimension groupings\n  # geom_node_point(aes(\n  #   filter = leaf,\n  #   x = x * 1.07,\n  #   y = y * 1.07,\n  #   colour = group,\n  #   size = value,\n  #   alpha = 0.2\n  # )) +\n  \n  # Label the dimensions within the graph\n  geom_node_label(\n    aes(label = ifelse(name == group, name, NA)),\n    label.padding = unit(0.2, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.1,\n    size = 3\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(5, 'Set1')) +\n  scale_edge_color_manual(values = brewer.pal(5, 'Set1')) +\n  scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  expand_limits(x = c(-2, 2), y = c(-2, 2))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/02_framework.html#cladogram",
    "href": "pages/02_framework.html#cladogram",
    "title": "Framework",
    "section": "2 Cladogram",
    "text": "2 Cladogram\nA slightly more readable version of the diagram above.\n\n\nCode\npacman::p_load(\n  ggtree,\n  dplyr,\n  ape,\n  data.tree,\n  viridisLite,\n  stringr\n)\n\n## Load data and add an origin level\ndat &lt;- readRDS('data/trees/tree_dat.rds') %&gt;% \n  mutate(Framework = 'Sustainability') %&gt;% \n  select(Framework, Dimension:Indicator) %&gt;% \n  mutate(across(\n    everything(), \n    ~ str_trim(str_replace_all(., ';|%|/|\\\\.|\\\"|,|\\\\(|\\\\)', '_'))\n  ))\n\ndat$pathString &lt;- paste(\n  dat$Framework,\n  dat$Dimension,\n  dat$Index,\n  dat$Indicator,\n  sep = '/'\n)\ntree &lt;- as.Node(dat)\n\n# Convert the data.tree structure to Newick format\ntree_newick &lt;- ToNewick(tree)\n\n# Read the Newick tree into ape\nphylo_tree &lt;- read.tree(text = tree_newick)\n\n# Make all edge lengths 1\nphylo_tree$edge.length &lt;- rep(1, length(phylo_tree$edge.length))\n\n# Add a space to end of node labels so it isn't cut off\nphylo_tree$node.label &lt;- paste0(phylo_tree$node.label, ' ')\n\n# Plot it\nplot(\n  phylo_tree, \n  type = 'c',\n  cex = 0.75,\n  edge.width = 2,\n  show.tip.label = TRUE,\n  label.offset = 0,\n  no.margin = TRUE,\n  tip.color = 'black',\n  edge.color = viridis(181),\n  x.lim = c(-0.1, 5)\n)\n\nnodelabels(\n  phylo_tree$node.label,\n  cex = 0.8,\n  bg = 'white'\n)\n\n\n\n\n\nCladogram of Sustainability Metrics framework",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html",
    "href": "pages/04.1_economics.html",
    "title": "Economics",
    "section": "",
    "text": "Shown in the diagram below are a total of 45 indicators within the economics dimension. Indices are labeled within the diagram. 17 indicators are both included in the Wiltshire et al. framework as well as being studied by one or more teams (red), 9 are included in the Wiltshire et al. but not currently belong studied (green), while 19 were not in the original framework, but have been added by one or more teams (blue).\nThe points beside each indicator name represent the number of secondary data metrics that have been aggregated for each indicator. Sources include USDA NASS, BLS, ERS, Census Bureau, and others. The quality and appropiateness of these metrics vary widely - I do not mean to suggest that having more of them means an indicator is more accurately better represented. For more information on the data sources, head to Section 2 below.\nOne other point to note here is that I removed several dozen metrics from BLS wage labor data broken down by NAICS industry code so as not to inflate that indicator relative to the others.\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite,\n  ggrepel,\n  stringr\n)\n\nconflicted::conflicts_prefer(\n  dplyr::as_data_frame(),\n  .quiet = TRUE\n)\n\n## Load data for tree and metrics\ndat &lt;- readRDS('data/trees/econ_tree.rds') %&gt;% \n  select(Dimension:Source)\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmeta &lt;- metadata_all %&gt;% \n  filter(\n    dimension == 'economics'\n  )\n\n# Rename metadata so it fits into formatting of tree data\n# This is quite not ideal - Note to harmonize this properly later\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Assets') ~ 'Balance sheet (assets and liabilities)',\n      str_detect(indicator, '^Business failure') ~ 'Business failure rate of food business',\n      str_detect(indicator, '^Direct') ~ '% direct-to-consumer sales',\n      str_detect(indicator, '^Job avail') ~ 'Availability of good-paying jobs in food systems',\n      str_detect(indicator, '^Local sales') ~ '% local sales',\n      str_detect(indicator, '^Operator salary') ~ 'Operator salary / wage',\n      str_detect(indicator, '^Total sales') ~ 'Total sales / revenue',\n      str_detect(indicator, '^Wealth/income') ~ 'Wealth / income distribution',\n      TRUE ~ indicator\n    )\n  ) \n\n# Join counts of secondary data metrics to original dataset\n# Remove the NAICS variables - there are so many of them, don't add much\ncounts &lt;- meta %&gt;% \n  filter(str_detect(variable_name, '^lq|lvl|Lvl|Naics', negate = TRUE)) %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = to)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = from)\nedges &lt;- bind_rows(edges)\n\n# Add column for use (will use in colors of text?)\nedges$group &lt;- c(rep(NA, 10), dat$Source)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to)))\n) %&gt;% \n  left_join(counts, by = join_by(name == indicator)) %&gt;% \n  dplyr::rename('value' = count)\n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(color = 'black', width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.15,\n      y = y * 1.15,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 3,\n    alpha = 1\n  ) +\n  \n  # Label indices within graph\n  geom_label_repel(\n    aes(\n      x = x,\n      y = y,\n      label = ifelse(name %in% unique(dat$Index), name, NA)\n    ),\n    label.padding = unit(0.15, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.05,\n    size = 2.25,\n    force = 0.1,    \n    force_pull = 1, \n    max.overlaps = 10 \n  ) +\n  \n  # Make the points for indicators based on secondary metric count\n  geom_node_point(\n    aes(\n      filter = leaf,\n      x = x * 1.07,\n      y = y * 1.07,\n      colour = group,\n      size = value\n    ),\n    alpha = 0.4\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(3, 'Set1')) +\n  # scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  scale_colour_manual(\n    name = \"Indicator Use\",\n    values = brewer.pal(3, 'Set1'),\n    labels = c(\"Both\", \"Current Only\", \"Wiltshire Only\")\n  ) +\n  expand_limits(x = c(-2.5, 2.5), y = c(-2.5, 2.5))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#dimension-overview",
    "href": "pages/04.1_economics.html#dimension-overview",
    "title": "Economics",
    "section": "",
    "text": "Shown in the diagram below are a total of 45 indicators within the economics dimension. Indices are labeled within the diagram. 17 indicators are both included in the Wiltshire et al. framework as well as being studied by one or more teams (red), 9 are included in the Wiltshire et al. but not currently belong studied (green), while 19 were not in the original framework, but have been added by one or more teams (blue).\nThe points beside each indicator name represent the number of secondary data metrics that have been aggregated for each indicator. Sources include USDA NASS, BLS, ERS, Census Bureau, and others. The quality and appropiateness of these metrics vary widely - I do not mean to suggest that having more of them means an indicator is more accurately better represented. For more information on the data sources, head to Section 2 below.\nOne other point to note here is that I removed several dozen metrics from BLS wage labor data broken down by NAICS industry code so as not to inflate that indicator relative to the others.\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite,\n  ggrepel,\n  stringr\n)\n\nconflicted::conflicts_prefer(\n  dplyr::as_data_frame(),\n  .quiet = TRUE\n)\n\n## Load data for tree and metrics\ndat &lt;- readRDS('data/trees/econ_tree.rds') %&gt;% \n  select(Dimension:Source)\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmeta &lt;- metadata_all %&gt;% \n  filter(\n    dimension == 'economics'\n  )\n\n# Rename metadata so it fits into formatting of tree data\n# This is quite not ideal - Note to harmonize this properly later\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Assets') ~ 'Balance sheet (assets and liabilities)',\n      str_detect(indicator, '^Business failure') ~ 'Business failure rate of food business',\n      str_detect(indicator, '^Direct') ~ '% direct-to-consumer sales',\n      str_detect(indicator, '^Job avail') ~ 'Availability of good-paying jobs in food systems',\n      str_detect(indicator, '^Local sales') ~ '% local sales',\n      str_detect(indicator, '^Operator salary') ~ 'Operator salary / wage',\n      str_detect(indicator, '^Total sales') ~ 'Total sales / revenue',\n      str_detect(indicator, '^Wealth/income') ~ 'Wealth / income distribution',\n      TRUE ~ indicator\n    )\n  ) \n\n# Join counts of secondary data metrics to original dataset\n# Remove the NAICS variables - there are so many of them, don't add much\ncounts &lt;- meta %&gt;% \n  filter(str_detect(variable_name, '^lq|lvl|Lvl|Naics', negate = TRUE)) %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = to)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = from)\nedges &lt;- bind_rows(edges)\n\n# Add column for use (will use in colors of text?)\nedges$group &lt;- c(rep(NA, 10), dat$Source)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to)))\n) %&gt;% \n  left_join(counts, by = join_by(name == indicator)) %&gt;% \n  dplyr::rename('value' = count)\n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(color = 'black', width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.15,\n      y = y * 1.15,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 3,\n    alpha = 1\n  ) +\n  \n  # Label indices within graph\n  geom_label_repel(\n    aes(\n      x = x,\n      y = y,\n      label = ifelse(name %in% unique(dat$Index), name, NA)\n    ),\n    label.padding = unit(0.15, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.05,\n    size = 2.25,\n    force = 0.1,    \n    force_pull = 1, \n    max.overlaps = 10 \n  ) +\n  \n  # Make the points for indicators based on secondary metric count\n  geom_node_point(\n    aes(\n      filter = leaf,\n      x = x * 1.07,\n      y = y * 1.07,\n      colour = group,\n      size = value\n    ),\n    alpha = 0.4\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(3, 'Set1')) +\n  # scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  scale_colour_manual(\n    name = \"Indicator Use\",\n    values = brewer.pal(3, 'Set1'),\n    labels = c(\"Both\", \"Current Only\", \"Wiltshire Only\")\n  ) +\n  expand_limits(x = c(-2.5, 2.5), y = c(-2.5, 2.5))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#sec-metadata",
    "href": "pages/04.1_economics.html#sec-metadata",
    "title": "Economics",
    "section": "2 Metadata Table",
    "text": "2 Metadata Table\nThis is table to explore metadata for secondary metrics data. It does not include the values or geographic areas themselves, but does include definitions, sources, and links to the data used.\nUsing the table:\n\nClick column headers to sort\nGlobal search in the top right, or column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\nClick the arrow on the left of each row for details, including a URL to the data source.\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Renaming latest year as year, not including og year\n    source,\n    scope,\n    resolution,\n    url\n) %&gt;% \n  setNames(c(str_to_title(names(.))))\n\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metadata_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metadata_table', 'sustainability_metadata.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 150\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metadata_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Variable Name: '), \n            as.character(metadata_all[index, 'variable_name']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)\n\n\n\n\n\nShow/hide more columns\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#data-table",
    "href": "pages/04.1_economics.html#data-table",
    "title": "Economics",
    "section": "3 Data Table",
    "text": "3 Data Table\nThis is another table that includes values. It takes some more legwork to navigate through years and counties, but all the secondary data collected for the economics dimension so far is included here. Again, use the button to download the filtered view of the table.\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load metrics and metadata\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nfips_key &lt;- readRDS('data/sm_data.rds')[['fips_key']]\n\n# Value formatting function based on units\nsource('dev/format_values.R')\n\n# Filter to economics metrics, join with metadata and county fips codes\necon_metrics &lt;- metrics %&gt;% \n  left_join(metadata_all, by = join_by('variable_name')) %&gt;% \n  filter(dimension == 'economics') %&gt;% \n  left_join(fips_key, by = join_by('fips')) %&gt;% \n  mutate(county_name = ifelse(is.na(county_name), state_name, county_name)) %&gt;% \n  format_values() %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    year = year.x,\n    Area = county_name,\n    units,\n    value\n  ) %&gt;% \n  setNames(c(str_to_title(names(.)))) %&gt;% \n  filter(!is.na(Value))\n\n\n## Reactable table\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      econ_metrics,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 125,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 125\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        Units = colDef(minWidth = 100),\n        'Year' = colDef(minWidth = 100)\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\"\n    )\n  )\n)\n\n\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#distributions",
    "href": "pages/04.1_economics.html#distributions",
    "title": "Economics",
    "section": "4 Distributions",
    "text": "4 Distributions\nWe are taking out the abundant but largely redundant BLS NAICS wage data variables to leave us with a more approachable set of 46 variables to explore here. First just show univariate distributions by county.\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nmetadata &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Use metadata to get help filter by dimension\necon_meta &lt;- metadata %&gt;% \n  filter(dimension == 'economics')\n\n# Filter to economics dimension\necon_metrics &lt;- metrics %&gt;% \n  filter(variable_name %in% econ_meta$variable_name)\n\n# Filter to latest year and new (post-2024) counties\n# Also remove NAICS variables to leave us with an approachable number\n# And pivot wider so it is easier to get correlations\necon_metrics_latest &lt;- econ_metrics %&gt;%\n  filter_fips(scope = 'new') %&gt;% \n  get_latest_year() %&gt;% \n  filter(\n    str_detect(\n      variable_name, \n      'Naics|NAICS|^lq|^avgEmpLvl|expHiredLaborPercOpExp', \n      negate = TRUE\n    )\n  )\n\n# Pivot wider for easier correlations below\necon_metrics_latest &lt;- econ_metrics_latest %&gt;% \n  select(fips, variable_name, value) %&gt;% \n  unique() %&gt;% \n  mutate(variable_name = str_split_i(variable_name, '_', 1)) %&gt;% \n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;% \n  unnest(!fips) %&gt;% \n  mutate(across(c(civLaborForce:last_col()), as.numeric))\n\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nplots &lt;- map(names(econ_metrics_latest)[-1], \\(var){\n  if (is.character(econ_metrics_latest[[var]])) {\n    econ_metrics_latest %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_bar(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else if (is.numeric(econ_metrics_latest[[var]])) {\n    econ_metrics_latest %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_density(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else {\n    return(NULL)\n  }\n}) \n\n# Arrange them in 4 columns\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 12\n)\n\n\n\n\n\nDistributions of economic metrics at the county level.",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#correlation-heatmap",
    "href": "pages/04.1_economics.html#correlation-heatmap",
    "title": "Economics",
    "section": "5 Correlation Heatmap",
    "text": "5 Correlation Heatmap\nThrowing those same variables into a correlation matrix. Hover to see variable names, Pearson correlation, and p-values.\n\n\nCode\npacman::p_load(\n  dplyr,\n  tidyr,\n  tibble,\n  stringr,\n  purrr,\n  tidyr,\n  ggplot2,\n  plotly,\n  reshape,\n  Hmisc,\n  viridisLite\n)\n\n# Arrange variables in some halfway reasonable order\ncor_dat &lt;- econ_metrics_latest %&gt;% \n  select(\n    matches('Code_|metro'),\n    matches('employ|abor|Worker'),\n    matches('Sales'),\n    matches('Earn|Income'),\n    everything(),\n    -fips,\n    -matches('expHiredLaborPercOpExp') # This one didn't come through\n  )\n\n# Make a correlation matrix using all the selected variables\ncor &lt;- cor_dat %&gt;% \n  as.matrix() %&gt;% \n  rcorr()\n\n# Melt correlation values and rename columns\ncor_r &lt;- melt(cor$r) %&gt;% \n  setNames(c('var_1', 'var_2', 'value'))\n\n# Save p values\ncor_p &lt;- melt(cor$P)\np.value &lt;- cor_p$value\n\n# Make heatmap with custom text aesthetic for tooltip\nplot &lt;- cor_r %&gt;% \n  ggplot(aes(var_1, var_2, fill = value, text = paste0(\n    'Var 1: ', var_1, '\\n',\n    'Var 2: ', var_2, '\\n',\n    'Correlation: ', format(round(value, 3), nsmall = 3), '\\n',\n    'P-Value: ', format(round(p.value, 3), nsmall = 3)\n  ))) + \n  geom_tile() + \n  scale_fill_viridis_c() + \n  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    fill = 'Correlation'\n  )\n\n# Convert to interactive plotly figure with text tooltip\nggplotly(\n  plot, \n  tooltip = 'text',\n  width = 1000,\n  height = 800\n)\n\n\n\n\nInteractive Correlation Plot",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.1_economics.html#pca",
    "href": "pages/04.1_economics.html#pca",
    "title": "Economics",
    "section": "6 PCA",
    "text": "6 PCA\nPCA is a popular tool in this area for exploring unique variation with many collinear variables. It is a way to reduce the dimensionality of the data into fewer, more interpretable principal components.\nIt also requires complete data, which we do not have. So we either have to run a probabililistic PCA or run imputations. I’m using a random forest algorithm to impute data here as a first pass (Stekhoven and Bühlmann 2012). This really warrants a deeper dive into the type and severity of missingness though, and PPCA is likely the better option in the end.\n\n\nCode\npacman::p_load(\n  missForest\n)\n\n# Wrangle dataset. Need all numeric vars or factor vars. And can't be tibble\n# Also removing character vars - can't use these in PCA\ndat &lt;- econ_metrics_latest %&gt;%\n  select(where(is.numeric)) %&gt;%\n  as.data.frame()\n# get_str(dat)\n\n# Check missing variables\n# skimr::skim(dat)\n\n# Impute missing variables\nset.seed(42)\nmf_out &lt;- dat %&gt;%\n  missForest(\n    ntree = 200,\n    mtry = 10,\n    verbose = FALSE,\n    variablewise = FALSE\n  )\n\n# Save imputed dataset\nimp &lt;- mf_out$ximp\n\n# Print OOB\nmf_out$OOBerror\n\n\n    NRMSE \n0.1839393 \n\n\nOut of bag error is shown as normalized root mean square error. Now we can explore how many composite factors is appropriate for the data.\n\n\nCode\npacman::p_load(\n  psych\n)\nVSS(imp)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.68  with  2  factors\nVSS complexity 2 achieves a maximimum of 0.87  with  2  factors\n\nThe Velicer MAP achieves a minimum of 0.04  with  7  factors \nBIC achieves a minimum of  -489.17  with  5  factors\nSample Size adjusted BIC achieves a minimum of  1478.99  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq\n1 0.58 0.00 0.104 860  4406\n2 0.68 0.87 0.060 818  3618\n3 0.64 0.84 0.059 777  3298\n4 0.64 0.84 0.058 737  2920\n5 0.59 0.83 0.045 698  2552\n6 0.57 0.80 0.045 660  2437\n7 0.56 0.79 0.042 623  2280\n8 0.57 0.81 0.045 587  2186\n                                                                                                                                                                                                                                                                                                                   prob\n1 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n2 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n3 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000016\n4 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001645637239849334630984942218212552234035683795809746\n5 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000690875312224248350895239312308149237651377916336059570312500000000000000000000000000000000000000000\n6 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000020100945303999495240160344522450941440183669328689575195312500000000000000000000000000000000000000000000000\n7 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000004548934418792562005100232891408040813985280692577362060546875000000000000000000000000000000000000000000000000000000000000\n8 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000223377243925002633411630581505846748768817633390426635742187500000000000000000000000000000000000000000000000000000000000000000\n  sqresid  fit RMSEA  BIC SABIC complex eChisq  SRMR eCRMS  eBIC\n1   110.5 0.58  0.23  659  3371     1.0   6540 0.215 0.221  2793\n2    34.9 0.87  0.21   54  2633     1.3   1485 0.103 0.108 -2079\n3    24.3 0.91  0.20  -87  2363     1.6    907 0.080 0.086 -2478\n4    18.3 0.93  0.19 -291  2032     1.7    610 0.066 0.073 -2601\n5    13.9 0.95  0.18 -489  1711     1.7    388 0.053 0.060 -2652\n6    11.6 0.96  0.19 -439  1642     1.9    305 0.047 0.054 -2570\n7     9.3 0.96  0.18 -434  1530     2.0    212 0.039 0.047 -2503\n8     8.0 0.97  0.19 -372  1479     2.0    170 0.035 0.043 -2388\n\n\nCode\nfa.parallel(imp)\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  5  and the number of components =  4 \n\n\nVSS gives a wide range from 2 to 8, MAP shows 7, parallel analysis shows 4. I tend to trust PA the most, so let’s go with 4.\n\n\nCode\n(pca_out &lt;- pca(imp, nfactors = 4))\n\n\nPrincipal Components Analysis\nCall: principal(r = r, nfactors = nfactors, residuals = residuals, \n    rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, \n    missing = missing, impute = impute, oblique.scores = oblique.scores, \n    method = method, use = use, cor = cor, correct = 0.5, weight = NULL)\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        RC1   RC2   RC3   RC4    h2    u2 com\ncivLaborForce          0.23  0.90  0.19  0.02 0.897 0.103 1.2\nemployed               0.23  0.90  0.19  0.02 0.895 0.105 1.2\nunemployed             0.24  0.91  0.16  0.10 0.914 0.086 1.2\nunemploymentRate       0.12  0.12 -0.02  0.78 0.637 0.363 1.1\nmedHhIncome            0.08  0.36  0.82 -0.02 0.808 0.192 1.4\nmedHhIncomePercState   0.06  0.09  0.81 -0.17 0.705 0.295 1.1\ngini                  -0.19  0.38 -0.03  0.47 0.402 0.598 2.3\nnCSA                   0.17  0.37 -0.09 -0.24 0.231 0.769 2.3\nnFarmersMarket         0.34  0.84  0.14 -0.05 0.837 0.163 1.4\nnOnFarmMarket          0.03  0.07  0.14 -0.09 0.034 0.966 2.4\nagTourSalesPerc       -0.14  0.24  0.35  0.64 0.606 0.394 2.0\nd2cSalesPerc          -0.23  0.42  0.52  0.10 0.507 0.493 2.4\nlocalSalesPerc        -0.16  0.40  0.55  0.06 0.486 0.514 2.1\nnAnaerDigestion        0.53 -0.38 -0.09  0.06 0.434 0.566 1.9\nnCompost               0.37  0.77  0.15  0.07 0.762 0.238 1.5\nnFoodHubs              0.18 -0.02  0.01 -0.10 0.043 0.957 1.7\nnMeatProcess           0.17  0.79  0.09  0.04 0.665 0.335 1.1\nmedianEarnMaleFood     0.00  0.23  0.12 -0.36 0.201 0.799 2.0\nmedianEarnFemaleFood  -0.19  0.12  0.17  0.65 0.497 0.503 1.4\nwomenEarnPercMaleFood -0.15 -0.15 -0.05  0.69 0.529 0.471 1.2\nmedianEarnMaleFarm    -0.16  0.05  0.33  0.27 0.211 0.789 2.5\nmedianEarnFemaleFarm  -0.13 -0.06  0.73  0.21 0.602 0.398 1.2\nwomenEarnPercMaleFarm -0.09  0.01  0.64  0.05 0.419 0.581 1.1\nnHiredWorkers          0.92  0.31  0.01 -0.09 0.951 0.049 1.2\nnOpsMigrantWorkers     0.79  0.09  0.05 -0.10 0.646 0.354 1.1\nnOpsHiredLabor         0.88  0.27 -0.09 -0.23 0.897 0.103 1.4\nnOpsHiredLaborExp      0.87  0.27 -0.09 -0.22 0.897 0.103 1.4\nnWorkersLE150          0.88  0.25 -0.04 -0.04 0.841 0.159 1.2\nnMigrantWorkers        0.61 -0.15 -0.13  0.11 0.425 0.575 1.3\nnOpsWorkersLE150       0.88  0.24 -0.11 -0.22 0.897 0.103 1.3\nnWorkersGE150          0.85  0.38  0.09 -0.10 0.887 0.113 1.4\nnOpsWorkersGE150       0.88  0.30  0.01 -0.18 0.906 0.094 1.3\nnOpsUnpaidWorkers      0.69  0.26 -0.22 -0.35 0.712 0.288 2.1\nnUnpaidWorkers         0.65  0.35 -0.23 -0.32 0.697 0.303 2.4\nexpHiredLabor          0.95  0.15  0.04 -0.06 0.931 0.069 1.1\nexpHiredLaborPF        0.62 -0.08  0.25  0.13 0.468 0.532 1.5\nexpPF                  0.75 -0.34  0.12  0.28 0.776 0.224 1.8\nfarmIncomePF           0.32  0.27  0.63  0.05 0.578 0.422 1.9\nacresOperated          0.69 -0.43 -0.35 -0.06 0.786 0.214 2.2\nacresPF                0.32 -0.61 -0.51  0.09 0.740 0.260 2.5\nmedianAcresPF          0.22 -0.55 -0.60 -0.03 0.709 0.291 2.3\nlandValPF              0.21 -0.18  0.56 -0.01 0.392 0.608 1.5\nlandValPerAcre        -0.13  0.48  0.48  0.21 0.521 0.479 2.5\n\n                        RC1  RC2  RC3  RC4\nSS loadings           11.01 7.59 5.25 3.14\nProportion Var         0.26 0.18 0.12 0.07\nCumulative Var         0.26 0.43 0.55 0.63\nProportion Explained   0.41 0.28 0.19 0.12\nCumulative Proportion  0.41 0.69 0.88 1.00\n\nMean item complexity =  1.7\nTest of the hypothesis that 4 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n with the empirical chi square  678.89  with prob &lt;  0.94 \n\nFit based upon off diagonal values = 0.96\n\n\nCode\nplot(pca_out$values)\nabline(h = 1)\n\n\n\n\n\n\n\n\n\nFrom the scree plot and eigenvalues it looks like the first three components bear lots of unique variance, but after that there is no clear elbow where a qualitative decision can be made to choose a certain number of components. The Kaiser-Guttman rule suggests keeping any compents with an eigenvalue &gt; 1 (at the horizontal line), but we can see here that this is a rather dubious distinction.\nIf we look at the output from the PCA call, we can see how closely each variable (row) correlates with each component (columns 1-4). The variables most associated with Component #1 are the farm labor variables - numbers of workers, labor expenses, etc. They also tend to be raw figures, and probably have more to do with population than anything else. Component #2 is made up mostly of generic employment figures - total civilian labor force, total employed, total unemployed. These are not specific to food systems. Component #3 has a curious collection of median earnings variables and ‘per farm’ variables like acres per farm, income per farm, and local and direct-to-consumer sales. Component #4 does not represent much unique variance, and loooks like a grab bag of variables.\nA couple of early takeaways here are that the raw figures that are tied to population probably shouldn’t be mixed with other variables like proportions. We could try normalizing all the variables so that raw variables are not disproportionately weighted. But it might make more sense to avoid raw counts and dollar amounts entirely.",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/04.2_environment.html#analysis",
    "href": "pages/04.2_environment.html#analysis",
    "title": "Environment",
    "section": "9 Analysis",
    "text": "9 Analysis\n\nImputation\n\n\nCode\npacman::p_load(\n  missForest\n)\n# Wrangle dataset. Need all numeric vars or factor vars. And can't be tibble\n# Also removing character vars - can't use these in PCA\n# Using old Connecticut counties - some lulc data is missing for them though\ndat &lt;- env_county %&gt;%\n  filter_fips('old') %&gt;% \n  select(fips, where(is.numeric)) %&gt;%\n  column_to_rownames('fips') %&gt;% \n  as.data.frame()\n# get_str(dat)\n# skimr::skim(dat)\n\n# Remove variables with most missing data - too much to impute.\n# Also remove the proportional LULC values - keeping diversity though\ndat &lt;- dat %&gt;% \n  select(-matches('consIncome'), -matches('^lulcProp'))\n\n# Impute missing variables\nset.seed(42)\nmf_out &lt;- dat %&gt;%\n  missForest(\n    ntree = 200,\n    mtry = 10,\n    verbose = FALSE,\n    variablewise = FALSE\n  )\n\n# Save imputed dataset\nimp &lt;- mf_out$ximp\n\n# Print OOB\nmf_out$OOBerror\n\n\n     NRMSE \n0.00142119 \n\n\n\n\nNormalization\nUsing min-max normalization to put all indicators on an arbitrary 0-1 scale\n\n\nCode\n# get_str(imp)\n\n# Function to normalize data\nnormalize &lt;- function(x) {\n    (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\n# Normalize all variables\ndat &lt;- map_dfc(imp, normalize)\n\n\nNow that we have normalized variables, we have to make normative decisions about what constitutes a good or bad value of those variables. This will eventually be a collaborative process where we will seek input from teams to come to some kind of consensus. But until then, I’m going to make some heroic assumptions that LULC diversity is good, above ground forest biomass is good, conservation practices and easements are good, and fertilizer expenses are bad. Open to thoughts here as always.\nWith that, we can recode our normalized variables accordingly.\n\n\nCode\n# Flip 'bad' variables by subtracting them from 1\nnormed &lt;- dat %&gt;% \n  mutate(across(c(matches('^fert')), ~ 1 - .x))\n# get_str(normed)\n\n\n\n\nComponent Extraction\nDetermine the number of components to extract using a few tools: very simple structure (VSS), Velicer’s minimum average partial (MAP) test, parallel analysis, and a scree plot.\n\n\nCode\npacman::p_load(\n  psych\n)\nVSS(normed)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.79  with  1  factors\nVSS complexity 2 achieves a maximimum of 0.94  with  2  factors\n\nThe Velicer MAP achieves a minimum of 0.06  with  8  factors \nBIC achieves a minimum of  -212.51  with  8  factors\nSample Size adjusted BIC achieves a minimum of  190.51  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq\n1 0.79 0.00 0.157 275  1633\n2 0.76 0.94 0.081 251  1083\n3 0.73 0.94 0.077 228   897\n4 0.60 0.88 0.081 206   722\n5 0.55 0.85 0.063 185   597\n6 0.53 0.85 0.063 165   547\n7 0.52 0.82 0.062 146   429\n8 0.52 0.79 0.060 128   326\n                                                                                                                                                                                                prob\n1 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000026\n2 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000098945650053446549182165070668304451828589662909507751464843750000000000000000000000000000\n3 0.000000000000000000000000000000000000000000000000000000000000000000000000000000039129475698153761190588306728699308223440311849117279052734375000000000000000000000000000000000000000000000000000\n4 0.000000000000000000000000000000000000000000000000000000000199731474755145863271901807145525253872619941830635070800781250000000000000000000000000000000000000000000000000000000000000000000000000\n5 0.000000000000000000000000000000000000000000007276720351332410293559993519352246948983520269393920898437500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n6 0.000000000000000000000000000000000000000001728048955544093425503587857505749525444116443395614624023437500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n7 0.000000000000000000000000000014378040855225031248269818018314936125534586608409881591796875000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n8 0.000000000000000000340581713295255120773491475105743120366241782903671264648437500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n  sqresid  fit RMSEA  BIC SABIC complex eChisq  SRMR eCRMS eBIC\n1   34.26 0.79  0.27  476  1342     1.0 1687.8 0.205 0.214  531\n2    9.70 0.94  0.22   28   818     1.2  348.0 0.093 0.102 -707\n3    5.48 0.97  0.21  -61   657     1.4  170.5 0.065 0.075 -788\n4    3.90 0.98  0.19 -145   504     1.7  105.4 0.051 0.062 -761\n5    2.57 0.98  0.18 -181   402     1.8   55.9 0.037 0.047 -722\n6    1.42 0.99  0.19 -147   373     1.8   24.9 0.025 0.034 -669\n7    0.89 0.99  0.17 -185   274     1.8   12.9 0.018 0.026 -601\n8    0.59 1.00  0.15 -213   191     1.8    6.6 0.013 0.020 -532\n\n\nCode\nfa.parallel(normed)\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  3 \n\n\nVSS suggests 1 or 2, MAP suggests 8, parallel analysis shows 3. I’m going with 3 here, which will be explained further below.\n\n\nPrincipal Components Analysis\nUsing an oblique varimax rotation that allows for correlations between principal components. First we just observe the scree plot to see how the components play out.\n\n\nCode\npca_out &lt;- pca(normed, nfactors = 3, rotate = 'varimax')\nplot(pca_out$values)\nabline(h = 1)\n\n\n\n\n\n\n\n\n\nThis scree plot shows the eigenvalues (variance explained) of each principal component (y-axis) against each component (x-axis). The first few components explain lots of variance, but there is a decent elbow around the fourth component. Just looking at this plot, I would be tempted to take four, but the results below suggest three is more appropriate for our application.\nNow we let’s look at PCA results.\n\n\nCode\npca_out\n\n\nPrincipal Components Analysis\nCall: principal(r = r, nfactors = nfactors, residuals = residuals, \n    rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, \n    missing = missing, impute = impute, oblique.scores = oblique.scores, \n    method = method, use = use, cor = cor, correct = 0.5, weight = NULL)\nStandardized loadings (pattern matrix) based upon correlation matrix\n                            RC1   RC2   RC3   RC4   h2    u2 com\nlulcDiversity             -0.06  0.55 -0.20  0.38 0.48 0.516 2.1\nmeanAboveGrndForBiomass   -0.44  0.51 -0.06  0.31 0.55 0.449 2.7\nalleyCropSilvapastureNOps  0.20  0.68  0.54 -0.14 0.81 0.186 2.2\nconsEasementAcres          0.01  0.41  0.81  0.12 0.84 0.159 1.5\nconsEasementAcresPF        0.20 -0.06  0.77  0.21 0.69 0.314 1.3\nconsEasementNOps          -0.16  0.80  0.32  0.02 0.77 0.233 1.4\nconsTillExclNoTillAcres    0.91  0.14  0.11  0.25 0.92 0.081 1.2\nconsTillExclNoTillAcresPF  0.89 -0.03  0.14  0.20 0.85 0.146 1.2\nconsTillExclNoTillNOps     0.31  0.83  0.14  0.14 0.82 0.180 1.4\nconsTillNoTillAcres        0.70  0.31  0.38  0.08 0.74 0.264 2.0\nconsTillNoTillAcresPF      0.67 -0.02  0.38 -0.10 0.61 0.392 1.6\nconsTillNoTillNOps         0.14  0.89  0.10  0.12 0.83 0.168 1.1\ncoverCropExclCrpAcres      0.93  0.21  0.00 -0.02 0.92 0.083 1.1\ncoverCropExclCrpAcresPF    0.90  0.02  0.17  0.04 0.84 0.157 1.1\ncoverCropExclCrpNOps       0.31  0.88  0.02 -0.03 0.87 0.130 1.3\ndrainedDitchesAcres        0.88  0.17  0.05  0.29 0.89 0.108 1.3\ndrainedDitchesAcresPF      0.92  0.07  0.08  0.17 0.89 0.113 1.1\ndrainedDitchesNOps         0.38  0.49  0.10  0.46 0.61 0.394 3.0\ndrainedTileAcres           0.54  0.03  0.31  0.68 0.85 0.149 2.3\ndrainedTileAcresPF         0.57 -0.10  0.36  0.55 0.77 0.231 2.8\ndrainedTileNOps            0.59  0.37  0.27  0.56 0.87 0.130 3.1\nprecisionAgNOps            0.64  0.52 -0.16  0.28 0.79 0.214 2.5\nrotateIntenseGrazeNOps     0.21  0.74  0.48 -0.09 0.84 0.163 1.9\nfertExpenseTotal           0.87  0.32 -0.15  0.06 0.89 0.112 1.3\nfertExpenseOpsWithExp      0.13  0.93 -0.10  0.02 0.88 0.117 1.1\n\n                       RC1  RC2  RC3  RC4\nSS loadings           8.73 6.43 2.69 1.96\nProportion Var        0.35 0.26 0.11 0.08\nCumulative Var        0.35 0.61 0.71 0.79\nProportion Explained  0.44 0.32 0.14 0.10\nCumulative Proportion 0.44 0.77 0.90 1.00\n\nMean item complexity =  1.7\nTest of the hypothesis that 4 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.06 \n with the empirical chi square  136.54  with prob &lt;  1 \n\nFit based upon off diagonal values = 0.99\n\n\nRecommendations for creating composite indices are to extract components that each have eigenvalues &gt; 1, explained variance &gt; 0.10, and such that the proportion of explained variance for the total set is &gt; 0.60 (Nicoletti 2000; OECD 2008).\nOur total cumulative variance is explained is 0.74, and our component that explains the least variance is RC4 with 0.11. Note that extracting four or more components here gives us a component with less than 0.10, so this is why we are sticking to three. The first component (RC1) explains 38% of the variance in the data. The second component is respectable at 0.26, while the third is barely above the threshold at 0.11.\nLooking at the metrics, we can see that the first component loads mostly onto the conservation practices, no-till acres, cover cropping, drainage, and total fertilizer expenses. The second component leads onto mean aboveground biomass (although there is crossloading with the first component), operations wtih silvapasture, operations with easements, rotational grazing operations, and operations with fertilizer expenses. This seems to be catching more of the population-related metrics. The last component only loads onto a few metrics: easement acres, easement acres per farm, and silvpasture operations (which has some heavy crossloading).",
    "crumbs": [
      "Dimensions",
      "Environment"
    ]
  }
]