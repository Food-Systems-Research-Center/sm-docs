[
  {
    "objectID": "pages/04.4_regression.html",
    "href": "pages/04.4_regression.html",
    "title": "Food Systems Research Center",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/04.2_correlations.html",
    "href": "pages/04.2_correlations.html",
    "title": "Correlations",
    "section": "",
    "text": "Kate Schneider (Schneider et al. 2023)\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "pages/04.2_correlations.html#sec-intro",
    "href": "pages/04.2_correlations.html#sec-intro",
    "title": "Correlations",
    "section": "",
    "text": "Kate Schneider (Schneider et al. 2023)\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "pages/04.2_correlations.html#correlation-heatmap",
    "href": "pages/04.2_correlations.html#correlation-heatmap",
    "title": "Correlations",
    "section": "2 Correlation Heatmap",
    "text": "2 Correlation Heatmap\nFirst we have some data wrangle to do. Here, we choose a selection of 35 variables to work with. We also filter for the Connecticut governing regions rather than counties. Finally, we arrange the variables in sensible order so they appear in similar blocks on the correlation plot.\n\n\nCode\npacman::p_load(\n  dplyr,\n  tidyr,\n  tibble,\n  stringr,\n  purrr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n\n# What variables should we use?\n# First let's just take the last year of everything\ndat &lt;- dat %&gt;%\n  filter_fips(scope = 'new') %&gt;% \n  get_latest_year()\n\n# Put together a matching pattern for a selection of relevant variables\npattern &lt;- paste0(c(\n  '^agri', 'd2c', '^edu', '^groc', 'insecurity', 'median_rent$', '^female',\n  'median_rent_as_perc', '^n_house', '^number_', 'refrig', 'pth$', '_pct$',\n  '^wic', '^hired', '^total', '^womens_earnings_as_perc', 'vacancy'\n  ), collapse = '|')\n\n# Filter by variables, break out variables into separate columns, and make some variable names shorter so they fit in figures\ndat &lt;- dat %&gt;%\n  filter(str_detect(variable_name, pattern)) %&gt;%\n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;%\n  dplyr::rename(\n    womens_earnings_perc_men_fff_2023 = womens_earnings_as_perc_of_men_farming_fishing_forestry_2023,\n    womens_earnings_perc_men_service_2023 = \n    womens_earnings_as_perc_of_men_food_prep_and_serving_2023\n  )\n\n# Arrange variables in a sensible order by group\n# Housing, income, education, food security, infrastructure, localness, total sales, expenses\ndat &lt;- dat %&gt;% \n  select(\n    matches('_rent_|vacancy'),\n    matches('income|earnings'),\n    matches('education'),\n    matches('insecurity|^wic|^snap'),\n    matches('^number|^groc'),\n    matches('agritourism|market|_csa_|d2c|valueadded|local_sales'),\n    matches('total_|^hired|producer')\n  )\n\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  ggplot2,\n  plotly,\n  reshape,\n  Hmisc,\n  viridisLite\n)\n\n# Make a correlation matrix using all the selected variables\ncor &lt;- dat %&gt;% \n  as.matrix() %&gt;% \n  rcorr()\n\n# Melt correlation values and rename columns\ncor_r &lt;- melt(cor$r) %&gt;% \n  setNames(c('var_1', 'var_2', 'value'))\n\n# Save p values\ncor_p &lt;- melt(cor$P) \np.value &lt;- cor_p$value\n\n# Make heatmap with custom text aesthetic for tooltip\nplot &lt;- cor_r %&gt;% \n  ggplot(aes(var_1, var_2, fill = value, text = paste0(\n  'Var 1: ', var_1, '\\n',\n  'Var 2: ', var_2, '\\n',\n  'Correlation: ', format(round(value, 3), nsmall = 3), '\\n',\n  'P-Value: ', format(round(p.value, 3), nsmall = 3)\n))) + \n  geom_tile() + \n  scale_fill_viridis_c() + \n  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    fill = 'Correlation'\n  )\n\n# Convert to interactive plotly figure with text tooltip\nggplotly(\n  plot, \n  tooltip = 'text',\n  width = 1000,\n  height = 800\n)\n\n\n\n\nInteractive Correlation Plot"
  },
  {
    "objectID": "pages/03_dimensions.html",
    "href": "pages/03_dimensions.html",
    "title": "Dimensions",
    "section": "",
    "text": "The plan here is to describe the dimensions, indices, and indicators in detail. Waiting on most of this until it is slightly more clear what we are working with."
  },
  {
    "objectID": "pages/03_dimensions.html#environment",
    "href": "pages/03_dimensions.html#environment",
    "title": "Dimensions",
    "section": "1 Environment",
    "text": "1 Environment"
  },
  {
    "objectID": "pages/03_dimensions.html#economics",
    "href": "pages/03_dimensions.html#economics",
    "title": "Dimensions",
    "section": "2 Economics",
    "text": "2 Economics"
  },
  {
    "objectID": "pages/03_dimensions.html#production",
    "href": "pages/03_dimensions.html#production",
    "title": "Dimensions",
    "section": "3 Production",
    "text": "3 Production"
  },
  {
    "objectID": "pages/03_dimensions.html#health",
    "href": "pages/03_dimensions.html#health",
    "title": "Dimensions",
    "section": "4 Health",
    "text": "4 Health"
  },
  {
    "objectID": "pages/03_dimensions.html#social",
    "href": "pages/03_dimensions.html#social",
    "title": "Dimensions",
    "section": "5 Social",
    "text": "5 Social"
  },
  {
    "objectID": "pages/03.1_economics.html",
    "href": "pages/03.1_economics.html",
    "title": "Economics",
    "section": "",
    "text": "Shown in the diagram below are a total of 45 indicators within the economics dimension. Indices are labeled within the diagram. 17 indicators are both included in the Wiltshire et al. framework as well as being studied by one or more teams (red), 9 are included in the Wiltshire et al. but not currently belong studied (green), while 19 were not in the original framework, but have been added by one or more teams (blue).\nThe points beside each indicator name represent the number of secondary data metrics that have been aggregated for each indicator. Sources include USDA NASS, BLS, ERS, Census Bureau, and others. The quality and appropiateness of these metrics vary widely - I do not mean to suggest that having more of them means an indicator is more accurately better represented. For more information on the data sources, head to Section 2 below.\nOne other point to note here is that I removed several dozen metrics from BLS wage labor data broken down by NAICS industry code so as not to inflate that indicator relative to the others.\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite,\n  ggrepel,\n  stringr\n)\n\nconflicted::conflicts_prefer(\n  dplyr::as_data_frame(),\n  .quiet = TRUE\n)\n\n## Load data for tree and metrics\ndat &lt;- readRDS('data/trees/econ_tree.rds') %&gt;% \n  select(Dimension:Source)\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmeta &lt;- metadata_all %&gt;% \n  filter(\n    dimension == 'economics'\n  )\n\n# Rename metadata so it fits into formatting of tree data\n# This is quite not ideal - Note to harmonize this properly later\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Assets') ~ 'Balance sheet (assets and liabilities)',\n      str_detect(indicator, '^Business failure') ~ 'Business failure rate of food business',\n      str_detect(indicator, '^Direct') ~ '% direct-to-consumer sales',\n      str_detect(indicator, '^Job avail') ~ 'Availability of good-paying jobs in food systems',\n      str_detect(indicator, '^Local sales') ~ '% local sales',\n      str_detect(indicator, '^Operator salary') ~ 'Operator salary / wage',\n      str_detect(indicator, '^Total sales') ~ 'Total sales / revenue',\n      str_detect(indicator, '^Wealth/income') ~ 'Wealth / income distribution',\n      TRUE ~ indicator\n    )\n  ) \n\n# Join counts of secondary data metrics to original dataset\n# Remove the NAICS variables - there are so many of them, don't add much\ncounts &lt;- meta %&gt;% \n  filter(str_detect(variable_name, '^lq|lvl|Lvl|Naics', negate = TRUE)) %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = to)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = from)\nedges &lt;- bind_rows(edges)\n\n# Add column for use (will use in colors of text?)\nedges$group &lt;- c(rep(NA, 10), dat$Source)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to)))\n) %&gt;% \n  left_join(counts, by = join_by(name == indicator)) %&gt;% \n  dplyr::rename('value' = count)\n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(color = 'black', width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.15,\n      y = y * 1.15,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 3,\n    alpha = 1\n  ) +\n  \n  # Label indices within graph\n  geom_label_repel(\n    aes(\n      x = x,\n      y = y,\n      label = ifelse(name %in% unique(dat$Index), name, NA)\n    ),\n    label.padding = unit(0.15, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.05,\n    size = 2.25,\n    force = 0.1,    \n    force_pull = 1, \n    max.overlaps = 10 \n  ) +\n  \n  # Make the points for indicators based on secondary metric count\n  geom_node_point(\n    aes(\n      filter = leaf,\n      x = x * 1.07,\n      y = y * 1.07,\n      colour = group,\n      size = value\n    ),\n    alpha = 0.4\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(3, 'Set1')) +\n  # scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  scale_colour_manual(\n    name = \"Indicator Use\",\n    values = brewer.pal(3, 'Set1'),\n    labels = c(\"Both\", \"Current Only\", \"Wiltshire Only\")\n  ) +\n  expand_limits(x = c(-2.5, 2.5), y = c(-2.5, 2.5))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#dimension-overview",
    "href": "pages/03.1_economics.html#dimension-overview",
    "title": "Economics",
    "section": "",
    "text": "Shown in the diagram below are a total of 45 indicators within the economics dimension. Indices are labeled within the diagram. 17 indicators are both included in the Wiltshire et al. framework as well as being studied by one or more teams (red), 9 are included in the Wiltshire et al. but not currently belong studied (green), while 19 were not in the original framework, but have been added by one or more teams (blue).\nThe points beside each indicator name represent the number of secondary data metrics that have been aggregated for each indicator. Sources include USDA NASS, BLS, ERS, Census Bureau, and others. The quality and appropiateness of these metrics vary widely - I do not mean to suggest that having more of them means an indicator is more accurately better represented. For more information on the data sources, head to Section 2 below.\nOne other point to note here is that I removed several dozen metrics from BLS wage labor data broken down by NAICS industry code so as not to inflate that indicator relative to the others.\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite,\n  ggrepel,\n  stringr\n)\n\nconflicted::conflicts_prefer(\n  dplyr::as_data_frame(),\n  .quiet = TRUE\n)\n\n## Load data for tree and metrics\ndat &lt;- readRDS('data/trees/econ_tree.rds') %&gt;% \n  select(Dimension:Source)\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmeta &lt;- metadata_all %&gt;% \n  filter(\n    dimension == 'economics'\n  )\n\n# Rename metadata so it fits into formatting of tree data\n# This is quite not ideal - Note to harmonize this properly later\nmeta &lt;- meta %&gt;% \n  mutate(\n    indicator = str_to_sentence(indicator),\n    indicator = case_when(\n      str_detect(indicator, '^Assets') ~ 'Balance sheet (assets and liabilities)',\n      str_detect(indicator, '^Business failure') ~ 'Business failure rate of food business',\n      str_detect(indicator, '^Direct') ~ '% direct-to-consumer sales',\n      str_detect(indicator, '^Job avail') ~ 'Availability of good-paying jobs in food systems',\n      str_detect(indicator, '^Local sales') ~ '% local sales',\n      str_detect(indicator, '^Operator salary') ~ 'Operator salary / wage',\n      str_detect(indicator, '^Total sales') ~ 'Total sales / revenue',\n      str_detect(indicator, '^Wealth/income') ~ 'Wealth / income distribution',\n      TRUE ~ indicator\n    )\n  ) \n\n# Join counts of secondary data metrics to original dataset\n# Remove the NAICS variables - there are so many of them, don't add much\ncounts &lt;- meta %&gt;% \n  filter(str_detect(variable_name, '^lq|lvl|Lvl|Naics', negate = TRUE)) %&gt;% \n  group_by(indicator) %&gt;% \n  dplyr::summarize(count = n())\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = to)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  dplyr::rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = from)\nedges &lt;- bind_rows(edges)\n\n# Add column for use (will use in colors of text?)\nedges$group &lt;- c(rep(NA, 10), dat$Source)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to)))\n) %&gt;% \n  left_join(counts, by = join_by(name == indicator)) %&gt;% \n  dplyr::rename('value' = count)\n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(color = 'black', width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.15,\n      y = y * 1.15,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 3,\n    alpha = 1\n  ) +\n  \n  # Label indices within graph\n  geom_label_repel(\n    aes(\n      x = x,\n      y = y,\n      label = ifelse(name %in% unique(dat$Index), name, NA)\n    ),\n    label.padding = unit(0.15, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.05,\n    size = 2.25,\n    force = 0.1,    \n    force_pull = 1, \n    max.overlaps = 10 \n  ) +\n  \n  # Make the points for indicators based on secondary metric count\n  geom_node_point(\n    aes(\n      filter = leaf,\n      x = x * 1.07,\n      y = y * 1.07,\n      colour = group,\n      size = value\n    ),\n    alpha = 0.4\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(3, 'Set1')) +\n  # scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  scale_colour_manual(\n    name = \"Indicator Use\",\n    values = brewer.pal(3, 'Set1'),\n    labels = c(\"Both\", \"Current Only\", \"Wiltshire Only\")\n  ) +\n  expand_limits(x = c(-2.5, 2.5), y = c(-2.5, 2.5))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#sec-metadata",
    "href": "pages/03.1_economics.html#sec-metadata",
    "title": "Economics",
    "section": "2 Metadata Table",
    "text": "2 Metadata Table\nThis is table to explore metadata for secondary metrics data. It does not include the values or geographic areas themselves, but does include definitions, sources, and links to the data used.\nUsing the table:\n\nClick column headers to sort\nGlobal search in the top right, or column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\nClick the arrow on the left of each row for details, including a URL to the data source.\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Renaming latest year as year, not including og year\n    source,\n    scope,\n    resolution,\n    url\n) %&gt;% \n  setNames(c(str_to_title(names(.))))\n\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metadata_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metadata_table', 'sustainability_metadata.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 150\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metadata_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Variable Name: '), \n            as.character(metadata_all[index, 'variable_name']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)\n\n\n\n\n\nShow/hide more columns\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#data-table",
    "href": "pages/03.1_economics.html#data-table",
    "title": "Economics",
    "section": "3 Data Table",
    "text": "3 Data Table\nThis is another table that includes values. It takes some more legwork to navigate through years and counties, but all the secondary data is included here. Again, use the button to download the filtered view of the table.\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load metrics and metadata\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nfips_key &lt;- readRDS('data/sm_data.rds')[['fips_key']]\n\n# Value formatting function based on units\nsource('dev/format_values.R')\n\n# Filter to economics metrics, join with metadata and county fips codes\necon_metrics &lt;- metrics %&gt;% \n  left_join(metadata_all, by = join_by('variable_name')) %&gt;% \n  filter(dimension == 'economics') %&gt;% \n  left_join(fips_key, by = join_by('fips')) %&gt;% \n  mutate(county_name = ifelse(is.na(county_name), state_name, county_name)) %&gt;% \n  format_values() %&gt;% \n  select(\n    metric,\n    'Variable Name' = variable_name,\n    definition,\n    year = year.x,\n    Area = county_name,\n    units,\n    value\n  ) %&gt;% \n  setNames(c(str_to_title(names(.)))) %&gt;% \n  filter(!is.na(Value))\n\n\n## Reactable table\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      econ_metrics,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        Metric = colDef(\n          minWidth = 125,\n          sticky = 'left'\n        ),\n        'Variable Name' = colDef(\n          minWidth = 125\n        ),\n        Definition = colDef(\n          minWidth = 250\n        ),\n        Units = colDef(minWidth = 100),\n        'Year' = colDef(minWidth = 100)\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\"\n    )\n  )\n)\n\n\n\n\n\nDownload as CSV",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#distributions",
    "href": "pages/03.1_economics.html#distributions",
    "title": "Economics",
    "section": "4 Distributions",
    "text": "4 Distributions\nWe are taking out the abundant but largely redundant BLS NAICS wage data variables to leave us with a more approachable set of 46 variables to explore here. First just show univariate distributions by county.\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\nmetrics &lt;- readRDS('data/sm_data.rds')[['metrics']]\nmetadata &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Use metadata to get help filter by dimension\necon_meta &lt;- metadata %&gt;% \n  filter(dimension == 'economics')\n\n# Filter to economics dimension\necon_metrics &lt;- metrics %&gt;% \n  filter(variable_name %in% econ_meta$variable_name)\n\n# Filter to latest year and new (post-2024) counties\n# Also remove NAICS variables to leave us with an approachable number\n# And pivot wider so it is easier to get correlations\necon_metrics_latest &lt;- econ_metrics %&gt;%\n  filter_fips(scope = 'new') %&gt;% \n  get_latest_year() %&gt;% \n  filter(\n    str_detect(\n      variable_name, \n      'Naics|^lq|^avgEmpLvl|expHiredLaborPercOpExp', \n      negate = TRUE\n    )\n  )\n\n# Pivot wider for easier correlations below\necon_metrics_latest &lt;- econ_metrics_latest %&gt;% \n  select(fips, variable_name, value) %&gt;% \n  unique() %&gt;% \n  mutate(variable_name = str_split_i(variable_name, '_', 1)) %&gt;% \n  pivot_wider(\n    names_from = 'variable_name',\n    values_from = 'value'\n  ) %&gt;% \n  unnest(!fips) %&gt;% \n  mutate(across(c(civLaborForce:last_col()), as.numeric))\n\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nplots &lt;- map(names(econ_metrics_latest)[-1], \\(var){\n  if (is.character(econ_metrics_latest[[var]])) {\n    econ_metrics_latest %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_bar(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else if (is.numeric(econ_metrics_latest[[var]])) {\n    econ_metrics_latest %&gt;% \n      ggplot(aes(x = !!sym(var))) + \n      geom_density(\n        fill = 'lightblue',\n        color = 'royalblue',\n        alpha = 0.5\n      ) +\n      theme_classic() +\n      theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n  } else {\n    return(NULL)\n  }\n}) \n\n\n# Arrange them in 4 columns\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 12\n)\n\n\n\n\n\nDistributions of economic metrics at the county level.\n\n\n\n\nCode\n# ggsave(\n#   'images/distribution_plots.png',\n#   plot = out,\n#   dpi = 150,\n#   width = 1500,\n#   height = 3000,\n#   units = 'px'\n# )",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#correlation-heatmap",
    "href": "pages/03.1_economics.html#correlation-heatmap",
    "title": "Economics",
    "section": "5 Correlation Heatmap",
    "text": "5 Correlation Heatmap\nThrowing those same variables into a correlation matrix. Hover to see variable names, Pearson correlation, and p-values.\n\n\nCode\npacman::p_load(\n  dplyr,\n  tidyr,\n  tibble,\n  stringr,\n  purrr,\n  tidyr,\n  ggplot2,\n  plotly,\n  reshape,\n  Hmisc,\n  viridisLite\n)\n\n# Arrange variables in some halfway reasonable order\ncor_dat &lt;- econ_metrics_latest %&gt;% \n  select(\n    matches('Code_|metro'),\n    matches('employ|abor|Worker'),\n    matches('Sales'),\n    matches('Earn|Income'),\n    everything(),\n    -fips,\n    -matches('expHiredLaborPercOpExp') # This one didn't come through\n  )\n\n# Make a correlation matrix using all the selected variables\ncor &lt;- cor_dat %&gt;% \n  as.matrix() %&gt;% \n  rcorr()\n\n# Melt correlation values and rename columns\ncor_r &lt;- melt(cor$r) %&gt;% \n  setNames(c('var_1', 'var_2', 'value'))\n\n# Save p values\ncor_p &lt;- melt(cor$P)\np.value &lt;- cor_p$value\n\n# Make heatmap with custom text aesthetic for tooltip\nplot &lt;- cor_r %&gt;% \n  ggplot(aes(var_1, var_2, fill = value, text = paste0(\n    'Var 1: ', var_1, '\\n',\n    'Var 2: ', var_2, '\\n',\n    'Correlation: ', format(round(value, 3), nsmall = 3), '\\n',\n    'P-Value: ', format(round(p.value, 3), nsmall = 3)\n  ))) + \n  geom_tile() + \n  scale_fill_viridis_c() + \n  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    fill = 'Correlation'\n  )\n\n# Convert to interactive plotly figure with text tooltip\nggplotly(\n  plot, \n  tooltip = 'text',\n  width = 1000,\n  height = 800\n)\n\n\n\n\nInteractive Correlation Plot",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/03.1_economics.html#pca",
    "href": "pages/03.1_economics.html#pca",
    "title": "Economics",
    "section": "6 PCA",
    "text": "6 PCA\nPCA is a popular tool in this area for exploring unique variation with many collinear variables. It is a way to reduce the dimensionality of the data into fewer, more interpretable principal components.\nIt also requires complete data, which we do not have. So I’m using a random forest algorithm to impute data here (Stekhoven and Bühlmann 2012). This really warrants a deeper dive into the type and severity of missingness, but I’m just going to run with it for now.\n\n\nCode\npacman::p_load(\n  missForest\n)\n\n# Wrangle dataset. Need all numeric vars or factor vars. And can't be tibble\n# Also removing character vars - can't use these in PCA\ndat &lt;- econ_metrics_latest %&gt;%\n  select(where(is.numeric)) %&gt;%\n  as.data.frame()\n# get_str(dat)\n\n# Check missing variables\n# skimr::skim(dat)\n\n# Impute missing variables\nset.seed(42)\nmf_out &lt;- dat %&gt;%\n  missForest(\n    ntree = 200,\n    mtry = 10,\n    verbose = FALSE,\n    variablewise = FALSE\n  )\n\n# Save imputed dataset\nimp &lt;- mf_out$ximp\n\n# Print OOB\nmf_out$OOBerror\n\n\n    NRMSE \n0.1839393 \n\n\nOut of bag error is shown as normalized root mean square error. Now we can explore how many composite factors is appropriate for the data.\n\n\nCode\npacman::p_load(\n  psych\n)\nVSS(imp)\n\n\n\n\n\n\n\n\n\n\nVery Simple Structure\nCall: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n    n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\nVSS complexity 1 achieves a maximimum of 0.68  with  2  factors\nVSS complexity 2 achieves a maximimum of 0.87  with  2  factors\n\nThe Velicer MAP achieves a minimum of 0.04  with  7  factors \nBIC achieves a minimum of  -351.11  with  5  factors\nSample Size adjusted BIC achieves a minimum of  1623.83  with  8  factors\n\nStatistics by number of factors \n  vss1 vss2   map dof chisq\n1 0.58 0.00 0.099 860  4507\n2 0.68 0.87 0.059 818  3743\n3 0.64 0.84 0.058 777  3434\n4 0.65 0.84 0.056 737  3025\n5 0.59 0.83 0.044 698  2690\n6 0.58 0.81 0.043 660  2582\n7 0.57 0.79 0.042 623  2431\n8 0.57 0.81 0.045 587  2331\n                                                                                                                                                                                                                                                                                  prob\n1 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n2 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n3 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n4 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011\n5 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000065155928144872149385125048581812734482809901\n6 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000122685234038161408720319506260310049583495128899813\n7 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002610076918036057804471672394441839060164056718349456787109375000\n8 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001091194080860970601187104334073296740825753659009933471679687500000000\n  sqresid  fit RMSEA  BIC SABIC complex eChisq  SRMR eCRMS  eBIC\n1   109.7 0.58  0.23  760  3472     1.0   6460 0.214 0.219  2713\n2    35.1 0.87  0.21  180  2759     1.3   1483 0.103 0.108 -2081\n3    24.6 0.91  0.21   49  2499     1.6    920 0.081 0.087 -2465\n4    18.5 0.93  0.20 -186  2137     1.7    610 0.066 0.073 -2601\n5    14.1 0.95  0.19 -351  1850     1.7    397 0.053 0.060 -2644\n6    11.7 0.96  0.19 -294  1787     1.9    308 0.047 0.055 -2568\n7     9.4 0.96  0.19 -283  1681     2.0    214 0.039 0.047 -2500\n8     8.1 0.97  0.19 -227  1624     2.0    174 0.035 0.044 -2383\n\n\nCode\nfa.parallel(imp)\n\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  5  and the number of components =  4 \n\n\nVSS gives a wide range from 2 to 8, MAP shows 7, parallel analysis shows 4. I tend to trust PA the most, so let’s go with 4.\n\n\nCode\n(pca_out &lt;- pca(imp, nfactors = 4))\n\n\nPrincipal Components Analysis\nCall: principal(r = r, nfactors = nfactors, residuals = residuals, \n    rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, \n    missing = missing, impute = impute, oblique.scores = oblique.scores, \n    method = method, use = use, cor = cor, correct = 0.5, weight = NULL)\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        RC1   RC2   RC3   RC4    h2    u2 com\ncivLaborForce          0.22  0.90  0.19  0.02 0.901 0.099 1.2\nemployed               0.22  0.90  0.19  0.02 0.900 0.100 1.2\nunemployed             0.22  0.91  0.16  0.10 0.921 0.079 1.2\nunemploymentRate       0.12  0.13 -0.05  0.76 0.617 0.383 1.1\nmedHhIncome            0.07  0.34  0.83 -0.03 0.802 0.198 1.3\nmedHhIncomePercState   0.06  0.07  0.82 -0.16 0.702 0.298 1.1\ngini                  -0.19  0.39  0.00  0.46 0.403 0.597 2.3\nnCSA                   0.16  0.37 -0.10 -0.24 0.235 0.765 2.3\nnFarmersMarket         0.33  0.84  0.13 -0.05 0.828 0.172 1.4\nnOnFarmMarket          0.03  0.07  0.12 -0.09 0.029 0.971 2.6\nagTourSalesPerc       -0.15  0.26  0.32  0.63 0.581 0.419 2.0\nd2cSalesPerc          -0.24  0.41  0.52  0.10 0.501 0.499 2.4\nlocalSalesPerc        -0.18  0.39  0.53  0.04 0.468 0.532 2.1\nnAnaerDigestion        0.54 -0.37 -0.12  0.10 0.451 0.549 2.0\nnCompost               0.36  0.78  0.16  0.07 0.761 0.239 1.5\nnFoodHubs              0.17 -0.02  0.02 -0.12 0.045 0.955 1.8\nnMeatProcess           0.16  0.80  0.07  0.05 0.669 0.331 1.1\nmedianEarnMaleFood    -0.01  0.23  0.09 -0.35 0.186 0.814 1.9\nmedianEarnFemaleFood  -0.19  0.12  0.17  0.63 0.478 0.522 1.4\nwomenEarnPercMaleFood -0.15 -0.15 -0.04  0.67 0.501 0.499 1.2\nmedianEarnMaleFarm    -0.17  0.04  0.33  0.30 0.228 0.772 2.5\nmedianEarnFemaleFarm  -0.11 -0.06  0.71  0.20 0.565 0.435 1.2\nwomenEarnPercMaleFarm -0.08  0.01  0.63  0.08 0.409 0.591 1.1\nnHiredWorkers          0.92  0.29  0.01 -0.11 0.944 0.056 1.2\nnOpsMigrantWorkers     0.79  0.09  0.04 -0.10 0.647 0.353 1.1\nnOpsHiredLabor         0.88  0.26 -0.07 -0.25 0.902 0.098 1.4\nnOpsHiredLaborExp      0.88  0.26 -0.06 -0.25 0.902 0.098 1.4\nnWorkersLE150          0.88  0.23 -0.04 -0.06 0.839 0.161 1.2\nnMigrantWorkers        0.60 -0.14 -0.19  0.13 0.427 0.573 1.4\nnOpsWorkersLE150       0.88  0.24 -0.09 -0.24 0.900 0.100 1.3\nnWorkersGE150          0.85  0.37  0.09 -0.11 0.885 0.115 1.4\nnOpsWorkersGE150       0.89  0.28  0.02 -0.20 0.906 0.094 1.3\nnOpsUnpaidWorkers      0.69  0.25 -0.19 -0.38 0.717 0.283 2.1\nnUnpaidWorkers         0.64  0.34 -0.19 -0.35 0.697 0.303 2.4\nexpHiredLabor          0.95  0.14  0.05 -0.07 0.935 0.065 1.1\nexpHiredLaborPF        0.62 -0.08  0.25  0.15 0.472 0.528 1.5\nexpPF                  0.75 -0.33  0.09  0.30 0.774 0.226 1.8\nfarmIncomePF           0.31  0.26  0.64  0.09 0.585 0.415 1.9\nacresOperated          0.70 -0.41 -0.36 -0.05 0.790 0.210 2.2\nacresPF                0.32 -0.58 -0.54  0.11 0.743 0.257 2.6\nmedianAcresPF          0.22 -0.52 -0.62 -0.01 0.708 0.292 2.2\nlandValPF              0.21 -0.19  0.55  0.01 0.380 0.620 1.6\nlandValPerAcre        -0.14  0.47  0.47  0.21 0.513 0.487 2.6\n\n                        RC1  RC2  RC3  RC4\nSS loadings           11.00 7.46 5.19 3.20\nProportion Var         0.26 0.17 0.12 0.07\nCumulative Var         0.26 0.43 0.55 0.62\nProportion Explained   0.41 0.28 0.19 0.12\nCumulative Proportion  0.41 0.69 0.88 1.00\n\nMean item complexity =  1.7\nTest of the hypothesis that 4 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n with the empirical chi square  680.81  with prob &lt;  0.93 \n\nFit based upon off diagonal values = 0.96\n\n\nCode\nplot(pca_out$values)\nabline(h = 1)\n\n\n\n\n\n\n\n\n\nFrom the scree plot and eigenvalues it looks like the first three components bear lots of unique variance, but after that there is no clear elbow where a qualitative decision can be made to choose a certain number of components. The Kaiser-Guttman rule suggests keeping any compents with an eigenvalue &gt; 1 (at the horizontal line), but we can see here that this is a rather dubious distinction.\nIf we look at the output from the PCA call, we can see how closely each variable (row) correlates with each component (columns 1-4). The variables most associated with Component #1 are the farm labor variables - numbers of workers, labor expenses, etc. They also tend to be raw figures, and probably have more to do with population than anything else. Component #2 is made up mostly of generic employment figures - total civilian labor force, total employed, total unemployed. These are not specific to food systems. Component #3 has a curious collection of median earnings variables and ‘per farm’ variables like acres per farm, income per farm, and local and direct-to-consumer sales. Component #4 does not represent much unique variance, and loooks like a grab bag of variables.\nA couple of early takeaways here are that the raw figures that are tied to population probably shouldn’t be mixed with other variables like proportions. We could try normalizing all the variables so that raw variables are not disproportionately weighted. But it might make more sense to avoid raw counts and dollar amounts entirely.",
    "crumbs": [
      "Dimensions",
      "Economics"
    ]
  },
  {
    "objectID": "pages/02.1_sm-explorer.html",
    "href": "pages/02.1_sm-explorer.html",
    "title": "SM-Explorer",
    "section": "",
    "text": "Caution\n\n\n\n\n\nThe SM-Explorer is a work in progress. There are a small heap of bugs I’m already aware of, and it is using a dataset that outdated compared to the Quarto doc. If you find anything else that isn’t working properly, feel free to let Chris know about it.\n\n\n\nThis is a Shiny app that allows for interactive exploration of metrics, mostly at the county level. It includes a map page, a bivariate plot explorer, and a metadata table much like what is included in this Quarto doc. It tends to work best if you open it in its own page using the button below:\n\n\n\n\nGo To SM-Explorer\n\n\n\n\nYou can also just use it here in the window. Note that some functions (like the full screen button) won’t work here.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "SM-Explorer"
    ]
  },
  {
    "objectID": "pages/01_home.html",
    "href": "pages/01_home.html",
    "title": "Sustainability Metrics",
    "section": "",
    "text": "Caution\n\n\n\n\n\nThe Sustainability Metrics project, as well as this site itself, are both works in progress. All data and analyses shown here are preliminary. If you have any questions, comments, or suggestions, feel free to reach out to Chris at christopher.donovan@uvm.edu.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#sec-intro",
    "href": "pages/01_home.html#sec-intro",
    "title": "Sustainability Metrics",
    "section": "1 Introduction",
    "text": "1 Introduction\n\n\n\nIntervale Center, Burlington, Vermont. Copyright: Sally McCay, UVM Photo.\n\n\nResilient food systems are increasingly recognized as essential, not only in meeting human needs, but in doing so within planetary bounds (Conijn et al. 2018). Approximately 42% of world’s population depend on agriculture for employment, which is a challenging endeavor in the face of farm consolidation, changing consumption patterns, and climate change (Giller et al. 2021; Aznar-Sánchez et al. 2019). Food systems themselves are responsible for one-third of greenhouse gas emissions, while anthropogenic climate change has reduced agricultural output by 21% in the last 60 years (Crippa et al. 2021; Ortiz-Bobea et al. 2021).\nMonitoring and adaptively managing the sustainability of food systems is thus vital. However, there is little consensus on how to define, let alone measure food system sustainability (Allen and Prosperi 2016; Béné et al. 2019). And while there is an abundance of research at the global level (Bathaei and Štreimikienė 2023; Chaudhary, Gustafson, and Mathys 2018), there exists a conspicuous gap in understanding at the local, regional, or landscape level (Dale et al. 2012).\n\n\n\nSpread from the Climate Kitchen harvest dinner. Photo credit: Colleen Goodhue, FSRC.\n\n\nThe Sustainability Metrics project is an effort to develop both the conceptual and methodological frameworks to define and measure regional food system sustainability in New England. The work is led by the Food Systems Research Center at the University of Vermont in partnership with the USDA Agricultural Research Service in Burlington, Vermont. Primary research in developing and measuring indicators of sustainability is ongoing. For now, what you will find here is a growing collection of secondary data, visualizations, and preliminary analyses to help inform the project as well as the public on the sustainability of the New England food system.\nMetadata and citations will be provided throughout the document, but it is worth appreciating the work of the folks at USDA AMS Food and Agriculture Mapper and Explorer in particular, as many of the data shown here were cleaned and compiled in their data warehouse.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#about-fsrc",
    "href": "pages/01_home.html#about-fsrc",
    "title": "Sustainability Metrics",
    "section": "2 About FSRC",
    "text": "2 About FSRC\nThe Food Systems Research Center at the University of Vermont is transforming the research landscape by funding collaborative projects that put people and the planet first, break down traditional academic silos and are integrated with and responsive to the needs of the communities we serve, including decision-makers, farmers, and food systems actors.\nRooted in the belief that no one group can find the answers alone, FSRC empowers researchers to work together across disciplines to address critical issues like soil health, food security, and climate resilience. Instead of funding research that leads to short-term fixes, our commitment is to give researchers the freedom, resources, and time they need to do relevant research that will inform policies, practices, and programs that will long outlast their work.\nFSRC considers the relationship of food systems across scales from local to global and is a partnership between UVM and the U.S. Department of Agriculture (USDA) Agricultural Research Service (ARS). FSRC’s transdisciplinary approach prioritizes research that studies food systems as a whole, including the networks of people, institutions, physical infrastructure, and natural resources through which food is grown, processed, distributed, sold, prepared, and eaten.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/01_home.html#license",
    "href": "pages/01_home.html#license",
    "title": "Sustainability Metrics",
    "section": "3 License",
    "text": "3 License\n\n    This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. \n\n\n    The code is licensed under the GNU General Public License v3.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/02_framework.html",
    "href": "pages/02_framework.html",
    "title": "Framework",
    "section": "",
    "text": "Just including some visualizations of the framework here for now.",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/02_framework.html#radial-plot",
    "href": "pages/02_framework.html#radial-plot",
    "title": "Framework",
    "section": "1 Radial Plot",
    "text": "1 Radial Plot\n\n\nCode\n## Load packages\npacman::p_load(\n  ggraph,\n  igraph,\n  dplyr,\n  RColorBrewer,\n  viridisLite\n)\n\n\n## Load data and add an origin level\ndat &lt;- readRDS('data/trees/tree_dat.rds') %&gt;% \n  mutate(Framework = 'Sustainability') %&gt;% \n  select(Framework, Dimension:Indicator)\n\n\n## Make edges\n# include groupings by dimension, then combine them\nedges &lt;- list()\nedges$sm_dim &lt;- dat %&gt;% \n  select(Framework, Dimension) %&gt;% \n  unique() %&gt;% \n  rename(from = Framework, to = Dimension) %&gt;% \n  mutate(group = to)\nedges$dim_ind &lt;- dat %&gt;% \n  select(Dimension, Index) %&gt;% \n  unique() %&gt;% \n  rename(from = Dimension, to = Index) %&gt;% \n  mutate(group = from)\nedges$ind_ind &lt;- dat %&gt;% \n  select(Index, Indicator) %&gt;% \n  unique() %&gt;% \n  rename(from = Index, to = Indicator) %&gt;% \n  mutate(group = edges$dim_ind$from[match(.$from, edges$dim_ind$to)])\nedges &lt;- bind_rows(edges)\n\n\n## Make vertices\n# Each line is a single vertex (dimension, index, or indicator)\n# We are just giving them random values to control point size for now\nvertices = data.frame(\n  name = unique(c(as.character(edges$from), as.character(edges$to))) , \n  value = runif(nrow(edges) + 1)\n) \n\n# Add the dimension groupings to the vertices as well\nvertices$group = edges$group[match(vertices$name, edges$to)]\n\n# Calculate the angles to arrange indicator labels\nvertices$id = NA\nmyleaves = which(is.na(match(vertices$name, edges$from)))\nnleaves = length(myleaves)\nvertices$id[myleaves] = seq(1:nleaves)\nvertices$angle = 90 - 360 * vertices$id / nleaves\n\n# Calculate alignment of indicator labels\nvertices$hjust &lt;- ifelse(vertices$angle &lt; -90, 1, 0)\n\n# Flip label angles around 180 degrees if they are facing the wrong way\nvertices$angle &lt;- ifelse(vertices$angle &lt; -90, vertices$angle + 180, vertices$angle)\n\n\n## Create graph\n# Make ggraph object from edges and vertices\ngraph &lt;- graph_from_data_frame(edges, vertices = vertices)\n\n# Plot the graph\nggraph(graph, layout = 'dendrogram', circular = TRUE) +\n  \n  # Color edges by dimension\n  geom_edge_diagonal(aes(color = group), width = 0.5) +\n  \n  # Create text for indicators using angles, hjust, and dimension groupings\n  geom_node_text(\n    aes(\n      x = x * 1.04,\n      y = y * 1.04,\n      filter = leaf,\n      label = name,\n      angle = angle,\n      hjust = hjust,\n      colour = group\n    ),\n    size = 2.7,\n    alpha = 1\n  ) +\n  \n  # Make the points for indicators based on dimension groupings\n  # geom_node_point(aes(\n  #   filter = leaf,\n  #   x = x * 1.07,\n  #   y = y * 1.07,\n  #   colour = group,\n  #   size = value,\n  #   alpha = 0.2\n  # )) +\n  \n  # Label the dimensions within the graph\n  geom_node_label(\n    aes(label = ifelse(name == group, name, NA)),\n    label.padding = unit(0.2, \"lines\"),\n    label.r = unit(0.3, \"lines\"),\n    label.size = 0.1,\n    size = 3\n  ) +\n  \n  # Various formatting options\n  scale_colour_manual(values = brewer.pal(5, 'Set1')) +\n  scale_edge_color_manual(values = brewer.pal(5, 'Set1')) +\n  scale_size_continuous(range = c(0.1, 7)) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.margin = unit(c(0, 0, 0, 0), \"cm\")\n  ) +\n  expand_limits(x = c(-2, 2), y = c(-2, 2))\n\n\n\n\n\nRadial dendrogram of Sustainability Metrics framework",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/02_framework.html#cladogram",
    "href": "pages/02_framework.html#cladogram",
    "title": "Framework",
    "section": "2 Cladogram",
    "text": "2 Cladogram\nA slightly more readable version of the diagram above.\n\n\nCode\npacman::p_load(\n  ggtree,\n  dplyr,\n  ape,\n  data.tree,\n  viridisLite,\n  stringr\n)\n\n## Load data and add an origin level\ndat &lt;- readRDS('data/trees/tree_dat.rds') %&gt;% \n  mutate(Framework = 'Sustainability') %&gt;% \n  select(Framework, Dimension:Indicator) %&gt;% \n  mutate(across(\n    everything(), \n    ~ str_trim(str_replace_all(., ';|%|/|\\\\.|\\\"|,|\\\\(|\\\\)', '_'))\n  ))\n\ndat$pathString &lt;- paste(\n  dat$Framework,\n  dat$Dimension,\n  dat$Index,\n  dat$Indicator,\n  sep = '/'\n)\ntree &lt;- as.Node(dat)\n\n# Convert the data.tree structure to Newick format\ntree_newick &lt;- ToNewick(tree)\n\n# Read the Newick tree into ape\nphylo_tree &lt;- read.tree(text = tree_newick)\n\n# Make all edge lengths 1\nphylo_tree$edge.length &lt;- rep(1, length(phylo_tree$edge.length))\n\n# Add a space to end of node labels so it isn't cut off\nphylo_tree$node.label &lt;- paste0(phylo_tree$node.label, ' ')\n\n# Plot it\nplot(\n  phylo_tree, \n  type = 'c',\n  cex = 0.75,\n  edge.width = 2,\n  show.tip.label = TRUE,\n  label.offset = 0,\n  no.margin = TRUE,\n  tip.color = 'black',\n  edge.color = viridis(181),\n  x.lim = c(-0.1, 5)\n)\n\nnodelabels(\n  phylo_tree$node.label,\n  cex = 0.8,\n  bg = 'white'\n)\n\n\n\n\n\nCladogram of Sustainability Metrics framework",
    "crumbs": [
      "Framework"
    ]
  },
  {
    "objectID": "pages/03.1_metrics.html",
    "href": "pages/03.1_metrics.html",
    "title": "Metrics",
    "section": "",
    "text": "Using the table:\n\nClick column headers to sort\nGlobal search at top right, column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Note renaming latest year as year, not including year\n    source,\n    scope,\n    resolution,\n    url\n)\n\n# Fix capitalization of column names\nnames(metadata) &lt;- str_to_title(names(metadata))\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metrics_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        # Dimension = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Index = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Indicator = colDef(\n          # minWidth = 100,\n          # sticky = 'left'\n        # ),\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        Definition = colDef(\n          minWidth = 250,\n        ),\n        # Units = colDef(minWidth = 50),\n        # Year = colDef(minWidth = 75),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included here): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)\n\n\n\n\n\nShow/hide more columns\n\n\n\nDownload as CSV"
  },
  {
    "objectID": "pages/03.1_metrics.html#metrics-explorer",
    "href": "pages/03.1_metrics.html#metrics-explorer",
    "title": "Metrics",
    "section": "",
    "text": "Using the table:\n\nClick column headers to sort\nGlobal search at top right, column search in each header\nChange page length and page through results at the bottom\nUse the download button to download a .csv file of the filtered table\n\n\n\nCode\npacman::p_load(\n  dplyr,\n  reactable,\n  stringr,\n  htmltools\n)\n\n# Load full metadata table\nmetadata_all &lt;- readRDS('data/sm_data.rds')[['metadata']]\n\n# Pick out variables to display\nmetadata &lt;- metadata_all %&gt;% \n  select(\n    metric,\n    definition,\n    dimension,\n    index,\n    indicator,\n    units,\n    'Year' = latest_year, # Note renaming latest year as year, not including year\n    source,\n    scope,\n    resolution,\n    url\n)\n\n# Fix capitalization of column names\nnames(metadata) &lt;- str_to_title(names(metadata))\n\n###\nhtmltools::browsable(\n  tagList(\n    \n    tags$div(\n      style = \"display: flex; gap: 16px; margin-bottom: 20px; justify-content: center;\",\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Show/hide more columns\"),\n        onclick = \"Reactable.setHiddenColumns('metrics_table', prevColumns =&gt; {\n          return prevColumns.length === 0 ? ['Definition', 'Scope', 'Resolution', 'Url'] : []\n        })\"\n      ),\n      \n      tags$button(\n        class = \"btn btn-primary\",\n        style = \"display: flex; align-items: center; gap: 8px; padding: 8px 12px;\",\n        tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n        onclick = \"Reactable.downloadDataCSV('metrics_table', 'sustainability_metrics.csv')\"\n      )\n    ),\n    \n    reactable(\n      metadata,\n      sortable = TRUE,\n      resizable = TRUE,\n      filterable = TRUE,\n      searchable = TRUE,\n      pagination = TRUE,\n      bordered = TRUE,\n      wrap = TRUE,\n      rownames = FALSE,\n      onClick = 'select',\n      striped = TRUE,\n      pageSizeOptions = c(5, 10, 25, 50, 100),\n      defaultPageSize = 5,\n      showPageSizeOptions = TRUE,\n      highlight = TRUE,\n      style = list(fontSize = \"14px\"),\n      compact = TRUE,\n      columns = list(\n        # Dimension = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Index = colDef(\n          # minWidth = 75,\n          # sticky = 'left'\n        # ),\n        # Indicator = colDef(\n          # minWidth = 100,\n          # sticky = 'left'\n        # ),\n        Metric = colDef(\n          minWidth = 200,\n          sticky = 'left'\n        ),\n        Definition = colDef(\n          minWidth = 250,\n        ),\n        # Units = colDef(minWidth = 50),\n        # Year = colDef(minWidth = 75),\n        'Latest Year' = colDef(minWidth = 75),\n        Source = colDef(minWidth = 250),\n        Scope = colDef(show = FALSE),\n        Resolution = colDef(show = FALSE),\n        Url = colDef(\n          minWidth = 300,\n          show = FALSE\n        )\n      ),\n      defaultColDef = colDef(minWidth = 100),\n      elementId = \"metrics_table\",\n      details = function(index) {\n        div(\n          style = \"padding: 15px; border: 1px solid #ddd; margin: 10px 0;\n             background-color: #E0EEEE; border-radius: 10px; border-color: black;\n             box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\",\n          \n          tags$h4(\n            strong(\"Details\"), \n          ),\n          tags$p(\n            strong('Metric Name: '), \n            as.character(metadata_all[index, 'metric']),\n          ),\n          tags$p(\n            strong('Definition: '), \n            as.character(metadata_all[index, 'definition']),\n          ),\n          tags$p(\n            strong('Source: '), \n            as.character(metadata_all[index, 'source'])\n          ),\n          tags$p(\n            strong('Latest Year: '), \n            as.character(metadata_all[index, 'latest_year'])\n          ),\n          tags$p(\n            strong('All Years (cleaned, wrangled, and included here): '), \n            as.character(metadata_all[index, 'year'])\n          ),\n          tags$p(\n            strong('Updates: '), \n            str_to_title(as.character(metadata_all[index, 'updates']))\n          ),\n          tags$p(\n            strong('URL: '), \n            tags$a(\n              href = as.character(metadata_all[index, 'url']),\n              target = '_blank',\n              as.character(metadata_all[index, 'url'])\n            )\n          )\n        )\n      }\n    )\n  )\n)\n\n\n\n\n\nShow/hide more columns\n\n\n\nDownload as CSV"
  },
  {
    "objectID": "pages/04.1_graphs.html",
    "href": "pages/04.1_graphs.html",
    "title": "Exploratory Graphs",
    "section": "",
    "text": "Outdated\n\n\n\n\n\nThis section is outdated and uses an older, smaller dataset. To be reworked."
  },
  {
    "objectID": "pages/04.1_graphs.html#introduction",
    "href": "pages/04.1_graphs.html#introduction",
    "title": "Exploratory Graphs",
    "section": "\n1 Introduction",
    "text": "1 Introduction\n\n\n\n\n\n\nConnecticut Planning Regions\n\n\n\n\n\nThe state of Connecticut has operated under an alternative to the traditional county system known as the Councils of Governments since 1960. The U.S. Census Bureau has historically released figures on the county level. In 2022, the Census Bureau formally recognized the state’s nine governing regions. Unfortunately as it relates to data management, this means that data from before and after 2022 are challenging to compare at the county level. Some resources for understanding the shift can be found at the CT Data Collaborative.\n\n\n\nThis is a first pass at exploratory graphs with the metrics collected so far. We will explore time series trends, marginal distributions, and some bivariate plots and correlations.\n\nKate Schneider (Schneider et al. 2023)\n\nAllen and Prosperi (Allen and Prosperi 2016)."
  },
  {
    "objectID": "pages/04.1_graphs.html#time-series",
    "href": "pages/04.1_graphs.html#time-series",
    "title": "Exploratory Graphs",
    "section": "\n2 Time Series",
    "text": "2 Time Series\nExplore a few metrics that have 5 or more time points at state level.\n\nCodepacman::p_load(\n  dplyr,\n  ggplot2,\n  plotly,\n  purrr,\n  RColorBrewer,\n  stringr\n)\n\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\nfips_key &lt;- readRDS('data/sm_data.rds')[['fips_key']]\n\n## Select metrics\n# Start with variables with &gt;= 5 time points\nts_vars &lt;- dat %&gt;% \n  group_by(variable_name) %&gt;% \n  summarize(n_years = length(unique(year))) %&gt;% \n  filter(n_years &gt;= 5) %&gt;% \n  pull(variable_name)\n\n# Select a subset of them\nts_vars &lt;- str_subset(ts_vars, 'child|overall|^wic|^women')\n\n# Add a clean name for graphs\nts_vars &lt;- data.frame(\n  variable = ts_vars,\n  yaxis = c(\n    'Insecurity Rate',\n    'Insecurity Rate',\n    'Coverage Rate',\n    'Eligibility Rate',\n    'Percent',\n    'Percent'\n  ),\n  title = c(\n    'Child Food Insecurity Rate',\n    'Overall Food Insecurity Rate',\n    'WIC Coverage Rate',\n    'WIC Eligibility Rate',\n    'Women\\'s Earnings as % of Men, Farming',\n    'Women\\'s Earnings as % of Men, Food Service'\n  )\n)\n\n## Keep only New England states, add state names from fips_key df\ndat &lt;- dat %&gt;% \n  filter_fips(scope = 'states') %&gt;% \n  left_join(fips_key, by = 'fips')\n\n\n\nCode# Mapping over our time series variables to make a list of plots\nplots &lt;- map(1:nrow(ts_vars), \\(row) {\n  sub_plot &lt;- dat %&gt;% \n    filter(variable_name == ts_vars$variable[row], str_length(fips) == 2) %&gt;% \n    ggplot(aes(\n      x = year, \n      y = value, \n      group = state_name, \n      color = state_name,\n      text = paste0(\n        'State: ', state_name, '\\n',\n        'Value: ', round(value, 3)\n      )\n    )) +\n    geom_line(\n      lwd = 1,\n      alpha = 0.6\n    ) +\n    theme_bw() +\n    scale_y_continuous(n.breaks = 10) +\n    labs(\n      x = 'Year',\n      y = ts_vars$yaxis[row],\n      color = 'State'\n    ) + \n    scale_color_manual(values = brewer.pal(6, 'Dark2'))\n  \n  ggplotly(\n    sub_plot, \n    tooltip = 'text',\n    width = 500,\n    height = 500\n  ) %&gt;% \n  add_annotations(\n    text = ~unique(ts_vars$title[row]),\n    x = -0.05,\n    y = 1.175,\n    yref = \"paper\",\n    xref = \"paper\",\n    xanchor = \"left\",\n    yanchor = \"top\",\n    showarrow = FALSE,\n    font = list(size = 15)\n  )\n})\n\n# Arrange the plots together in one frame\nsubplot(\n  plots[[1]],\n  style(plots[[2]], showlegend = FALSE),\n  style(plots[[3]], showlegend = FALSE),\n  style(plots[[4]], showlegend = FALSE),\n  style(plots[[5]], showlegend = FALSE),\n  style(plots[[6]], showlegend = FALSE),\n  nrows = 3,\n  heights = c(0.32, 0.36, 0.32),\n  margin = c(0.05, 0.06, 0.05, 0.06),\n  titleY = TRUE\n) %&gt;% \n  plotly::layout(\n    autosize = FALSE,\n    margin = list(l = 25, r = 10, t = 75, b = 75),\n    width = 800,\n    height= 600\n  )\n\n\nInteractive time series plots\n\n\nThere is certainly more to come in terms of time series data."
  },
  {
    "objectID": "pages/04.1_graphs.html#distributions",
    "href": "pages/04.1_graphs.html#distributions",
    "title": "Exploratory Graphs",
    "section": "\n3 Distributions",
    "text": "3 Distributions\nTaking an exploratory look at the distributions of our variables at the county level. We are only using the latest years available for each metric. Note that y-axes are indepednent\n\nCodepacman::p_load(\n  dplyr,\n  purrr,\n  ggplot2,\n  rlang,\n  ggpubr,\n  tidyr\n)\n\nsource('dev/data_pipeline_functions.R')\nsource('dev/filter_fips.R')\ndat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n\n# Get names of all vars\nvars &lt;- dat$variable_name %&gt;% unique\n\n# DF with only final years of all vars, states only, CT governing regions\ndat_latest &lt;- dat %&gt;% \n  filter_fips(scope = 'new') %&gt;% \n  mutate(\n    variable_name = str_sub(variable_name, end = 60),\n    value = as.numeric(value)\n  ) %&gt;%\n  get_latest_year() %&gt;%\n  unique() %&gt;% \n  pivot_wider(\n    id_cols = fips,\n    names_from = 'variable_name',\n    values_from = 'value'\n  )\n\nplots &lt;- map(names(dat_latest)[-1], \\(var){\n  dat_latest %&gt;% \n    ggplot(aes(x = !!sym(var))) + \n    geom_density(\n      fill = 'lightblue',\n      color = 'royalblue',\n      alpha = 0.5\n    ) +\n    theme_classic() +\n    theme(plot.margin = unit(c(rep(0.5, 4)), 'cm'))\n})\n\nggarrange(\n  plotlist = plots,\n  ncol = 4,\n  nrow = 17\n)\n\n\n\nDistributions of all metrics at the county level."
  },
  {
    "objectID": "pages/04.1_graphs.html#bivariate-plots",
    "href": "pages/04.1_graphs.html#bivariate-plots",
    "title": "Exploratory Graphs",
    "section": "\n4 Bivariate Plots",
    "text": "4 Bivariate Plots\n\n\nCodepacman::p_load(\n  GGally\n)\n\n# Neat function for mapping colors to ggpairs plots\n# https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values\nmap_colors &lt;- function(data,\n                       mapping,\n                       method = \"p\",\n                       use = \"pairwise\",\n                       ...) {\n  # grab data\n  x &lt;- eval_data_col(data, mapping$x)\n  y &lt;- eval_data_col(data, mapping$y)\n  \n  # calculate correlation\n  corr &lt;- cor(x, y, method = method, use = use)\n  colFn &lt;- colorRampPalette(c(\"blue\", \"white\", \"red\"), interpolate = 'spline')\n  fill &lt;- colFn(100)[findInterval(corr, seq(-1, 1, length = 100))]\n  \n  # correlation plot\n  ggally_cor(data = data, mapping = mapping, color = 'black', ...) +\n    theme_void() +\n    theme(panel.background = element_rect(fill = fill))\n}\n\nlower_function &lt;- function(data, mapping, ...) {\n  ggplot(data = data, mapping = mapping) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(color = \"blue\", fill = \"grey\", ...) +\n    theme_bw()\n}\n\ndat_latest %&gt;%\n  select(\n    rent = median_rent_2022,\n    rent_burden = median_rent_as_perc_of_household_income_2022,\n    vacancy = vacancy_rate_2022,\n    edu = education_prop_bs_2022,\n    pay_equity = womens_earnings_as_perc_of_men_farming_fishing_forestry_2023,\n    age = mean_producer_age_2022,\n    groc = grocpth_2016,\n    wic = wicspth_2016,\n    snap = snapspth_2017,\n    insecurity = overall_food_insecurity_rate_2021\n  ) %&gt;%\n  ggpairs(\n    upper = list(continuous = map_colors),\n    lower = list(continuous = lower_function),\n    axisLabels = 'show'\n  )\n\n\n\nBivariate scatter plots and correlations for selected metrics."
  },
  {
    "objectID": "pages/04.3_pca.html",
    "href": "pages/04.3_pca.html",
    "title": "PCA",
    "section": "",
    "text": "Code\n# pacman::p_load(\n#   dplyr,\n#   tidyr,\n#   tibble,\n#   missForest\n# )\n# \n# source('dev/data_pipeline_functions.R')\n# source('dev/filter_fips.R')\n# dat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n# get_str(dat)\n# \n# # Wrangle dataset. Need all numeric vars, also have to remove CT because the \n# # county change creates lots of missing data.\n# dat &lt;- dat %&gt;% \n#   filter_fips(scope = 'new') %&gt;% \n#   get_latest_year() %&gt;% \n#   pivot_wider(\n#     names_from = 'variable_name',\n#     values_from = 'value'\n#   ) %&gt;% \n#   filter(str_detect(fips, '^09', negate = TRUE)) %&gt;% \n#   tibble::column_to_rownames('fips')\n# get_str(dat)\n# \n# # Impute missing variables for now (revisit this, too much missing to go well)\n# mf_out &lt;- dat %&gt;% \n#   missForest()\n# \n# # Check OOB\n# mf_out$OOBerror\n# \n# # Use imputed dataset\n# dat &lt;- mf_out$ximp\n\n\n\n\nCode\n# pacman::p_load(\n#   dplyr,\n#   psych\n# )\n# \n# VSS(dat) # 7 \n# fa.parallel(dat) # 5\n# (pca_out &lt;- pca(dat, nfactors = 5))\n# get_str(pca_out)\n# \n# \n# plot(pca_out$values)\n# abline(h = 1)"
  },
  {
    "objectID": "pages/04.3_pca.html#something",
    "href": "pages/04.3_pca.html#something",
    "title": "PCA",
    "section": "",
    "text": "Code\n# pacman::p_load(\n#   dplyr,\n#   tidyr,\n#   tibble,\n#   missForest\n# )\n# \n# source('dev/data_pipeline_functions.R')\n# source('dev/filter_fips.R')\n# dat &lt;- readRDS('data/sm_data.rds')[['metrics']]\n# get_str(dat)\n# \n# # Wrangle dataset. Need all numeric vars, also have to remove CT because the \n# # county change creates lots of missing data.\n# dat &lt;- dat %&gt;% \n#   filter_fips(scope = 'new') %&gt;% \n#   get_latest_year() %&gt;% \n#   pivot_wider(\n#     names_from = 'variable_name',\n#     values_from = 'value'\n#   ) %&gt;% \n#   filter(str_detect(fips, '^09', negate = TRUE)) %&gt;% \n#   tibble::column_to_rownames('fips')\n# get_str(dat)\n# \n# # Impute missing variables for now (revisit this, too much missing to go well)\n# mf_out &lt;- dat %&gt;% \n#   missForest()\n# \n# # Check OOB\n# mf_out$OOBerror\n# \n# # Use imputed dataset\n# dat &lt;- mf_out$ximp\n\n\n\n\nCode\n# pacman::p_load(\n#   dplyr,\n#   psych\n# )\n# \n# VSS(dat) # 7 \n# fa.parallel(dat) # 5\n# (pca_out &lt;- pca(dat, nfactors = 5))\n# get_str(pca_out)\n# \n# \n# plot(pca_out$values)\n# abline(h = 1)"
  }
]